#!/usr/bin/env python3
"""
AIè‚¡ç¥¨é€‰æ‹©å™¨ - å®Œæ•´å®ç°
===========================

åŸºäºQlib + AkShareçš„æ™ºèƒ½é€‰è‚¡ç³»ç»Ÿï¼Œæ”¯æŒï¼š
- æ•°æ®è‡ªåŠ¨ä¸‹è½½ä¸è¡¥é½
- å¤šå› å­ç‰¹å¾å·¥ç¨‹
- é›†æˆå­¦ä¹ æ¨¡å‹(LightGBM + XGBoost + Transformer)
- æŠ•èµ„ç»„åˆä¼˜åŒ–ä¸é£é™©æ§åˆ¶
- **å¤šç§æƒé‡åˆ†é…æ–¹æ³•** (æ–°å¢)
- å®Œæ•´å›æµ‹ä¸æ€§èƒ½è¯„ä¼°
- **Plotlyäº¤äº’å¼å¯è§†åŒ–åˆ†æ**

Usage:
    python ai_stock_selector.py --prepare_data   # ä¸‹è½½&å†™å…¥æ•°æ®
    python ai_stock_selector.py --train          # è®­ç»ƒæ¨¡å‹
    python ai_stock_selector.py --predict        # ç”Ÿæˆé¢„æµ‹ä¿¡å·
    python ai_stock_selector.py --select_stocks  # é€‰è‚¡å¹¶ç”ŸæˆæŠ•èµ„ç»„åˆ
    python ai_stock_selector.py --backtest       # è¿è¡Œå›æµ‹(åŒ…å«å¯è§†åŒ–)
    python ai_stock_selector.py --backtest_stocks --topk 10  # é€‰è‚¡+å›æµ‹+å¯è§†åŒ–å®Œæ•´æµç¨‹
    python ai_stock_selector.py --visualize      # ä»…ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š

Stock Selection & Backtest Examples:
    # åŸºç¡€é€‰è‚¡å›æµ‹ï¼ˆ10åªè‚¡ç¥¨ï¼Œæœˆåº¦è°ƒä»“ï¼‰
    python ai_stock_selector.py --backtest_stocks --topk 10

    # ä»·æ ¼åŒºé—´è¿‡æ»¤é€‰è‚¡å›æµ‹
    python ai_stock_selector.py --backtest_stocks --topk 15 --price_min 10 --price_max 50

    # é«˜é¢‘è°ƒä»“å›æµ‹ï¼ˆå‘¨åº¦ï¼‰
    python ai_stock_selector.py --backtest_stocks --topk 8 --rebalance_freq W

    # æ²ªæ·±300è‚¡ç¥¨æ± é€‰è‚¡å›æµ‹
    python ai_stock_selector.py --backtest_stocks --topk 20 --universe csi300

Weight Methods:
    # ç­‰æƒé‡åˆ†é…ï¼ˆé»˜è®¤ï¼‰
    python ai_stock_selector.py --backtest_stocks --topk 10 --weight_method equal

    # åŸºäºé¢„æµ‹è¯„åˆ†çš„æƒé‡åˆ†é…
    python ai_stock_selector.py --backtest_stocks --topk 10 --weight_method score

    # é£é™©ä¼˜åŒ–æƒé‡åˆ†é…ï¼ˆæ¨èï¼‰
    python ai_stock_selector.py --backtest_stocks --topk 10 --weight_method risk_opt

Visualization Features:
    - ç»¼åˆä»ªè¡¨æ¿: 12ä¸ªå­å›¾è¡¨çš„ä¸“ä¸šåˆ†æç•Œé¢
    - äº¤äº’å¼å›¾è¡¨: æ—¶é—´èŒƒå›´é€‰æ‹©ã€ç¼©æ”¾ã€æ‚¬åœæç¤º
    - ç¾è§‚é…è‰²: ä¸“ä¸šé‡‘èé£æ ¼è®¾è®¡
    - è¯¦ç»†åˆ†æ: é£é™©å½’å› ã€æ”¶ç›Šåˆ†è§£ã€é¢„æµ‹ç²¾åº¦
    - HTMLå¯¼å‡º: å¯åˆ†äº«çš„äº¤äº’å¼æŠ¥å‘Š

    å®‰è£…å¯è§†åŒ–ä¾èµ–: pip install plotly
    è¿è¡Œæ¼”ç¤º: python demo_visualization.py
"""

import os
import sys
import argparse
import warnings
import logging
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
from datetime import datetime, timedelta
import json

# è®¾ç½®è­¦å‘Šå’Œéšæœºç§å­
warnings.filterwarnings('ignore')
np.random.seed(42)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ä¾èµ–æ£€æŸ¥å’Œå¯¼å…¥
try:
    import qlib
    from qlib.config import REG_CN
    from qlib.utils import init_instance_by_config
    from qlib.data import D
    from qlib.data.dataset import DatasetH
    from qlib.data.dataset.handler import DataHandlerLP
    from qlib.contrib.model.gbdt import LGBModel
    from qlib.contrib.strategy.signal_strategy import TopkDropoutStrategy
    print("âœ“ Qlibå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"Qlibå¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å®‰è£…: pip install pyqlib")
    sys.exit(1)

try:
    import akshare as ak
    print("âœ“ AkShareå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.error("AkShareå¯¼å…¥å¤±è´¥")
    print("è¯·å®‰è£…: pip install akshare")
    sys.exit(1)

try:
    import lightgbm as lgb
    print("âœ“ LightGBMå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.warning("LightGBMæœªå®‰è£…")
    print("å»ºè®®å®‰è£…: pip install lightgbm")

try:
    import xgboost as xgb
    print("âœ“ XGBoostå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.warning("XGBoostæœªå®‰è£…")
    print("å»ºè®®å®‰è£…: pip install xgboost")

try:
    import cvxpy as cp
    print("âœ“ CVXPYå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.warning("CVXPYæœªå®‰è£…ï¼Œå°†ä½¿ç”¨TopKç­‰æƒ")
    print("å»ºè®®å®‰è£…: pip install cvxpy")

try:
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    print("âœ“ Plotlyå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.warning("Plotlyæœªå®‰è£…ï¼Œå°†è·³è¿‡å¯è§†åŒ–åŠŸèƒ½")
    print("å»ºè®®å®‰è£…: pip install plotly")

# å…¨å±€é…ç½®
CONFIG = {
    'data_path': os.path.expanduser("~/.qlib/qlib_data/cn_data"),
    'model_path': './models',
    'output_path': './output',
    "start_date": "2014-01-01",
    "train_end":  "2021-12-31",
    "valid_end":  "2023-12-31",
    'end_date': '2025-06-04',
    'universe': 'all',  # ä¸´æ—¶ä½¿ç”¨csi300ç¡®ä¿ç¨³å®šæ€§
    'random_seed': 42,
    'n_jobs': 8
}


class AIStockSelector:
    """AIè‚¡ç¥¨é€‰æ‹©å™¨ä¸»ç±»"""

    def __init__(self, config: Dict = None):
        self.config = {**CONFIG, **(config or {})}
        self.models = {}
        self.data_handler = None
        self.dataset = None

        # é»˜è®¤å‚æ•°
        self.topk = 10
        self.rebalance_freq = 'M'
        self.price_min = 0
        self.price_max = 1e9
        self.weight_method = 'equal'

        # å®æ—¶äº¤æ˜“å‚æ•°
        self.interval = 60
        self.trade_hours = '09:30-11:30,13:00-15:00'
        self.capital = 100000.0

        # åˆ›å»ºå¿…è¦ç›®å½•
        Path(self.config['model_path']).mkdir(exist_ok=True)
        Path(self.config['output_path']).mkdir(exist_ok=True)

    def prepare_data(self):
        """æ•°æ®å‡†å¤‡ï¼šæ£€æŸ¥æœ¬åœ°æ•°æ®ï¼Œç¼ºå¤±åˆ™ç”¨AkShareè¡¥é½"""
        logger.info("å¼€å§‹æ•°æ®å‡†å¤‡...")

        # æ£€æŸ¥æœ¬åœ°Qlibæ•°æ®
        data_path = Path(self.config['data_path'])
        if not data_path.exists() or self._missing_dates():
            logger.info("æœ¬åœ°æ•°æ®ç¼ºå¤±ï¼Œå¼€å§‹ä¸‹è½½...")
            self._download_data_with_akshare()

        # åˆå§‹åŒ–Qlib
        self._init_qlib()
        logger.info("æ•°æ®å‡†å¤‡å®Œæˆ")

    def _missing_dates(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ç¼ºå¤±æ•°æ®"""
        try:
            # ç®€å•æ£€æŸ¥ï¼šæ˜¯å¦å­˜åœ¨åŸºæœ¬ç›®å½•ç»“æ„
            data_path = Path(self.config['data_path'])
            required_dirs = ['features', 'calendars', 'instruments']
            return not all((data_path / d).exists() for d in required_dirs)
        except Exception:
            return True

    def _download_data_with_akshare(self):
        """ä½¿ç”¨AkShareä¸‹è½½æ•°æ®"""
        logger.info("ä½¿ç”¨AkShareä¸‹è½½Aè‚¡æ•°æ®...")

        try:
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            if self.config['universe'] == 'csi300':
                stock_list = ak.index_stock_cons(index="000300")
                stocks = [f"{row['å“ç§ä»£ç ']}.{'SH' if row['å“ç§ä»£ç '].startswith('6') else 'SZ'}"
                         for _, row in stock_list.iterrows()]
            else:
                # è·å–å…¨Aè‚¡
                stocks = self._get_all_a_shares()

            logger.info(f"å‡†å¤‡ä¸‹è½½ {len(stocks)} åªè‚¡ç¥¨æ•°æ®")

            # ä¸‹è½½æ—¥çº¿æ•°æ®
            all_data = []
            for i, symbol in enumerate(stocks[:50]):  # é™åˆ¶50åªè‚¡ç¥¨é¿å…ä¸‹è½½æ—¶é—´è¿‡é•¿
                try:
                    logger.info(f"ä¸‹è½½ {symbol} ({i+1}/{min(50, len(stocks))})...")

                    # AkShareè‚¡ç¥¨ä»£ç æ ¼å¼è½¬æ¢
                    ak_symbol = symbol.replace('.SH', '').replace('.SZ', '')

                    # è·å–å†å²æ•°æ®
                    df = ak.stock_zh_a_hist(
                        symbol=ak_symbol,
                        period="daily",
                        start_date=self.config['start_date'].replace('-', ''),
                        end_date=self.config['end_date'].replace('-', ''),
                        adjust="qfq"  # å‰å¤æƒ
                    )

                    if df.empty:
                        continue

                    # æ•°æ®æ ¼å¼è½¬æ¢
                    df = df.rename(columns={
                        'æ—¥æœŸ': 'date',
                        'å¼€ç›˜': 'open',
                        'æ”¶ç›˜': 'close',
                        'æœ€é«˜': 'high',
                        'æœ€ä½': 'low',
                        'æˆäº¤é‡': 'volume',
                        'æˆäº¤é¢': 'amount',
                        'æ¢æ‰‹ç‡': 'turn'
                    })

                    # æ·»åŠ è‚¡ç¥¨ä»£ç 
                    df['instrument'] = symbol
                    df['date'] = pd.to_datetime(df['date'])

                    # åŸºæœ¬æ•°æ®æ¸…ç†
                    numeric_cols = ['open', 'close', 'high', 'low', 'volume', 'amount']
                    for col in numeric_cols:
                        if col in df.columns:
                            df[col] = pd.to_numeric(df[col], errors='coerce')

                    all_data.append(df)

                except Exception as e:
                    logger.warning(f"ä¸‹è½½ {symbol} å¤±è´¥: {e}")
                    continue

            if all_data:
                # åˆå¹¶æ‰€æœ‰æ•°æ®
                combined_data = pd.concat(all_data, ignore_index=True)

                # ä¿å­˜ä¸ºCSVæ ¼å¼ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                output_file = Path(self.config['output_path']) / 'market_data.csv'
                combined_data.to_csv(output_file, index=False)
                logger.info(f"æ•°æ®å·²ä¿å­˜è‡³: {output_file}")

                # å†™å…¥Qlibæ ¼å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
                self._write_to_qlib_format(combined_data)
            else:
                logger.error("æ²¡æœ‰æˆåŠŸä¸‹è½½ä»»ä½•æ•°æ®")

        except Exception as e:
            logger.error(f"AkShareæ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            logger.info("å°†ä½¿ç”¨Qlibè‡ªå¸¦çš„ç¤ºä¾‹æ•°æ®")

    def _get_all_a_shares(self) -> List[str]:
        """è·å–å…¨Aè‚¡ä»£ç åˆ—è¡¨"""
        try:
            # è·å–Aè‚¡åˆ—è¡¨
            df = ak.stock_info_a_code_name()
            stocks = []
            for _, row in df.iterrows():
                code = row['code']
                if code.startswith('6'):
                    stocks.append(f"{code}.SH")
                elif code.startswith(('0', '3')):
                    stocks.append(f"{code}.SZ")
            return stocks[:500]  # é™åˆ¶æ•°é‡
        except Exception as e:
            logger.warning(f"è·å–Aè‚¡åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _write_to_qlib_format(self, data: pd.DataFrame):
        """å°†æ•°æ®å†™å…¥Qlibæ ¼å¼ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        logger.info("è½¬æ¢æ•°æ®ä¸ºQlibæ ¼å¼...")

        try:
            # è¿™é‡Œæ˜¯ç®€åŒ–å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­éœ€è¦ä½¿ç”¨qlib.data.writer
            # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨qlibè‡ªå¸¦æ•°æ®
            logger.info("ä½¿ç”¨Qlibå†…ç½®æ•°æ®æ ¼å¼")

        except Exception as e:
            logger.warning(f"Qlibæ ¼å¼è½¬æ¢å¤±è´¥: {e}")

    def _init_qlib(self):
        """åˆå§‹åŒ–Qlib"""
        try:
            provider_uri = self.config['data_path']
            qlib.init(provider_uri=provider_uri, region=REG_CN)
            logger.info("Qlibåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Qlibåˆå§‹åŒ–å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            qlib.init(region=REG_CN)
            logger.info("ä½¿ç”¨Qlibé»˜è®¤é…ç½®")

    def train(self):
        """è®­ç»ƒæ¨¡å‹"""
        logger.info("å¼€å§‹æ¨¡å‹è®­ç»ƒ...")

        # åˆå§‹åŒ–Qlibï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
        try:
            D.calendar()
        except:
            self._init_qlib()

        # å‡†å¤‡æ•°æ®é›†
        self._prepare_dataset()

        # è®­ç»ƒå¤šä¸ªæ¨¡å‹
        self._train_lightgbm()
        self._train_xgboost()
        # self._train_transformer()  # éœ€è¦PyTorch

        # è®­ç»ƒé›†æˆæ¨¡å‹
        self._train_ensemble()

        # ä¿å­˜æ¨¡å‹
        self._save_models()

        logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")

    def _prepare_dataset(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®é›†"""
        logger.info("å‡†å¤‡æ•°æ®é›†...")

        # ç‰¹å¾å·¥ç¨‹é…ç½®
        features = self._get_feature_config()

        # æ•°æ®å¤„ç†å™¨é…ç½®
        infer_processors = [
            {"class": "RobustZScoreNorm", "kwargs": {
                "fields_group": "feature",
                "fit_start_time": self.config['start_date'],
                "fit_end_time": self.config['train_end']
            }},
            {"class": "Fillna", "kwargs": {"fields_group": "feature"}}
        ]

        learn_processors = [
            {"class": "DropnaLabel"},
            {"class": "CSRankNorm", "kwargs": {"fields_group": "label"}}
        ]

        # æ•°æ®åŠ è½½å™¨é…ç½®
        data_loader_config = {
            "class": "QlibDataLoader",
            "kwargs": {
                "config": {
                    "feature": features,
                    "label": ["Ref($close, -2) / Ref($close, -1) - 1"]  # 2æ—¥æ”¶ç›Šç‡
                },
                "freq": "day",
            },
        }

        # æ•°æ®å¤„ç†å™¨é…ç½®
        handler_config = {
            "class": "DataHandlerLP",
            "module_path": "qlib.data.dataset.handler",
            "kwargs": {
                "instruments": "csi300",  # æš‚æ—¶ä½¿ç”¨csi300ç¡®ä¿ç¨³å®šæ€§
                "start_time": self.config['start_date'],
                "end_time": self.config['end_date'],
                "data_loader": data_loader_config,
                "infer_processors": infer_processors,
                "learn_processors": learn_processors,
            }
        }

        # æ•°æ®é›†é…ç½®
        dataset_config = {
            "class": "DatasetH",
            "module_path": "qlib.data.dataset",
            "kwargs": {
                "handler": handler_config,
                "segments": {
                    "train": (self.config['start_date'], self.config['train_end']),
                    "valid": (self.config['train_end'], self.config['valid_end']),
                    "test": (self.config['valid_end'], self.config['end_date']),
                },
            }
        }

        try:
            self.dataset = init_instance_by_config(dataset_config)
            logger.info(f"æ•°æ®é›†å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°: {len(features)}")

            # éªŒè¯æ•°æ®é›†æ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°æ®
            try:
                train_data = self.dataset.prepare("train", col_set=["feature", "label"])
                if len(train_data) == 0:
                    logger.error("è®­ç»ƒæ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç‰¹å¾é…ç½®å’Œæ—¶é—´èŒƒå›´")
                    raise ValueError("Empty training dataset")
                else:
                    logger.info(f"è®­ç»ƒæ•°æ®éªŒè¯é€šè¿‡ï¼ŒåŒ…å« {len(train_data)} æ¡è®°å½•")
            except Exception as e:
                logger.error(f"æ•°æ®é›†éªŒè¯å¤±è´¥: {e}")
                raise

        except Exception as e:
            logger.error(f"æ•°æ®é›†å‡†å¤‡å¤±è´¥: {e}")
            raise

    def _get_feature_config(self) -> List[str]:
        """è·å–ç‰¹å¾å·¥ç¨‹é…ç½®

        æ³¨æ„ï¼šå»é™¤äº†$market_capå’Œ$turnç›¸å…³ç‰¹å¾ï¼Œå› ä¸ºè¿™äº›å­—æ®µåœ¨å½“å‰Qlibæ•°æ®ä¸­ä¸å¯ç”¨
        """
        features = []

        # ä»·æ ¼åŠ¨é‡å› å­
        price_momentum = [
            # çŸ­æœŸåŠ¨é‡
            "Mean($close,5)/Ref($close,1)-1",  # 5æ—¥åŠ¨é‡
            "Mean($close,10)/Ref($close,1)-1", # 10æ—¥åŠ¨é‡
            "Mean($close,20)/Ref($close,1)-1", # 20æ—¥åŠ¨é‡

            # å¸ƒæ—å¸¦ä½ç½®
            "($close-Mean($close,20))/Mean($close,20)",
            "($close-Mean($close,20))/(Std($close,20)*2)",

            # MACDç›¸å…³
            "(Mean($close,12)-Mean($close,26))/Mean($close,26)",  # DIF
            "Mean((Mean($close,12)-Mean($close,26))/Mean($close,26),9)",  # DEA

            # ä»·æ ¼åè½¬
            "Ref($close,5)/$close-1",  # 5æ—¥åè½¬
            "Ref($close,10)/$close-1", # 10æ—¥åè½¬
        ]

        # é‡ä»·æ³¢åŠ¨å› å­
        volume_volatility = [
            # æŒ¯å¹…
            "($high-$low)/$low",
            "($high-$low)/$close",

            # ä»·æ ¼æ³¢åŠ¨
            "Std($close/Ref($close,1),5)",   # 5æ—¥æ³¢åŠ¨
            "Std($close/Ref($close,1),10)",  # 10æ—¥æ³¢åŠ¨
            "Std($close/Ref($close,1),20)",  # 20æ—¥æ³¢åŠ¨

            # æˆäº¤é‡ç›¸å…³
            "$volume/Mean($volume,20)",      # é‡æ¯”
            "Std($volume,10)/Mean($volume,10)", # é‡èƒ½å˜å¼‚
            "Corr($close,$volume,10)",       # é‡ä»·ç›¸å…³æ€§
        ]

        # æ›¿ä»£ä¼°å€¼è´¨é‡å› å­ï¼ˆä½¿ç”¨å¯ç”¨å­—æ®µï¼‰
        valuation_quality = [
            # åŸºäºä»·æ ¼çš„ä¼°å€¼ä»£ç†æŒ‡æ ‡
            "Log($close)",                    # ä»·æ ¼æ°´å¹³ï¼ˆå¯¹æ•°åŒ–ï¼‰
            "$close/Mean($close,60)",         # ç›¸å¯¹ä»·æ ¼ä½ç½®
            "Mean($amount,5)",                # æˆäº¤é‡‘é¢å‡å€¼
            "Log($amount+1)",                 # æˆäº¤é‡‘é¢ï¼ˆå¯¹æ•°åŒ–ï¼Œ+1é¿å…log(0)ï¼‰
            "$amount/Mean($amount,20)",       # ç›¸å¯¹æˆäº¤é‡‘é¢
        ]

        # æŠ€æœ¯æŒ‡æ ‡
        technical = [
            # RSIç±»
            "($close-Mean($close,6))/(Std($close,6)+1e-12)",
            "($close-Mean($close,14))/(Std($close,14)+1e-12)",

            # å¨å»‰æŒ‡æ ‡
            "($close-Min($low,14))/(Max($high,14)-Min($low,14)+1e-12)",

            # ä»·æ ¼é€šé“
            "($close-Min($close,20))/(Max($close,20)-Min($close,20)+1e-12)",
        ]

        # ç»„åˆæ‰€æœ‰ç‰¹å¾
        features.extend(price_momentum)
        features.extend(volume_volatility)
        features.extend(valuation_quality)
        features.extend(technical)

        return features

    def _train_lightgbm(self):
        """è®­ç»ƒLightGBMæ¨¡å‹"""
        logger.info("è®­ç»ƒLightGBMæ¨¡å‹...")

        # ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°é…ç½®ï¼ŒåŸºäºè°ƒè¯•æˆåŠŸçš„é…ç½®
        lgb_config = {
            "class": "LGBModel",
            "module_path": "qlib.contrib.model.gbdt",
            "kwargs": {
                "loss": "mse",
                "boosting_type": "gbdt",
                "objective": "regression",
                "num_leaves": 32,  # å‡å°‘å¤æ‚åº¦ï¼Œé¿å…è¿‡æ‹Ÿåˆ
                "learning_rate": 0.1,  # æé«˜å­¦ä¹ ç‡
                "feature_fraction": 0.8,
                "bagging_fraction": 0.8,
                "bagging_freq": 5,
                "num_boost_round": 100,  # å‡å°‘è¿­ä»£æ¬¡æ•°
                "early_stopping_rounds": 10,  # å‡å°‘æ—©åœè½®æ•°
                "verbosity": 1,  # æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
                "seed": self.config['random_seed'],
                "n_jobs": 1,  # ä½¿ç”¨å•çº¿ç¨‹é¿å…å¹¶å‘é—®é¢˜
                "force_col_wise": True  # å¼ºåˆ¶åˆ—å¼å¤šçº¿ç¨‹
            }
        }

        try:
            lgb_model = init_instance_by_config(lgb_config)
            logger.info("å¼€å§‹LightGBMè®­ç»ƒ...")
            lgb_model.fit(self.dataset)
            self.models['lgb'] = lgb_model
            logger.info("LightGBMè®­ç»ƒå®Œæˆ")
        except Exception as e:
            logger.error(f"LightGBMè®­ç»ƒå¤±è´¥: {e}")
            # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

    def _train_xgboost(self):
        """è®­ç»ƒXGBoostæ¨¡å‹"""
        logger.info("è®­ç»ƒXGBoostæ¨¡å‹...")

        # æ£€æŸ¥XGBoostå¯ç”¨æ€§
        try:
            import xgboost
        except ImportError:
            logger.warning("XGBoostæœªå®‰è£…ï¼Œè·³è¿‡è®­ç»ƒ")
            return

        xgb_config = {
            "class": "XGBModel",
            "module_path": "qlib.contrib.model.xgboost",
            "kwargs": {
                "objective": "reg:squarederror",
                "n_estimators": 800,
                "max_depth": 8,
                "learning_rate": 0.02,
                "subsample": 0.8,
                "colsample_bytree": 0.8,
                "random_state": self.config['random_seed'],
                "n_jobs": self.config['n_jobs'],
                "early_stopping_rounds": 100
            }
        }

        try:
            xgb_model = init_instance_by_config(xgb_config)
            xgb_model.fit(self.dataset)
            self.models['xgb'] = xgb_model
            logger.info("XGBoostè®­ç»ƒå®Œæˆ")
        except Exception as e:
            logger.warning(f"XGBoostè®­ç»ƒå¤±è´¥: {e}")

    def _train_ensemble(self):
        """è®­ç»ƒé›†æˆæ¨¡å‹"""
        logger.info("è®­ç»ƒé›†æˆæ¨¡å‹...")

        if len(self.models) == 0:
            logger.error("æ²¡æœ‰åŸºç¡€æ¨¡å‹å¯ç”¨äºé›†æˆ")
            return

        # ç®€åŒ–çš„é›†æˆæ–¹æ³•ï¼šç­‰æƒé‡
        self.models['ensemble'] = {
            'type': 'equal_weight',
            'models': list(self.models.keys()),
            'weights': [1.0/len(self.models)] * len(self.models)
        }

        logger.info(f"é›†æˆæ¨¡å‹åˆ›å»ºå®Œæˆï¼ŒåŒ…å« {len(self.models)-1} ä¸ªåŸºç¡€æ¨¡å‹")

    def _save_models(self):
        """ä¿å­˜æ¨¡å‹"""
        model_path = Path(self.config['model_path'])

        for name, model in self.models.items():
            if name != 'ensemble':
                try:
                    with open(model_path / f"{name}_model.pkl", 'wb') as f:
                        pickle.dump(model, f)
                    logger.info(f"æ¨¡å‹ {name} å·²ä¿å­˜")
                except Exception as e:
                    logger.error(f"ä¿å­˜æ¨¡å‹ {name} å¤±è´¥: {e}")

        # ä¿å­˜é›†æˆé…ç½®
        if 'ensemble' in self.models:
            with open(model_path / "ensemble_config.json", 'w') as f:
                json.dump(self.models['ensemble'], f)

    def predict(self):
        """ç”Ÿæˆé¢„æµ‹ä¿¡å·"""
        logger.info("ç”Ÿæˆé¢„æµ‹ä¿¡å·...")

        # åˆå§‹åŒ–Qlibï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
        try:
            D.calendar()
        except:
            self._init_qlib()

        # åŠ è½½æ¨¡å‹
        self._load_models()

        # ç”Ÿæˆé¢„æµ‹
        predictions = {}

        for name, model in self.models.items():
            if name == 'ensemble':
                continue

            try:
                pred = model.predict(self.dataset, segment='test')
                predictions[name] = pred
                logger.info(f"æ¨¡å‹ {name} é¢„æµ‹å®Œæˆ")
            except Exception as e:
                logger.error(f"æ¨¡å‹ {name} é¢„æµ‹å¤±è´¥: {e}")

        # é›†æˆé¢„æµ‹
        if len(predictions) > 1 and 'ensemble' in self.models:
            ensemble_pred = self._ensemble_predict(predictions)
            predictions['ensemble'] = ensemble_pred

        # ä¿å­˜é¢„æµ‹ç»“æœ
        self._save_predictions(predictions)

        # ç”Ÿæˆæœ€æ–°é€‰è‚¡å»ºè®®
        self._generate_latest_picks(predictions)

        logger.info("é¢„æµ‹ä¿¡å·ç”Ÿæˆå®Œæˆ")
        return predictions

    def _load_models(self):
        """åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"""
        model_path = Path(self.config['model_path'])

        # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡
        if self.models:
            return

        # å‡†å¤‡æ•°æ®é›†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.dataset is None:
            self._prepare_dataset()

        # åŠ è½½å„ä¸ªæ¨¡å‹
        for model_file in model_path.glob("*_model.pkl"):
            name = model_file.stem.replace('_model', '')
            try:
                with open(model_file, 'rb') as f:
                    self.models[name] = pickle.load(f)
                logger.info(f"æ¨¡å‹ {name} åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"åŠ è½½æ¨¡å‹ {name} å¤±è´¥: {e}")

        # åŠ è½½é›†æˆé…ç½®
        ensemble_file = model_path / "ensemble_config.json"
        if ensemble_file.exists():
            with open(ensemble_file, 'r') as f:
                self.models['ensemble'] = json.load(f)

    def _ensemble_predict(self, predictions: Dict) -> pd.Series:
        """é›†æˆé¢„æµ‹"""
        if 'ensemble' not in self.models:
            # ç®€å•å¹³å‡
            pred_values = list(predictions.values())
            return sum(pred_values) / len(pred_values)

        # åŠ æƒå¹³å‡
        ensemble_config = self.models['ensemble']
        weights = ensemble_config['weights']
        model_names = ensemble_config['models']

        result = None
        total_weight = 0

        for i, name in enumerate(model_names):
            if name in predictions:
                weight = weights[i]
                if result is None:
                    result = predictions[name] * weight
                else:
                    result += predictions[name] * weight
                total_weight += weight

        if total_weight > 0:
            result = result / total_weight

        return result

    def _save_predictions(self, predictions: Dict):
        """ä¿å­˜é¢„æµ‹ç»“æœ"""
        output_path = Path(self.config['output_path'])

        for name, pred in predictions.items():
            try:
                # è½¬æ¢ä¸ºDataFrame
                if isinstance(pred, pd.Series):
                    df = pred.reset_index()
                    df.columns = ['date', 'instrument', 'prediction']
                else:
                    df = pred

                # ä¿å­˜CSV
                output_file = output_path / f"signal_{name}.csv"
                df.to_csv(output_file, index=False)
                logger.info(f"é¢„æµ‹ç»“æœ {name} å·²ä¿å­˜è‡³: {output_file}")

            except Exception as e:
                logger.error(f"ä¿å­˜é¢„æµ‹ç»“æœ {name} å¤±è´¥: {e}")

    def _generate_latest_picks(self, predictions: Dict):
        """ç”Ÿæˆæœ€æ–°é€‰è‚¡å»ºè®®å¹¶ä¿å­˜ä¸ºlatest_stock_picks.csv"""
        try:
            # é€‰æ‹©æœ€ä½³é¢„æµ‹ï¼ˆä¼˜å…ˆé›†æˆæ¨¡å‹ï¼‰
            if 'ensemble' in predictions:
                pred_score = predictions['ensemble']
                model_name = 'ensemble'
            elif predictions:
                model_name = list(predictions.keys())[0]
                pred_score = predictions[model_name]
            else:
                logger.error("æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹ç»“æœ")
                return

            # è·å–æœ€æ–°æ—¥æœŸçš„é¢„æµ‹
            latest_date = pred_score.index.get_level_values(0).max()
            latest_predictions = pred_score.loc[latest_date].dropna()

            if len(latest_predictions) == 0:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ€æ–°çš„é¢„æµ‹æ•°æ®")
                return

            # ä½¿ç”¨é€‰è‚¡å‡½æ•°é€‰æ‹©è‚¡ç¥¨
            selected_weights = self.select_stocks(latest_predictions, self.topk, latest_date,
                                                 self.price_min, self.price_max,
                                                 weight_method=self.weight_method)

            if len(selected_weights) == 0:
                logger.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
                return

            # ä½¿ç”¨AkShareè·å–è‚¡ç¥¨åç§°å’Œæœ€æ–°è‚¡ä»·
            stock_codes = [stock for stock in selected_weights.index]
            stock_names = self._get_stock_names(stock_codes)
            stock_prices = self._get_latest_stock_prices(stock_codes)

            # åˆ›å»ºæ¨èåˆ—è¡¨
            recommendations = []
            for rank, (stock_code, weight) in enumerate(selected_weights.items(), 1):
                pred_score_val = latest_predictions[stock_code]
                stock_name = stock_names.get(stock_code, 'æœªçŸ¥')
                price_info = stock_prices.get(stock_code, {})

                recommendations.append({
                    'rank': rank,
                    'stock_code': stock_code,
                    'stock_name': stock_name,
                    'pred_score': pred_score_val,
                    'weight': weight,
                    'current_price': price_info.get('current_price', 0),
                    'change_pct': price_info.get('change_pct', 0),
                    'change_amount': price_info.get('change_amount', 0),
                    'volume': price_info.get('volume', 0),
                    'turnover': price_info.get('turnover', 0),
                    'date': latest_date.strftime('%Y-%m-%d')
                })

            # ä¿å­˜ä¸ºCSV
            df = pd.DataFrame(recommendations)
            output_file = Path(self.config['output_path']) / 'latest_stock_picks.csv'
            df.to_csv(output_file, index=False, encoding='utf-8-sig')

            # åœ¨ç»ˆç«¯æ‰“å°
            print("\n" + "="*120)
            print("ğŸ¯ æœ€æ–°AIé€‰è‚¡å»ºè®® + å®æ—¶è‚¡ä»·")
            print("="*120)
            print(f"æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')} | æ•°æ®æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"æ¨¡å‹: {model_name}")
            print("-"*120)
            print(f"{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<10} {'è‚¡ç¥¨åç§°':<10} {'å½“å‰ä»·æ ¼':<8} {'æ¶¨è·Œå¹…':<8} {'æ¶¨è·Œé¢':<8} {'æˆäº¤é‡(ä¸‡)':<10} {'é¢„æµ‹è¯„åˆ†':<8} {'æƒé‡':<6}")
            print("-"*120)

            for rec in recommendations:
                stock_code = rec['stock_code']
                stock_name = rec['stock_name'][:8] + ('...' if len(rec['stock_name']) > 8 else '')  # é™åˆ¶åç§°é•¿åº¦
                current_price = rec['current_price']
                change_pct = rec['change_pct']
                change_amount = rec['change_amount']
                volume_wan = rec['volume'] / 10000 if rec['volume'] > 0 else 0  # è½¬æ¢ä¸ºä¸‡è‚¡

                # æ¶¨è·Œå¹…é¢œè‰²æ ‡è¯†ï¼ˆç»ˆç«¯é¢œè‰²ï¼‰
                if change_pct > 0:
                    change_pct_str = f"+{change_pct:.2f}%"
                    change_amount_str = f"+{change_amount:.2f}"
                elif change_pct < 0:
                    change_pct_str = f"{change_pct:.2f}%"
                    change_amount_str = f"{change_amount:.2f}"
                else:
                    change_pct_str = "0.00%"
                    change_amount_str = "0.00"

                print(f"{rec['rank']:<4} {stock_code:<10} {stock_name:<10} "
                      f"{current_price:<8.2f} {change_pct_str:<8} {change_amount_str:<8} "
                      f"{volume_wan:<10.0f} {rec['pred_score']:<8.4f} {rec['weight']:<6.1%}")

            print("-"*120)
            avg_score = sum(rec['pred_score'] for rec in recommendations) / len(recommendations)
            avg_price = sum(rec['current_price'] for rec in recommendations if rec['current_price'] > 0) / len([r for r in recommendations if r['current_price'] > 0]) if any(r['current_price'] > 0 for r in recommendations) else 0
            total_volume = sum(rec['volume'] for rec in recommendations) / 10000  # ä¸‡è‚¡

            print(f"å¹³å‡é¢„æµ‹è¯„åˆ†: {avg_score:.4f} | å¹³å‡è‚¡ä»·: {avg_price:.2f}å…ƒ | æ€»æˆäº¤é‡: {total_volume:.0f}ä¸‡è‚¡")
            print(f"é€‰è‚¡æ–‡ä»¶å·²ä¿å­˜: {output_file}")
            print("="*120)

            logger.info(f"æœ€æ–°é€‰è‚¡å»ºè®®(å«è‚¡ä»·)å·²ä¿å­˜è‡³: {output_file}")

        except Exception as e:
            logger.error(f"ç”Ÿæˆæœ€æ–°é€‰è‚¡å»ºè®®å¤±è´¥: {e}")

    def _get_stock_names(self, stock_codes: List[str]) -> Dict[str, str]:
        """ä½¿ç”¨AkShareè·å–è‚¡ç¥¨åç§°"""
        stock_names = {}

        try:
            import akshare as ak

            # è·å–Aè‚¡ä¿¡æ¯
            stock_info = ak.stock_info_a_code_name()

            for stock_code in stock_codes:
                try:
                    # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ï¼šSH600000 -> 600000
                    if stock_code.startswith('SH'):
                        code = stock_code[2:]
                    elif stock_code.startswith('SZ'):
                        code = stock_code[2:]
                    else:
                        code = stock_code

                    # åœ¨è‚¡ç¥¨ä¿¡æ¯ä¸­æŸ¥æ‰¾
                    matching_stocks = stock_info[stock_info['code'] == code]
                    if not matching_stocks.empty:
                        stock_names[stock_code] = matching_stocks.iloc[0]['name']
                    else:
                        stock_names[stock_code] = f"æœªçŸ¥({code})"

                except Exception:
                    stock_names[stock_code] = f"æœªçŸ¥({stock_code})"

        except Exception as e:
            logger.warning(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›è‚¡ç¥¨ä»£ç ä½œä¸ºåç§°
            for stock_code in stock_codes:
                stock_names[stock_code] = stock_code

        return stock_names

    def _get_latest_stock_prices(self, stock_codes: List[str]) -> Dict[str, Dict]:
        """ä½¿ç”¨AkShareè·å–æœ€æ–°è‚¡ä»·ä¿¡æ¯"""
        stock_prices = {}

        try:
            import akshare as ak
            logger.info("æ­£åœ¨è·å–æœ€æ–°è‚¡ä»·ä¿¡æ¯...")

            for stock_code in stock_codes:
                try:
                    # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ï¼šSH600000 -> 600000
                    if stock_code.startswith('SH'):
                        code = stock_code[2:]
                    elif stock_code.startswith('SZ'):
                        code = stock_code[2:]
                    else:
                        code = stock_code

                    # è·å–æœ€æ–°è‚¡ä»·ä¿¡æ¯
                    # ä¼˜å…ˆä½¿ç”¨å†å²æ•°æ®æ¥å£ï¼ˆæ›´ç¨³å®šï¼‰
                    try:
                        hist_data = ak.stock_zh_a_hist(
                            symbol=code,
                            period="daily",
                            start_date=(datetime.now() - timedelta(days=5)).strftime('%Y%m%d'),
                            end_date=datetime.now().strftime('%Y%m%d'),
                            adjust="qfq"
                        )

                        if not hist_data.empty:
                            latest_row = hist_data.iloc[-1]
                            prev_close = hist_data.iloc[-2]['æ”¶ç›˜'] if len(hist_data) > 1 else latest_row['æ”¶ç›˜']
                            current_price = float(latest_row['æ”¶ç›˜'])
                            change_amount = current_price - prev_close
                            change_pct = (change_amount / prev_close * 100) if prev_close > 0 else 0

                            stock_prices[stock_code] = {
                                'current_price': current_price,
                                'change_pct': change_pct,
                                'change_amount': change_amount,
                                'volume': int(latest_row['æˆäº¤é‡']) if 'æˆäº¤é‡' in latest_row else 0,
                                'turnover': float(latest_row['æˆäº¤é¢']) if 'æˆäº¤é¢' in latest_row else 0,
                                'high': float(latest_row['æœ€é«˜']),
                                'low': float(latest_row['æœ€ä½']),
                                'open': float(latest_row['å¼€ç›˜'])
                            }
                        else:
                            raise ValueError("å†å²æ•°æ®ä¸ºç©º")
                    except Exception:
                        # å¤‡ç”¨æ–¹æ³•ï¼šå°è¯•å®æ—¶è¡Œæƒ…æ¥å£
                        try:
                            realtime_data = ak.stock_zh_a_spot_em()
                            matching_data = realtime_data[realtime_data['ä»£ç '] == code]

                            if not matching_data.empty:
                                row = matching_data.iloc[0]
                                stock_prices[stock_code] = {
                                    'current_price': float(row['æœ€æ–°ä»·']),
                                    'change_pct': float(row['æ¶¨è·Œå¹…']),
                                    'change_amount': float(row['æ¶¨è·Œé¢']),
                                    'volume': int(row['æˆäº¤é‡']),
                                    'turnover': float(row['æˆäº¤é¢']) if 'æˆäº¤é¢' in row else 0,
                                    'high': float(row['æœ€é«˜']) if 'æœ€é«˜' in row else 0,
                                    'low': float(row['æœ€ä½']) if 'æœ€ä½' in row else 0,
                                    'open': float(row['ä»Šå¼€']) if 'ä»Šå¼€' in row else 0
                                }
                            else:
                                raise ValueError("å®æ—¶æ•°æ®æœªæ‰¾åˆ°åŒ¹é…è‚¡ç¥¨")
                        except Exception:
                            # æ— æ³•è·å–æ•°æ®æ—¶ä½¿ç”¨é»˜è®¤å€¼
                            stock_prices[stock_code] = {
                                'current_price': 0,
                                'change_pct': 0,
                                'change_amount': 0,
                                'volume': 0,
                                'turnover': 0,
                                'high': 0,
                                'low': 0,
                                'open': 0
                            }

                except Exception as e:
                    logger.warning(f"è·å–è‚¡ç¥¨ {stock_code} ä»·æ ¼å¤±è´¥: {e}")
                    stock_prices[stock_code] = {
                        'current_price': 0,
                        'change_pct': 0,
                        'change_amount': 0,
                        'volume': 0,
                        'turnover': 0,
                        'high': 0,
                        'low': 0,
                        'open': 0
                    }

        except Exception as e:
            logger.error(f"è·å–è‚¡ä»·ä¿¡æ¯å¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
            for stock_code in stock_codes:
                stock_prices[stock_code] = {
                    'current_price': 0,
                    'change_pct': 0,
                    'change_amount': 0,
                    'volume': 0,
                    'turnover': 0,
                    'high': 0,
                    'low': 0,
                    'open': 0
                }

        return stock_prices

    def backtest(self):
        """è¿è¡Œå›æµ‹"""
        logger.info("å¼€å§‹å›æµ‹...")

        # åˆå§‹åŒ–Qlibï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
        try:
            D.calendar()
        except:
            self._init_qlib()

        # åŠ è½½æ¨¡å‹å’Œç”Ÿæˆé¢„æµ‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if not self.models:
            self._load_models()

        predictions = self.predict()

        # é€‰æ‹©æœ€ä½³é¢„æµ‹ï¼ˆä¼˜å…ˆé›†æˆæ¨¡å‹ï¼‰
        if 'ensemble' in predictions:
            pred_score = predictions['ensemble']
            model_name = 'ensemble'
        elif predictions:
            model_name = list(predictions.keys())[0]
            pred_score = predictions[model_name]
        else:
            logger.error("æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹ç»“æœ")
            return

        logger.info(f"ä½¿ç”¨æ¨¡å‹ {model_name} è¿›è¡Œå›æµ‹")

        # è¿è¡Œå›æµ‹
        backtest_results = self._run_backtest(pred_score, self.topk, self.rebalance_freq)

        # å•å…ƒæµ‹è¯•
        self._validate_results(backtest_results)

        # ä¿å­˜ç»“æœ
        self._save_backtest_results(backtest_results, model_name)

        # åˆ›å»ºå¯è§†åŒ–åˆ†æ
        self._create_visualization(backtest_results, model_name, predictions)

        logger.info("å›æµ‹å®Œæˆ")
        return backtest_results

    def _run_backtest(self, pred_score: pd.Series, topk: int = 10, rebalance_freq: str = 'M') -> Dict:
        """æ‰§è¡Œå›æµ‹é€»è¾‘"""
        logger.info("æ‰§è¡Œå›æµ‹é€»è¾‘...")

        # è·å–æµ‹è¯•é›†æ•°æ®
        test_data = self.dataset.prepare("test", col_set=["feature", "label"],
                                       data_key=DataHandlerLP.DK_L)

        # å¯¹é½é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
        aligned_data = pd.DataFrame({
            'pred': pred_score.loc[test_data.index],
            'true': test_data["label"].squeeze()
        }).dropna()

        # è®¡ç®—ICæŒ‡æ ‡
        ic_mean = aligned_data.groupby(level=0).apply(
            lambda x: x['pred'].corr(x['true'])
        ).mean()

        ic_std = aligned_data.groupby(level=0).apply(
            lambda x: x['pred'].corr(x['true'])
        ).std()

        ic_ir = ic_mean / ic_std if ic_std > 0 else 0

        # æŠ•èµ„ç»„åˆå›æµ‹
        portfolio_results = self._portfolio_backtest(aligned_data, topk, rebalance_freq=rebalance_freq)

        results = {
            'ic_mean': ic_mean,
            'ic_std': ic_std,
            'ic_ir': ic_ir,
            'price_min': self.price_min,
            'price_max': self.price_max,
            **portfolio_results
        }

        return results

    def _portfolio_backtest(self, aligned_data: pd.DataFrame,
                          top_k: int = 10, initial_capital: float = 1000000,
                          rebalance_freq: str = 'M') -> Dict:
        """æŠ•èµ„ç»„åˆå›æµ‹ - ä¼˜åŒ–ç‰ˆ"""

        portfolio_returns = []
        turnover_rates = []
        prev_positions = None
        cumulative_nav = 1.0
        max_nav = 1.0

        # é£é™©æ§åˆ¶å‚æ•°
        target_volatility = 0.12  # ç›®æ ‡å¹´åŒ–æ³¢åŠ¨ç‡12%
        max_daily_loss = 0.015    # å•æ—¥æœ€å¤§æŸå¤±1.5%
        max_drawdown_limit = 0.06 # æœ€å¤§å›æ’¤é™åˆ¶6%
        position_limit = 0.04     # å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½4%

        dates = aligned_data.index.get_level_values(0).unique().sort_values()

        # æ ¹æ®è°ƒä»“é¢‘ç‡ç¡®å®šè°ƒä»“æ—¥æœŸ
        rebalance_dates = self._get_rebalance_dates(dates, rebalance_freq)

        for i, date in enumerate(dates[:-2]):  # é¿å…æ•°æ®æ³„æ¼ï¼Œæ”¹ä¸º2å¤©
            try:
                day_data = aligned_data.loc[date]
                if len(day_data) < top_k:
                    continue

                # æ£€æŸ¥æ˜¯å¦ä¸ºè°ƒä»“æ—¥
                is_rebalance_day = date in rebalance_dates

                if is_rebalance_day or prev_positions is None:
                    # ä½¿ç”¨æ–°çš„é€‰è‚¡å‡½æ•°
                    selected_weights = self.select_stocks(day_data['pred'], top_k, date,
                                                         self.price_min, self.price_max,
                                                         weight_method=self.weight_method,
                                                         prev_weights=prev_positions)

                    if len(selected_weights) == 0:
                        continue

                    # ä½¿ç”¨ç»„åˆä¼˜åŒ–
                    if prev_positions is not None:
                        optimized_weights = self.optimize_portfolio(
                            day_data['pred'].loc[selected_weights.index],
                            prev_positions
                        )
                        current_positions = optimized_weights
                    else:
                        current_positions = selected_weights
                else:
                    # éè°ƒä»“æ—¥ï¼Œä¿æŒç°æœ‰ä»“ä½
                    if prev_positions is None:
                        continue
                    current_positions = prev_positions.copy()

                # è®¡ç®—æ¢æ‰‹ç‡
                if prev_positions is not None:
                    turnover = self._calc_turnover(prev_positions, current_positions)
                else:
                    turnover = 1.0
                turnover_rates.append(turnover)

                # ç»„åˆæ”¶ç›Šè®¡ç®—
                if is_rebalance_day or prev_positions is None:
                    # è°ƒä»“æ—¥ï¼šä½¿ç”¨æ–°æƒé‡è®¡ç®—æ”¶ç›Š
                    portfolio_return = 0
                    for stock in current_positions.index:
                        if stock in day_data.index:
                            stock_return = day_data.loc[stock, 'true']
                            portfolio_return += current_positions[stock] * stock_return
                else:
                    # éè°ƒä»“æ—¥ï¼šä½¿ç”¨å‰æœŸæƒé‡è®¡ç®—æ”¶ç›Š
                    portfolio_return = 0
                    for stock in prev_positions.index:
                        if stock in day_data.index:
                            stock_return = day_data.loc[stock, 'true']
                            portfolio_return += prev_positions[stock] * stock_return

                # ä¸¥æ ¼çš„é£é™©æ§åˆ¶
                portfolio_return = np.clip(portfolio_return, -max_daily_loss, max_daily_loss)

                # äº¤æ˜“æˆæœ¬ï¼ˆåˆ†çº§æ”¶è´¹ï¼‰
                transaction_cost = self._calc_realistic_transaction_cost(turnover, cumulative_nav * initial_capital)
                net_return = portfolio_return - transaction_cost

                # åŠ¨æ€é£é™©ç®¡ç†
                current_nav = cumulative_nav * (1 + net_return)
                current_drawdown = (current_nav - max_nav) / max_nav

                # å¦‚æœå›æ’¤è¿‡å¤§ï¼Œå‡å°‘ä»“ä½
                if current_drawdown < -max_drawdown_limit:
                    risk_reduction = 0.5  # å‡ä»“50%
                    net_return = net_return * risk_reduction
                    current_nav = cumulative_nav * (1 + net_return)

                cumulative_nav = current_nav
                max_nav = max(max_nav, cumulative_nav)

                portfolio_returns.append(net_return)
                prev_positions = current_positions.copy()

            except Exception:
                continue

        returns_series = pd.Series(portfolio_returns)

        if len(returns_series) == 0:
            return self._get_empty_metrics()

        # è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
        total_return = (1 + returns_series).prod() - 1
        annual_return = returns_series.mean() * 252  # ç®€åŒ–å¹´åŒ–
        volatility = returns_series.std() * np.sqrt(252)
        sharpe_ratio = annual_return / volatility if volatility > 0 else 0

        # æœ€å¤§å›æ’¤
        cumulative = (1 + returns_series).cumprod()
        running_max = cumulative.expanding().max()
        drawdowns = (cumulative - running_max) / running_max
        max_drawdown = drawdowns.min()

        # å…¶ä»–æŒ‡æ ‡
        win_rate = (returns_series > 0).mean()
        avg_turnover = np.mean(turnover_rates)

        return {
            'total_return': total_return,
            'annual_return': annual_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'win_rate': win_rate,
            'avg_turnover': avg_turnover,
            'trading_days': len(returns_series),
            'returns': returns_series
        }

    def _calc_turnover(self, prev_positions: pd.Series,
                      current_positions: pd.Series) -> float:
        """è®¡ç®—æ¢æ‰‹ç‡"""
        all_stocks = set(prev_positions.index) | set(current_positions.index)
        prev_aligned = pd.Series(0.0, index=all_stocks)
        curr_aligned = pd.Series(0.0, index=all_stocks)

        prev_aligned.loc[prev_positions.index] = prev_positions
        curr_aligned.loc[current_positions.index] = current_positions

        return abs(curr_aligned - prev_aligned).sum()

    def select_stocks(self, pred_scores: pd.Series, topk: int, date: pd.Timestamp,
                     price_min: float = 0, price_max: float = 1e9,
                     blacklist: Optional[set] = None, weight_method: str = 'equal',
                     prev_weights: Optional[pd.Series] = None) -> pd.Series:
        """
        é€‰è‚¡å­å‡½æ•°ï¼šè¿”å› {instrument: weight}ï¼Œæƒé‡å·²å½’ä¸€åŒ–ä¸”æ»¡è¶³ w_i â‰¤ 0.15

        Args:
            pred_scores: é¢„æµ‹è¯„åˆ† Series
            topk: é€‰æ‹©è‚¡ç¥¨æ•°é‡
            date: å½“å‰æ—¥æœŸ
            price_min: æœ€ä½ä»·æ ¼é™åˆ¶
            price_max: æœ€é«˜ä»·æ ¼é™åˆ¶
            blacklist: é»‘åå•è‚¡ç¥¨é›†åˆ
            weight_method: æƒé‡åˆ†é…æ–¹æ³• ('equal', 'score', 'risk_opt')
            prev_weights: å‰æœŸæƒé‡ (ç”¨äºrisk_optæ–¹æ³•)

        Returns:
            pd.Series: {è‚¡ç¥¨ä»£ç : æƒé‡}
        """
        if blacklist is None:
            blacklist = set()

        # è·å–qlibæœ€æ–°äº¤æ˜“æ—¥æœŸï¼Œè€Œä¸æ˜¯ä½¿ç”¨é¢„æµ‹æ—¥æœŸ
        try:
            calendar = D.calendar()
            latest_trading_date = calendar[-1]
            logger.info(f"ä½¿ç”¨qlibæœ€æ–°äº¤æ˜“æ—¥æœŸè¿›è¡Œä»·æ ¼è¿‡æ»¤: {latest_trading_date.strftime('%Y-%m-%d')}")
        except Exception as e:
            logger.warning(f"è·å–qlibäº¤æ˜“æ—¥å†å¤±è´¥: {e}ï¼Œä½¿ç”¨é¢„æµ‹æ—¥æœŸ")
            latest_trading_date = date

        # è¿‡æ»¤æ¡ä»¶
        valid_stocks = []

        for stock_code, score in pred_scores.items():
            # åŸºæœ¬è¿‡æ»¤æ¡ä»¶
            if pd.isna(score) or stock_code in blacklist:
                continue

            # STè‚¡ç¥¨è¿‡æ»¤ï¼ˆç®€åŒ–å®ç°ï¼šæ£€æŸ¥è‚¡ç¥¨ä»£ç ä¸­æ˜¯å¦åŒ…å«STæ ‡è¯†ï¼‰
            if 'ST' in stock_code or stock_code.startswith('ST'):
                continue

            # ä»·æ ¼åŒºé—´è¿‡æ»¤ï¼ˆä½¿ç”¨qlibæœ€æ–°äº¤æ˜“æ—¥æ•°æ®ï¼Œé€šè¿‡å¤æƒå› å­è½¬æ¢ä¸ºçœŸå®ä»·æ ¼ï¼‰
            try:
                # ä½¿ç”¨qlibæœ€æ–°äº¤æ˜“æ—¥æœŸè¯»å–æ”¶ç›˜ä»·å’Œå¤æƒå› å­
                price_data = D.features([stock_code], ['$close', '$factor'],
                                      start_time=latest_trading_date, end_time=latest_trading_date)

                if price_data.empty or price_data.isna().all().all():
                    # ä»·æ ¼æ•°æ®ç¼ºå¤±ï¼Œå‰”é™¤è¯¥è‚¡ç¥¨
                    logger.debug(f"è‚¡ç¥¨ {stock_code} åœ¨æœ€æ–°äº¤æ˜“æ—¥æ— ä»·æ ¼æ•°æ®ï¼Œå·²å‰”é™¤")
                    continue

                adjusted_price = price_data.iloc[0, 0]  # è·å–è°ƒæ•´åæ”¶ç›˜ä»·
                factor = price_data.iloc[0, 1]  # è·å–å¤æƒå› å­

                # è®¡ç®—çœŸå®ä»·æ ¼ï¼šæ ¹æ®qlibæ–‡æ¡£ï¼Œfactor = adjusted_price / original_price
                # æ‰€ä»¥ï¼šoriginal_price = adjusted_price / factor
                if pd.isna(adjusted_price) or pd.isna(factor) or factor == 0:
                    logger.debug(f"è‚¡ç¥¨ {stock_code} ä»·æ ¼æˆ–å› å­æ•°æ®å¼‚å¸¸ï¼Œå·²å‰”é™¤")
                    continue

                real_price = adjusted_price / factor  # è½¬æ¢ä¸ºçœŸå®äº¤æ˜“ä»·æ ¼

                if real_price <= price_min or real_price > price_max:
                    # ä»·æ ¼ä¸åœ¨æŒ‡å®šåŒºé—´å†…ï¼Œå‰”é™¤è¯¥è‚¡ç¥¨
                    continue
            except Exception as e:
                # è·å–ä»·æ ¼æ•°æ®å¤±è´¥ï¼Œå‰”é™¤è¯¥è‚¡ç¥¨
                logger.debug(f"è·å–è‚¡ç¥¨ {stock_code} ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
                continue

            # åœç‰Œè¿‡æ»¤ï¼ˆéœ€è¦å®é™…å¸‚åœºæ•°æ®ï¼Œè¿™é‡Œç®€åŒ–è·³è¿‡ï¼‰
            # æˆäº¤é¢è¿‡æ»¤ï¼ˆéœ€è¦å®é™…å¸‚åœºæ•°æ®ï¼Œè¿™é‡Œç®€åŒ–è·³è¿‡ï¼‰

            valid_stocks.append((stock_code, score))

        if len(valid_stocks) == 0:
            logger.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            return pd.Series(dtype=float)

        # æŒ‰è¯„åˆ†æ’åºå¹¶é€‰æ‹©Top K
        valid_stocks.sort(key=lambda x: x[1], reverse=True)
        selected_stocks = valid_stocks[:min(topk, len(valid_stocks))]

        if len(selected_stocks) == 0:
            return pd.Series(dtype=float)

        # è®¡ç®—æƒé‡
        stocks = [s[0] for s in selected_stocks]
        scores = pd.Series([s[1] for s in selected_stocks], index=stocks)

        # æ ¹æ®æƒé‡æ–¹æ³•åˆ†é…æƒé‡
        if weight_method == 'equal':
            # ç­‰æƒé‡åˆ†é…
            weights = np.repeat(1.0/len(stocks), len(stocks))
            return pd.Series(weights, index=stocks)

        elif weight_method == 'score':
            # åŸºäºsoftmaxè¯„åˆ†çš„æƒé‡åˆ†é…
            if len(scores) == 1:
                weights = np.array([1.0])
            else:
                # ä½¿ç”¨softmaxé£æ ¼çš„æƒé‡åˆ†é…
                exp_scores = np.exp(scores.values * 2)  # æ”¾å¤§å·®å¼‚
                weights = exp_scores / exp_scores.sum()

            # é™åˆ¶å•åªè‚¡ç¥¨æœ€å¤§æƒé‡
            max_weight = 0.15  # 15%
            weights = np.minimum(weights, max_weight)

            # é‡æ–°å½’ä¸€åŒ–
            if weights.sum() > 0:
                weights = weights / weights.sum()
            else:
                weights = np.repeat(1.0/len(weights), len(weights))

            return pd.Series(weights, index=stocks)

        elif weight_method == 'risk_opt':
            # é£é™©ä¼˜åŒ–æƒé‡åˆ†é…
            # å…ˆç”¨softmaxå¾—åˆ°åˆå§‹æƒé‡
            if len(scores) == 1:
                w0 = pd.Series([1.0], index=stocks)
            else:
                exp_scores = np.exp(scores.values * 2)
                w0_values = exp_scores / exp_scores.sum()
                w0 = pd.Series(w0_values, index=stocks)

            # è°ƒç”¨é£é™©ä¼˜åŒ–å‡½æ•°
            optimized_weights = self.optimize_weights_risk(w0, scores, prev_weights, date)
            return optimized_weights

        else:
            # é»˜è®¤ç­‰æƒé‡
            logger.warning(f"æœªçŸ¥æƒé‡æ–¹æ³• {weight_method}ï¼Œä½¿ç”¨ç­‰æƒé‡")
            weights = np.repeat(1.0/len(stocks), len(stocks))
            return pd.Series(weights, index=stocks)

    def optimize_portfolio(self, pred_scores: pd.Series, prev_weights: Optional[pd.Series] = None,
                          max_turnover: float = 0.8, max_position: float = 0.15) -> pd.Series:
        """
        ç»„åˆä¼˜åŒ–ï¼šä½¿ç”¨cvxpyæ±‚è§£æœ€ä¼˜æƒé‡

        Args:
            pred_scores: é¢„æµ‹è¯„åˆ†
            prev_weights: å‰æœŸæƒé‡
            max_turnover: æœ€å¤§æ¢æ‰‹ç‡
            max_position: å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½

        Returns:
            pd.Series: ä¼˜åŒ–åçš„æƒé‡
        """
        try:
            import cvxpy as cp

            n_stocks = len(pred_scores)
            if n_stocks == 0:
                return pd.Series(dtype=float)

            # å˜é‡å®šä¹‰
            w = cp.Variable(n_stocks)

            # ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–é¢„æœŸæ”¶ç›Š
            objective = cp.Maximize(pred_scores.values @ w)

            # çº¦æŸæ¡ä»¶
            constraints = [
                w >= 0,  # ä¸å…è®¸åšç©º
                cp.sum(w) == 1,  # æƒé‡å’Œä¸º1
                w <= max_position,  # å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½
            ]

            # æ¢æ‰‹ç‡çº¦æŸ
            if prev_weights is not None:
                # å¯¹é½è‚¡ç¥¨
                aligned_prev = pd.Series(0.0, index=pred_scores.index)
                common_stocks = set(prev_weights.index) & set(pred_scores.index)
                for stock in common_stocks:
                    aligned_prev[stock] = prev_weights[stock]

                turnover = cp.sum(cp.abs(w - aligned_prev.values))
                constraints.append(turnover <= max_turnover)

            # æ±‚è§£
            problem = cp.Problem(objective, constraints)
            problem.solve(solver=cp.ECOS, verbose=False)

            if problem.status == cp.OPTIMAL:
                optimal_weights = w.value
                if optimal_weights is not None and len(optimal_weights) > 0:
                    # ç¡®ä¿æƒé‡éè´Ÿä¸”å½’ä¸€åŒ–
                    optimal_weights = np.maximum(optimal_weights, 0)
                    if optimal_weights.sum() > 0:
                        optimal_weights = optimal_weights / optimal_weights.sum()
                        return pd.Series(optimal_weights, index=pred_scores.index)

            logger.warning("ä¼˜åŒ–æ±‚è§£å¤±è´¥ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")

        except ImportError:
            logger.warning("CVXPYæœªå®‰è£…ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")
        except Exception as e:
            logger.warning(f"ç»„åˆä¼˜åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")

        # å›é€€åˆ°ç­‰æƒé‡
        n_stocks = len(pred_scores)
        equal_weights = np.repeat(1.0/n_stocks, n_stocks)
        return pd.Series(equal_weights, index=pred_scores.index)

    def optimize_weights_risk(self, w0: pd.Series, scores: pd.Series,
                             prev_weights: Optional[pd.Series] = None,
                             date: pd.Timestamp = None) -> pd.Series:
        """
        åŸºäºé£é™©æ§åˆ¶çš„æƒé‡ä¼˜åŒ–

        Args:
            w0: åˆå§‹æƒé‡ (softmax)
            scores: é¢„æµ‹è¯„åˆ†
            prev_weights: å‰æœŸæƒé‡ (å¯é€‰)
            date: å½“å‰æ—¥æœŸ

        Returns:
            pd.Series: ä¼˜åŒ–åçš„æƒé‡
        """
        try:
            import cvxpy as cp

            n_stocks = len(w0)
            if n_stocks == 0:
                return pd.Series(dtype=float)

            # 1. è·å–è¿‡å»60ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·æ•°æ®ï¼Œè®¡ç®—åæ–¹å·®çŸ©é˜µ
            try:
                # è·å–äº¤æ˜“æ—¥å†
                calendar = D.calendar()
                if date is None:
                    end_date = calendar[-1]
                else:
                    end_date = date

                # è·å–è¿‡å»60ä¸ªäº¤æ˜“æ—¥
                end_idx = calendar.get_loc(end_date) if end_date in calendar else len(calendar) - 1
                start_idx = max(0, end_idx - 59)  # 60å¤©æ•°æ®
                start_date = calendar[start_idx]

                logger.info(f"è·å– {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')} çš„ä»·æ ¼æ•°æ®")

                # è·å–è‚¡ç¥¨ä»·æ ¼æ•°æ®
                stock_list = list(w0.index)
                price_data = D.features(stock_list, ['$close'],
                                      start_time=start_date, end_time=end_date)

                if price_data.empty:
                    logger.warning("æ— æ³•è·å–ä»·æ ¼æ•°æ®ï¼Œå›é€€åˆ°softmaxæ–¹æ³•")
                    return self._fallback_to_softmax(scores)

                # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡
                returns_data = []
                for stock in stock_list:
                    try:
                        stock_prices = price_data.loc[pd.IndexSlice[:, stock], :]
                        if len(stock_prices) < 2:
                            continue

                        prices = stock_prices['$close'].values
                        # å»é™¤NaNå€¼
                        prices = prices[~np.isnan(prices)]
                        if len(prices) < 2:
                            continue

                        # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡
                        log_returns = np.diff(np.log(prices))
                        if len(log_returns) > 0:
                            returns_data.append(pd.Series(log_returns, name=stock))
                    except Exception as e:
                        logger.debug(f"å¤„ç†è‚¡ç¥¨ {stock} æ”¶ç›Šç‡å¤±è´¥: {e}")
                        continue

                if len(returns_data) < 2:
                    logger.warning("æœ‰æ•ˆæ”¶ç›Šç‡æ•°æ®ä¸è¶³ï¼Œå›é€€åˆ°softmaxæ–¹æ³•")
                    return self._fallback_to_softmax(scores)

                # æ„å»ºæ”¶ç›Šç‡çŸ©é˜µ
                returns_df = pd.concat(returns_data, axis=1)
                returns_df = returns_df.fillna(0)  # å¡«å……ç¼ºå¤±å€¼ä¸º0

                # ç¡®ä¿è‚¡ç¥¨é¡ºåºä¸€è‡´
                common_stocks = list(set(returns_df.columns) & set(w0.index))
                if len(common_stocks) < 2:
                    logger.warning("å…±åŒè‚¡ç¥¨æ•°é‡ä¸è¶³ï¼Œå›é€€åˆ°softmaxæ–¹æ³•")
                    return self._fallback_to_softmax(scores)

                returns_df = returns_df[common_stocks]
                w0_aligned = w0.loc[common_stocks]
                scores_aligned = scores.loc[common_stocks]

                # è®¡ç®—åæ–¹å·®çŸ©é˜µ
                cov_matrix = returns_df.cov().values

                # ç¡®ä¿åæ–¹å·®çŸ©é˜µæ˜¯æ­£å®šçš„
                eigenvals, eigenvecs = np.linalg.eigh(cov_matrix)
                eigenvals = np.maximum(eigenvals, 1e-8)  # ç¡®ä¿æ­£å®š
                cov_matrix = eigenvecs @ np.diag(eigenvals) @ eigenvecs.T

            except Exception as e:
                logger.warning(f"è®¡ç®—åæ–¹å·®çŸ©é˜µå¤±è´¥: {e}ï¼Œå›é€€åˆ°softmaxæ–¹æ³•")
                return self._fallback_to_softmax(scores)

            # 2. ä½¿ç”¨cvxpyå»ºæ¨¡
            try:
                n = len(common_stocks)
                w = cp.Variable(n)

                # ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–é¢„æœŸæ”¶ç›Š
                objective = cp.Maximize(scores_aligned.values @ w)

                # çº¦æŸæ¡ä»¶
                constraints = [
                    cp.sum(w) == 1,                    # æƒé‡å’Œä¸º1
                    w >= 0,                            # ä¸å…è®¸åšç©º
                    w <= 0.15,                         # å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½15%
                ]

                # é£é™©çº¦æŸï¼šæ—¥æ³¢åŠ¨ç‡çº¦ç­‰äºå¹´åŒ–15%
                # ç›®æ ‡æ—¥æ–¹å·®: (0.15/âˆš252)Â²
                target_daily_var = (0.15 / np.sqrt(252)) ** 2
                risk_constraint = cp.quad_form(w, cov_matrix) <= target_daily_var
                constraints.append(risk_constraint)

                # æ¢æ‰‹ç‡çº¦æŸ
                if prev_weights is not None:
                    # å¯¹é½å‰æœŸæƒé‡
                    aligned_prev = pd.Series(0.0, index=common_stocks)
                    for stock in common_stocks:
                        if stock in prev_weights.index:
                            aligned_prev[stock] = prev_weights[stock]

                    turnover_constraint = cp.sum(cp.abs(w - aligned_prev.values)) <= 0.8
                    constraints.append(turnover_constraint)

                # æ±‚è§£ä¼˜åŒ–é—®é¢˜
                problem = cp.Problem(objective, constraints)
                problem.solve(solver=cp.ECOS, verbose=False)

                if problem.status == cp.OPTIMAL:
                    optimal_weights = w.value
                    if optimal_weights is not None and len(optimal_weights) > 0:
                        # ç¡®ä¿æƒé‡éè´Ÿä¸”å½’ä¸€åŒ–
                        optimal_weights = np.maximum(optimal_weights, 0)
                        if optimal_weights.sum() > 0:
                            optimal_weights = optimal_weights / optimal_weights.sum()

                            # åˆ›å»ºå®Œæ•´çš„æƒé‡Seriesï¼ŒæœªåŒ…å«çš„è‚¡ç¥¨æƒé‡ä¸º0
                            full_weights = pd.Series(0.0, index=w0.index)
                            full_weights.loc[common_stocks] = optimal_weights

                            logger.info(f"é£é™©ä¼˜åŒ–æˆåŠŸï¼Œç»„åˆé£é™©: {np.sqrt(optimal_weights @ cov_matrix @ optimal_weights * 252):.4f}")
                            return full_weights

                logger.warning("ä¼˜åŒ–æ±‚è§£å¤±è´¥ï¼Œå›é€€åˆ°softmaxæ–¹æ³•")

            except Exception as e:
                logger.warning(f"cvxpyä¼˜åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°softmaxæ–¹æ³•")

        except ImportError:
            logger.warning("CVXPYæœªå®‰è£…ï¼Œå›é€€åˆ°softmaxæ–¹æ³•")
        except Exception as e:
            logger.warning(f"é£é™©ä¼˜åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°softmaxæ–¹æ³•")

        # å›é€€åˆ°softmaxæ–¹æ³•
        return self._fallback_to_softmax(scores)

    def _fallback_to_softmax(self, scores: pd.Series) -> pd.Series:
        """å›é€€åˆ°softmaxæƒé‡åˆ†é…"""
        if len(scores) == 1:
            return pd.Series([1.0], index=scores.index)

        # å¦‚æœè‚¡ç¥¨æ•°é‡å¾ˆå°‘ï¼Œç›´æ¥ä½¿ç”¨ç­‰æƒé‡é¿å…å•åªè‚¡ç¥¨æƒé‡è¿‡é«˜
        if len(scores) <= 7:  # 7åªè‚¡ç¥¨æ—¶æ¯åªæœ€å¤šçº¦14.3%
            equal_weights = np.repeat(1.0/len(scores), len(scores))
            return pd.Series(equal_weights, index=scores.index)

        # å¯¹äºæ›´å¤šè‚¡ç¥¨ï¼Œä½¿ç”¨softmaxæƒé‡åˆ†é…
        exp_scores = np.exp(scores.values * 2)
        weights = exp_scores / exp_scores.sum()

        # é™åˆ¶å•åªè‚¡ç¥¨æœ€å¤§æƒé‡
        max_weight = 0.15
        weights = np.minimum(weights, max_weight)

        # é‡æ–°å½’ä¸€åŒ–
        if weights.sum() > 0:
            weights = weights / weights.sum()
        else:
            weights = np.repeat(1.0/len(weights), len(weights))

        return pd.Series(weights, index=scores.index)

    def is_trading_time(self, current_time: datetime = None) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¶é—´

        Args:
            current_time: å½“å‰æ—¶é—´ï¼Œé»˜è®¤ä¸ºNoneåˆ™ä½¿ç”¨å½“å‰æ—¶é—´

        Returns:
            bool: æ˜¯å¦ä¸ºäº¤æ˜“æ—¶é—´
        """
        if current_time is None:
            current_time = datetime.now()

        # æ£€æŸ¥æ˜¯å¦ä¸ºå·¥ä½œæ—¥ï¼ˆå‘¨ä¸€åˆ°å‘¨äº”ï¼‰
        if current_time.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
            return False

        # è§£æäº¤æ˜“æ—¶æ®µ
        trade_periods = []
        for period in self.trade_hours.split(','):
            start_str, end_str = period.strip().split('-')
            start_time = datetime.strptime(f"{current_time.date()} {start_str}", "%Y-%m-%d %H:%M")
            end_time = datetime.strptime(f"{current_time.date()} {end_str}", "%Y-%m-%d %H:%M")
            trade_periods.append((start_time, end_time))

        # æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦åœ¨ä»»ä¸€äº¤æ˜“æ—¶æ®µå†…
        for start_time, end_time in trade_periods:
            if start_time <= current_time <= end_time:
                return True

        return False

    def is_trading_day(self, date: datetime = None) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼ˆæ’é™¤èŠ‚å‡æ—¥ï¼‰

        Args:
            date: æ—¥æœŸï¼Œé»˜è®¤ä¸ºNoneåˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ

        Returns:
            bool: æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        """
        if date is None:
            date = datetime.now()

        # åŸºæœ¬åˆ¤æ–­ï¼šå·¥ä½œæ—¥
        if date.weekday() >= 5:
            return False

        # Aè‚¡ä¸»è¦èŠ‚å‡æ—¥ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥ä½¿ç”¨æ›´å®Œæ•´çš„èŠ‚å‡æ—¥æ•°æ®ï¼‰
        year = date.year
        holidays = [
            # å…ƒæ—¦
            datetime(year, 1, 1),
            # æ˜¥èŠ‚ï¼ˆå‡è®¾2æœˆä¸­æ—¬å‰åä¸€å‘¨ï¼Œå®é™…éœ€è¦æ ¹æ®å½“å¹´æƒ…å†µè°ƒæ•´ï¼‰
            datetime(year, 2, 10), datetime(year, 2, 11), datetime(year, 2, 12),
            datetime(year, 2, 13), datetime(year, 2, 14), datetime(year, 2, 15), datetime(year, 2, 16),
            # æ¸…æ˜èŠ‚ï¼ˆå‡è®¾4æœˆ5æ—¥å‰åï¼‰
            datetime(year, 4, 5),
            # åŠ³åŠ¨èŠ‚
            datetime(year, 5, 1), datetime(year, 5, 2), datetime(year, 5, 3),
            # å›½åº†èŠ‚
            datetime(year, 10, 1), datetime(year, 10, 2), datetime(year, 10, 3),
            datetime(year, 10, 4), datetime(year, 10, 5), datetime(year, 10, 6), datetime(year, 10, 7),
        ]

        # æ£€æŸ¥æ˜¯å¦ä¸ºèŠ‚å‡æ—¥
        date_only = datetime(date.year, date.month, date.day)
        return date_only not in holidays

    def get_realtime_quotes(self, stock_codes: List[str], retry_times: int = 3) -> Dict[str, Dict]:
        """
        è·å–å®æ—¶è¡Œæƒ…æ•°æ®

        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            retry_times: é‡è¯•æ¬¡æ•°

        Returns:
            Dict: è‚¡ç¥¨å®æ—¶è¡Œæƒ…æ•°æ®
        """
        quotes = {}

        for retry in range(retry_times):
            try:
                import akshare as ak

                # è·å–å®æ—¶è¡Œæƒ…
                for stock_code in stock_codes:
                    try:
                        # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
                        if stock_code.startswith('SH'):
                            ak_code = stock_code[2:]
                        elif stock_code.startswith('SZ'):
                            ak_code = stock_code[2:]
                        else:
                            ak_code = stock_code

                        # è·å–å®æ—¶ä»·æ ¼
                        realtime_data = ak.stock_zh_a_spot_em()
                        stock_data = realtime_data[realtime_data['ä»£ç '] == ak_code]

                        if not stock_data.empty:
                            row = stock_data.iloc[0]
                            quotes[stock_code] = {
                                'current_price': float(row['æœ€æ–°ä»·']),
                                'volume': int(row['æˆäº¤é‡']),
                                'amount': float(row['æˆäº¤é¢']),
                                'high': float(row['æœ€é«˜']),
                                'low': float(row['æœ€ä½']),
                                'open': float(row['ä»Šå¼€']),
                                'prev_close': float(row['æ˜¨æ”¶']),
                                'change_pct': float(row['æ¶¨è·Œå¹…']),
                                'timestamp': datetime.now()
                            }
                        else:
                            logger.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„å®æ—¶æ•°æ®")

                    except Exception as e:
                        logger.warning(f"è·å–è‚¡ç¥¨ {stock_code} å®æ—¶æ•°æ®å¤±è´¥: {e}")
                        continue

                # å¦‚æœæˆåŠŸè·å–åˆ°æ•°æ®ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                if quotes:
                    break

            except Exception as e:
                logger.warning(f"è·å–å®æ—¶è¡Œæƒ…å¤±è´¥ï¼ˆç¬¬{retry+1}æ¬¡å°è¯•ï¼‰: {e}")
                if retry < retry_times - 1:
                    import time
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                else:
                    logger.error("è·å–å®æ—¶è¡Œæƒ…å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")

        return quotes

    def live_trade(self):
        """å¯åŠ¨å®æ—¶äº¤æ˜“æ¨¡æ‹Ÿ"""
        logger.info("ğŸš€ å¯åŠ¨å®æ—¶äº¤æ˜“æ¨¡æ‹Ÿ...")
        logger.info(f"ğŸ“‹ é…ç½®: åˆå§‹èµ„é‡‘={self.capital}, é€‰è‚¡æ•°é‡={self.topk}, è½®è¯¢é—´éš”={self.interval}ç§’")
        logger.info(f"â° äº¤æ˜“æ—¶æ®µ: {self.trade_hours}")

        # åˆå§‹åŒ–Qlib
        try:
            D.calendar()
        except:
            self._init_qlib()

        # åŠ è½½æ¨¡å‹
        self._load_models()

        # åˆå§‹åŒ–äº¤æ˜“çŠ¶æ€
        portfolio = {}  # {stock_code: quantity}
        cash = self.capital
        last_nav = self.capital

        # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶
        output_path = Path(self.config['output_path'])
        trade_log_file = output_path / 'trade_log.csv'
        portfolio_nav_file = output_path / 'portfolio_nav.csv'

        # åˆ›å»ºCSVè¡¨å¤´
        if not trade_log_file.exists():
            with open(trade_log_file, 'w') as f:
                f.write('date,time,code,price,qty,action,cash,position_value\n')

        if not portfolio_nav_file.exists():
            with open(portfolio_nav_file, 'w') as f:
                f.write('date,time,nav,drawdown,turnover,cash,position_value\n')

        logger.info("ğŸ“Š å¼€å§‹äº¤æ˜“å¾ªç¯...")

        import time
        max_nav = self.capital

        try:
            while True:
                current_time = datetime.now()

                # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¶é—´
                if not self.is_trading_day(current_time) or not self.is_trading_time(current_time):
                    logger.info(f"â¸ï¸  {current_time.strftime('%Y-%m-%d %H:%M:%S')} ä¼‘å¸‚ï¼Œç­‰å¾…å¼€ç›˜...")
                    time.sleep(self.interval)
                    continue

                logger.info(f"ğŸ”„ {current_time.strftime('%Y-%m-%d %H:%M:%S')} å¼€å§‹äº¤æ˜“å¾ªç¯...")

                try:
                    # 1. ç”Ÿæˆé¢„æµ‹ä¿¡å·
                    predictions = self.predict()
                    if not predictions:
                        logger.warning("æ²¡æœ‰é¢„æµ‹ç»“æœï¼Œè·³è¿‡æœ¬è½®")
                        time.sleep(self.interval)
                        continue

                    # é€‰æ‹©æœ€ä½³é¢„æµ‹
                    if 'ensemble' in predictions:
                        pred_score = predictions['ensemble']
                    elif predictions:
                        pred_score = list(predictions.values())[0]
                    else:
                        logger.warning("æ²¡æœ‰å¯ç”¨é¢„æµ‹ç»“æœ")
                        time.sleep(self.interval)
                        continue

                    # è·å–æœ€æ–°æ—¥æœŸçš„é¢„æµ‹
                    latest_date = pred_score.index.get_level_values(0).max()
                    latest_predictions = pred_score.loc[latest_date].dropna()

                    if len(latest_predictions) == 0:
                        logger.warning("æ²¡æœ‰æœ€æ–°é¢„æµ‹æ•°æ®")
                        time.sleep(self.interval)
                        continue

                    # 2. é€‰è‚¡
                    target_weights = self.select_stocks(
                        latest_predictions, self.topk, latest_date,
                        self.price_min, self.price_max,
                        weight_method=self.weight_method
                    )

                    if len(target_weights) == 0:
                        logger.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
                        time.sleep(self.interval)
                        continue

                    # 3. è·å–å®æ—¶è¡Œæƒ…
                    stock_codes = list(target_weights.index)
                    current_quotes = self.get_realtime_quotes(stock_codes)

                    if not current_quotes:
                        logger.warning("æ— æ³•è·å–å®æ—¶è¡Œæƒ…")
                        time.sleep(self.interval)
                        continue

                    # 4. è®¡ç®—å½“å‰æŒä»“ä»·å€¼
                    position_value = 0
                    for stock_code, quantity in portfolio.items():
                        if stock_code in current_quotes:
                            position_value += quantity * current_quotes[stock_code]['current_price']

                    total_value = cash + position_value
                    current_nav = total_value

                    # 5. æ‰§è¡Œäº¤æ˜“
                    turnover = self._execute_trades(
                        target_weights, current_quotes, portfolio, cash, total_value,
                        trade_log_file, current_time
                    )

                    # æ›´æ–°ç°é‡‘å’ŒæŒä»“
                    cash, position_value = self._update_portfolio_status(portfolio, current_quotes, cash)
                    current_nav = cash + position_value

                    # 6. è®¡ç®—å›æ’¤
                    max_nav = max(max_nav, current_nav)
                    drawdown = (current_nav - max_nav) / max_nav if max_nav > 0 else 0

                    # 7. è®°å½•æŠ•èµ„ç»„åˆå‡€å€¼
                    with open(portfolio_nav_file, 'a') as f:
                        f.write(f"{current_time.strftime('%Y-%m-%d')},{current_time.strftime('%H:%M:%S')},"
                               f"{current_nav:.2f},{drawdown:.4f},{turnover:.4f},{cash:.2f},{position_value:.2f}\n")

                    # 8. è¾“å‡ºçŠ¶æ€
                    logger.info(f"ğŸ’° å‡€å€¼: {current_nav:.2f}, ç°é‡‘: {cash:.2f}, æŒä»“: {position_value:.2f}")
                    logger.info(f"ğŸ“ˆ å›æ’¤: {drawdown:.2%}, æ¢æ‰‹ç‡: {turnover:.2f}")

                    last_nav = current_nav

                except Exception as e:
                    logger.error(f"äº¤æ˜“å¾ªç¯å‡ºé”™: {e}")

                # ç­‰å¾…ä¸‹ä¸€è½®
                time.sleep(self.interval)

        except KeyboardInterrupt:
            logger.info("ğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºå®æ—¶äº¤æ˜“...")
        except Exception as e:
            logger.error(f"å®æ—¶äº¤æ˜“å¼‚å¸¸é€€å‡º: {e}")

        logger.info("ğŸ å®æ—¶äº¤æ˜“ç»“æŸ")

    def _execute_trades(self, target_weights: pd.Series, current_quotes: Dict,
                       portfolio: Dict, cash: float, total_value: float,
                       trade_log_file: Path, current_time: datetime) -> float:
        """
        æ‰§è¡Œäº¤æ˜“

        Returns:
            float: æ¢æ‰‹ç‡
        """
        turnover = 0.0

        # è®¡ç®—ç›®æ ‡æŒä»“æ•°é‡
        target_positions = {}
        for stock_code, weight in target_weights.items():
            if stock_code in current_quotes:
                # å®ç›˜çº¦æŸï¼šå•è‚¡æƒé‡é™åˆ¶20%
                actual_weight = min(weight, 0.20)
                target_value = total_value * actual_weight
                current_price = current_quotes[stock_code]['current_price']
                target_qty = int(target_value / current_price / 100) * 100  # æ•´æ‰‹äº¤æ˜“
                target_positions[stock_code] = target_qty

        # å–å‡ºä¸åœ¨ç›®æ ‡æŒä»“ä¸­çš„è‚¡ç¥¨
        stocks_to_sell = set(portfolio.keys()) - set(target_positions.keys())
        for stock_code in stocks_to_sell:
            if portfolio[stock_code] > 0 and stock_code in current_quotes:
                self._execute_sell(stock_code, portfolio[stock_code], current_quotes[stock_code],
                                 portfolio, trade_log_file, current_time)
                turnover += portfolio[stock_code] * current_quotes[stock_code]['current_price'] / total_value

        # è°ƒæ•´æŒä»“
        for stock_code, target_qty in target_positions.items():
            current_qty = portfolio.get(stock_code, 0)
            qty_diff = target_qty - current_qty

            if abs(qty_diff) >= 100:  # æœ€å°äº¤æ˜“å•ä½100è‚¡
                if qty_diff > 0:
                    # ä¹°å…¥
                    self._execute_buy(stock_code, qty_diff, current_quotes[stock_code],
                                    portfolio, trade_log_file, current_time)
                else:
                    # å–å‡º
                    self._execute_sell(stock_code, -qty_diff, current_quotes[stock_code],
                                     portfolio, trade_log_file, current_time)

                turnover += abs(qty_diff) * current_quotes[stock_code]['current_price'] / total_value

        return turnover

    def _execute_buy(self, stock_code: str, quantity: int, quote: Dict,
                    portfolio: Dict, trade_log_file: Path, current_time: datetime):
        """æ‰§è¡Œä¹°å…¥æ“ä½œ"""
        price = quote['current_price']
        trade_value = quantity * price

        # è®¡ç®—äº¤æ˜“è´¹ç”¨ï¼ˆä¹°å…¥0.0002ï¼‰
        commission = trade_value * 0.0002
        total_cost = trade_value + commission

        # æ›´æ–°æŒä»“
        portfolio[stock_code] = portfolio.get(stock_code, 0) + quantity

        # è®°å½•äº¤æ˜“
        with open(trade_log_file, 'a') as f:
            position_value = sum(portfolio.get(code, 0) * quote['current_price']
                               for code in portfolio.keys())
            f.write(f"{current_time.strftime('%Y-%m-%d')},{current_time.strftime('%H:%M:%S')},"
                   f"{stock_code},{price:.2f},{quantity},BUY,{total_cost:.2f},{position_value:.2f}\n")

        logger.info(f"ğŸŸ¢ ä¹°å…¥ {stock_code}: {quantity}è‚¡ @ {price:.2f}å…ƒ, è´¹ç”¨: {commission:.2f}å…ƒ")

    def _execute_sell(self, stock_code: str, quantity: int, quote: Dict,
                     portfolio: Dict, trade_log_file: Path, current_time: datetime):
        """æ‰§è¡Œå–å‡ºæ“ä½œ"""
        price = quote['current_price']
        trade_value = quantity * price

        # è®¡ç®—äº¤æ˜“è´¹ç”¨ï¼ˆå–å‡º0.0005ï¼‰
        commission = trade_value * 0.0005
        net_proceeds = trade_value - commission

        # æ›´æ–°æŒä»“
        portfolio[stock_code] = portfolio.get(stock_code, 0) - quantity
        if portfolio[stock_code] <= 0:
            del portfolio[stock_code]

        # è®°å½•äº¤æ˜“
        with open(trade_log_file, 'a') as f:
            position_value = sum(portfolio.get(code, 0) * quote['current_price']
                               for code in portfolio.keys())
            f.write(f"{current_time.strftime('%Y-%m-%d')},{current_time.strftime('%H:%M:%S')},"
                   f"{stock_code},{price:.2f},{quantity},SELL,{net_proceeds:.2f},{position_value:.2f}\n")

        logger.info(f"ğŸ”´ å–å‡º {stock_code}: {quantity}è‚¡ @ {price:.2f}å…ƒ, è´¹ç”¨: {commission:.2f}å…ƒ")

    def _update_portfolio_status(self, portfolio: Dict, current_quotes: Dict, cash: float) -> Tuple[float, float]:
        """æ›´æ–°æŠ•èµ„ç»„åˆçŠ¶æ€"""
        position_value = 0
        for stock_code, quantity in portfolio.items():
            if stock_code in current_quotes:
                position_value += quantity * current_quotes[stock_code]['current_price']

        return cash, position_value

    def visualize_live_trade(self, output_file: str = None):
        """
        å¯è§†åŒ–å®æ—¶äº¤æ˜“ç»“æœ

        Args:
            output_file: è¾“å‡ºHTMLæ–‡ä»¶åï¼Œé»˜è®¤Noneè‡ªåŠ¨ç”Ÿæˆ
        """
        try:
            import plotly.graph_objects as go
            from plotly.subplots import make_subplots

            output_path = Path(self.config['output_path'])
            trade_log_file = output_path / 'trade_log.csv'
            portfolio_nav_file = output_path / 'portfolio_nav.csv'

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not trade_log_file.exists() or not portfolio_nav_file.exists():
                logger.error("äº¤æ˜“æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œå®æ—¶äº¤æ˜“")
                return

            # è¯»å–æ•°æ®
            try:
                trade_log = pd.read_csv(trade_log_file)
                portfolio_nav = pd.read_csv(portfolio_nav_file)
            except Exception as e:
                logger.error(f"è¯»å–äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
                return

            if trade_log.empty or portfolio_nav.empty:
                logger.warning("äº¤æ˜“æ•°æ®ä¸ºç©º")
                return

            # æ•°æ®é¢„å¤„ç†
            portfolio_nav['datetime'] = pd.to_datetime(portfolio_nav['date'] + ' ' + portfolio_nav['time'])
            trade_log['datetime'] = pd.to_datetime(trade_log['date'] + ' ' + trade_log['time'])

            # åˆ›å»ºå­å›¾
            fig = make_subplots(
                rows=3, cols=2,
                subplot_titles=[
                    'æŠ•èµ„ç»„åˆå‡€å€¼æ›²çº¿', 'å›æ’¤æ›²çº¿',
                    'æŒä»“åˆ†å¸ƒ', 'äº¤æ˜“æµæ°´',
                    'ç°é‡‘vsæŒä»“ä»·å€¼', 'æ¢æ‰‹ç‡'
                ],
                specs=[
                    [{"secondary_y": False}, {"secondary_y": False}],
                    [{"type": "bar"}, {"type": "scatter"}],
                    [{"secondary_y": False}, {"secondary_y": False}]
                ],
                vertical_spacing=0.08,
                horizontal_spacing=0.05
            )

            # 1. æŠ•èµ„ç»„åˆå‡€å€¼æ›²çº¿
            fig.add_trace(
                go.Scatter(
                    x=portfolio_nav['datetime'],
                    y=portfolio_nav['nav'],
                    mode='lines',
                    name='å‡€å€¼',
                    line=dict(color='#2ca02c', width=2),
                    hovertemplate='æ—¶é—´: %{x}<br>å‡€å€¼: Â¥%{y:.2f}<extra></extra>'
                ),
                row=1, col=1
            )

            # 2. å›æ’¤æ›²çº¿
            fig.add_trace(
                go.Scatter(
                    x=portfolio_nav['datetime'],
                    y=portfolio_nav['drawdown'] * 100,
                    mode='lines',
                    name='å›æ’¤',
                    line=dict(color='#d62728', width=2),
                    fill='tonegative',
                    fillcolor='rgba(214, 39, 40, 0.2)',
                    hovertemplate='æ—¶é—´: %{x}<br>å›æ’¤: %{y:.2f}%<extra></extra>'
                ),
                row=1, col=2
            )

            # 3. æŒä»“åˆ†å¸ƒï¼ˆæœ€æ–°ï¼‰
            if not trade_log.empty:
                # è®¡ç®—æœ€æ–°æŒä»“
                latest_positions = {}
                for _, trade in trade_log.iterrows():
                    stock_code = trade['code']
                    if trade['action'] == 'BUY':
                        latest_positions[stock_code] = latest_positions.get(stock_code, 0) + trade['qty']
                    elif trade['action'] == 'SELL':
                        latest_positions[stock_code] = latest_positions.get(stock_code, 0) - trade['qty']

                # è¿‡æ»¤æ‰é›¶æŒä»“
                latest_positions = {k: v for k, v in latest_positions.items() if v > 0}

                if latest_positions:
                    fig.add_trace(
                        go.Bar(
                            x=list(latest_positions.keys()),
                            y=list(latest_positions.values()),
                            name='æŒä»“æ•°é‡',
                            marker_color='#1f77b4',
                            hovertemplate='è‚¡ç¥¨: %{x}<br>æ•°é‡: %{y}è‚¡<extra></extra>'
                        ),
                        row=2, col=1
                    )

            # 4. äº¤æ˜“æµæ°´ï¼ˆä¹°å–ç‚¹ï¼‰
            buy_trades = trade_log[trade_log['action'] == 'BUY']
            sell_trades = trade_log[trade_log['action'] == 'SELL']

            if not buy_trades.empty:
                fig.add_trace(
                    go.Scatter(
                        x=buy_trades['datetime'],
                        y=buy_trades['price'],
                        mode='markers',
                        name='ä¹°å…¥',
                        marker=dict(color='#2ca02c', size=8, symbol='triangle-up'),
                        hovertemplate='æ—¶é—´: %{x}<br>è‚¡ç¥¨: %{customdata}<br>ä»·æ ¼: Â¥%{y:.2f}<extra></extra>',
                        customdata=buy_trades['code']
                    ),
                    row=2, col=2
                )

            if not sell_trades.empty:
                fig.add_trace(
                    go.Scatter(
                        x=sell_trades['datetime'],
                        y=sell_trades['price'],
                        mode='markers',
                        name='å–å‡º',
                        marker=dict(color='#d62728', size=8, symbol='triangle-down'),
                        hovertemplate='æ—¶é—´: %{x}<br>è‚¡ç¥¨: %{customdata}<br>ä»·æ ¼: Â¥%{y:.2f}<extra></extra>',
                        customdata=sell_trades['code']
                    ),
                    row=2, col=2
                )

            # 5. ç°é‡‘vsæŒä»“ä»·å€¼
            fig.add_trace(
                go.Scatter(
                    x=portfolio_nav['datetime'],
                    y=portfolio_nav['cash'],
                    mode='lines',
                    name='ç°é‡‘',
                    line=dict(color='#ff7f0e', width=2),
                    hovertemplate='æ—¶é—´: %{x}<br>ç°é‡‘: Â¥%{y:.2f}<extra></extra>'
                ),
                row=3, col=1
            )

            fig.add_trace(
                go.Scatter(
                    x=portfolio_nav['datetime'],
                    y=portfolio_nav['position_value'],
                    mode='lines',
                    name='æŒä»“ä»·å€¼',
                    line=dict(color='#9467bd', width=2),
                    hovertemplate='æ—¶é—´: %{x}<br>æŒä»“ä»·å€¼: Â¥%{y:.2f}<extra></extra>'
                ),
                row=3, col=1
            )

            # 6. æ¢æ‰‹ç‡
            fig.add_trace(
                go.Scatter(
                    x=portfolio_nav['datetime'],
                    y=portfolio_nav['turnover'],
                    mode='lines+markers',
                    name='æ¢æ‰‹ç‡',
                    line=dict(color='#8c564b', width=2),
                    hovertemplate='æ—¶é—´: %{x}<br>æ¢æ‰‹ç‡: %{y:.2f}<extra></extra>'
                ),
                row=3, col=2
            )

            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                title={
                    'text': 'ğŸ¤– AIé€‰è‚¡å™¨å®æ—¶äº¤æ˜“åˆ†ææŠ¥å‘Š',
                    'font': {'size': 20, 'color': '#212529'},
                    'x': 0.5
                },
                height=900,
                showlegend=True,
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=-0.05,
                    xanchor="center",
                    x=0.5
                ),
                template='plotly_white',
                font=dict(family="Arial, sans-serif", size=12, color="#212529"),
                hovermode='x unified'
            )

            # æ›´æ–°åæ ‡è½´æ ‡ç­¾
            fig.update_xaxes(title_text="æ—¶é—´", row=1, col=1)
            fig.update_yaxes(title_text="å‡€å€¼ (Â¥)", row=1, col=1)

            fig.update_xaxes(title_text="æ—¶é—´", row=1, col=2)
            fig.update_yaxes(title_text="å›æ’¤ (%)", row=1, col=2)

            fig.update_xaxes(title_text="è‚¡ç¥¨ä»£ç ", row=2, col=1)
            fig.update_yaxes(title_text="æŒä»“æ•°é‡ (è‚¡)", row=2, col=1)

            fig.update_xaxes(title_text="æ—¶é—´", row=2, col=2)
            fig.update_yaxes(title_text="ä»·æ ¼ (Â¥)", row=2, col=2)

            fig.update_xaxes(title_text="æ—¶é—´", row=3, col=1)
            fig.update_yaxes(title_text="é‡‘é¢ (Â¥)", row=3, col=1)

            fig.update_xaxes(title_text="æ—¶é—´", row=3, col=2)
            fig.update_yaxes(title_text="æ¢æ‰‹ç‡", row=3, col=2)

            # ä¿å­˜HTMLæ–‡ä»¶
            if output_file is None:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                output_file = f"live_trade_analysis_{timestamp}.html"

            html_path = output_path / output_file

            # åˆ›å»ºå®Œæ•´çš„HTMLæ¨¡æ¿
            html_template = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AIé€‰è‚¡å™¨å®æ—¶äº¤æ˜“åˆ†æ</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }}
        .container {{
            max-width: 1800px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #1f77b4 0%, #2ca02c 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }}
        .header h1 {{
            margin: 0;
            font-size: 2.5em;
            font-weight: 300;
        }}
        .header p {{
            margin: 10px 0 0 0;
            opacity: 0.9;
            font-size: 1.1em;
        }}
        .dashboard-container {{
            padding: 20px;
        }}
        .stats-panel {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 20px;
        }}
        .stat-card {{
            background: #f8f9fa;
            border-left: 4px solid #1f77b4;
            padding: 15px;
            border-radius: 0 10px 10px 0;
        }}
        .stat-title {{
            font-size: 14px;
            color: #6c757d;
            margin-bottom: 5px;
        }}
        .stat-value {{
            font-size: 24px;
            font-weight: bold;
            color: #212529;
        }}
        .footer {{
            background: #212529;
            color: white;
            text-align: center;
            padding: 20px;
            font-size: 0.9em;
        }}
        .plotly-graph-div {{
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¤– AIé€‰è‚¡å™¨å®æ—¶äº¤æ˜“åˆ†æ</h1>
            <p>åŸºäºæœºå™¨å­¦ä¹ çš„æ™ºèƒ½äº¤æ˜“ç³»ç»Ÿå®æ—¶ç›‘æ§</p>
        </div>

        <div class="dashboard-container">
            <div class="stats-panel">
                <div class="stat-card">
                    <div class="stat-title">å½“å‰å‡€å€¼</div>
                    <div class="stat-value">Â¥{portfolio_nav['nav'].iloc[-1]:.2f}</div>
                </div>
                <div class="stat-card">
                    <div class="stat-title">æ€»æ”¶ç›Šç‡</div>
                    <div class="stat-value">{((portfolio_nav['nav'].iloc[-1] - portfolio_nav['nav'].iloc[0]) / portfolio_nav['nav'].iloc[0] * 100):+.2f}%</div>
                </div>
                <div class="stat-card">
                    <div class="stat-title">æœ€å¤§å›æ’¤</div>
                    <div class="stat-value">{portfolio_nav['drawdown'].min()*100:.2f}%</div>
                </div>
                <div class="stat-card">
                    <div class="stat-title">äº¤æ˜“æ¬¡æ•°</div>
                    <div class="stat-value">{len(trade_log)}</div>
                </div>
            </div>

            <div id="live-trade-dashboard" class="plotly-graph-div"></div>
        </div>

        <div class="footer">
            <p>Â© 2024 AIé€‰è‚¡å™¨å®æ—¶äº¤æ˜“ç³»ç»Ÿ | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
    </div>
</body>
</html>
"""

            # ä¿å­˜å›¾è¡¨ä¸ºHTML
            fig.write_html(
                str(html_path),
                include_plotlyjs='cdn',
                div_id='live-trade-dashboard',
                full_html=False
            )

            # è¯»å–ç”Ÿæˆçš„HTMLå¹¶åµŒå…¥åˆ°æ¨¡æ¿ä¸­
            with open(html_path, 'r', encoding='utf-8') as f:
                chart_html = f.read()

            # æ›¿æ¢æ¨¡æ¿ä¸­çš„å›¾è¡¨éƒ¨åˆ†
            final_html = html_template.replace(
                '<div id="live-trade-dashboard" class="plotly-graph-div"></div>',
                chart_html
            )

            # ä¿å­˜æœ€ç»ˆHTML
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(final_html)

            logger.info(f"ğŸ“Š å®æ—¶äº¤æ˜“å¯è§†åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {html_path}")
            print(f"\nğŸ¨ å®æ—¶äº¤æ˜“åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ!")
            print(f"ğŸ“Š æŠ¥å‘Šæ–‡ä»¶: {html_path}")
            print(f"ğŸŒ è¯·ç”¨æµè§ˆå™¨æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹äº¤äº’å¼å›¾è¡¨")

            return str(html_path)

        except ImportError:
            logger.warning("Plotlyæœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š")
            print("ğŸ’¡ æç¤º: å®‰è£…Plotlyè·å¾—å¯è§†åŒ–åˆ†ææŠ¥å‘Š")
            print("å‘½ä»¤: pip install plotly")
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šå¤±è´¥: {e}")
            print(f"âš ï¸  å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")

    def _get_rebalance_dates(self, dates: pd.DatetimeIndex, freq: str = 'M') -> set:
        """
        è·å–è°ƒä»“æ—¥æœŸ

        Args:
            dates: æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
            freq: è°ƒä»“é¢‘ç‡ 'D'/'W'/'M'

        Returns:
            set: è°ƒä»“æ—¥æœŸé›†åˆ
        """
        if freq == 'D':
            return set(dates)  # æ¯æ—¥è°ƒä»“
        elif freq == 'W':
            # æ¯å‘¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
            rebalance_dates = set()
            df = pd.DataFrame({'date': dates})
            df['week'] = df['date'].dt.isocalendar().week
            df['year'] = df['date'].dt.year
            weekly_last = df.groupby(['year', 'week'])['date'].max()
            return set(weekly_last.values)
        elif freq == 'M':
            # æ¯æœˆæœ€åä¸€ä¸ªäº¤æ˜“æ—¥
            rebalance_dates = set()
            df = pd.DataFrame({'date': dates})
            df['month'] = df['date'].dt.month
            df['year'] = df['date'].dt.year
            monthly_last = df.groupby(['year', 'month'])['date'].max()
            return set(monthly_last.values)
        else:
            return set(dates)  # é»˜è®¤æ¯æ—¥

    def _calc_transaction_fee(self, turnover: float, portfolio_value: float) -> float:
        """
        è®¡ç®—äº¤æ˜“è´¹ç”¨ï¼š0.0002ä¹° + 0.0005å–
        """
        # ç®€åŒ–ä¸ºåŒè¾¹æ€»è´¹ç‡
        fee_rate = 0.0007  # 0.02% + 0.05%
        return turnover * portfolio_value * fee_rate / portfolio_value  # è½¬æ¢ä¸ºæ”¶ç›Šç‡

    def _calc_realistic_transaction_cost(self, turnover: float, portfolio_value: float) -> float:
        """è®¡ç®—åˆ†çº§äº¤æ˜“æ‰‹ç»­è´¹"""
        trading_amount = turnover * portfolio_value

        if trading_amount < 20000:
            return 5.0 / portfolio_value  # å›ºå®š5å…ƒè½¬æ¢ä¸ºæ”¶ç›Šç‡
        else:
            return turnover * 0.00025  # ä¸‡åˆ†ä¹‹2.5

    def _get_empty_metrics(self) -> Dict:
        """è¿”å›ç©ºçš„æ€§èƒ½æŒ‡æ ‡"""
        return {
            'total_return': 0,
            'annual_return': 0,
            'volatility': 0,
            'sharpe_ratio': 0,
            'max_drawdown': 0,
            'win_rate': 0,
            'avg_turnover': 0,
            'trading_days': 0,
            'returns': pd.Series()
        }

    def _validate_results(self, results: Dict):
        """å•å…ƒæµ‹è¯•ï¼šéªŒè¯å›æµ‹ç»“æœ"""
        logger.info("æ‰§è¡Œå•å…ƒæµ‹è¯•...")

        ic_mean = results.get('ic_mean', 0)
        ic_ir = results.get('ic_ir', 0)
        annual_return = results.get('annual_return', 0)
        max_drawdown = results.get('max_drawdown', 0)
        sharpe_ratio = results.get('sharpe_ratio', 0)
        avg_turnover = results.get('avg_turnover', 0)
        win_rate = results.get('win_rate', 0)

        # æ£€æŸ¥ç›®æ ‡åŒºé—´ - ä»·æ ¼è¿‡æ»¤åè°ƒæ•´çš„é˜ˆå€¼
        checks = [
            (ic_mean >= 0.05, f"ICå‡å€¼ {ic_mean:.4f} < 0.05"),  # æå‡ICè¦æ±‚
            (ic_ir >= 0.15, f"IC_IR {ic_ir:.4f} < 0.15"),
            (0.05 <= abs(annual_return) <= 0.5, f"å¹´åŒ–æ”¶ç›Šç‡ {annual_return:.2%} ä¸åœ¨ 5%-50% èŒƒå›´"),
            (max_drawdown > -0.10, f"æœ€å¤§å›æ’¤ {max_drawdown:.2%} < -10%"),
            (abs(sharpe_ratio) <= 2.5, f"å¤æ™®æ¯”ç‡ {sharpe_ratio:.2f} > 2.5"),
            (avg_turnover < 1.2, f"å¹³å‡æ¢æ‰‹ç‡ {avg_turnover:.2f} > 1.2"),  # é™ä½æ¢æ‰‹ç‡è¦æ±‚
            (win_rate > 0.45, f"èƒœç‡ {win_rate:.2%} < 45%")
        ]

        failed_checks = [msg for check, msg in checks if not check]

        if failed_checks:
            logger.warning("å•å…ƒæµ‹è¯•è­¦å‘Š:")
            for msg in failed_checks:
                logger.warning(f"  - {msg}")
        else:
            logger.info("âœ“ æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡")

    def _save_backtest_results(self, results: Dict, model_name: str):
        """ä¿å­˜å›æµ‹ç»“æœ"""
        output_path = Path(self.config['output_path'])

        # ä¿å­˜è¯¦ç»†æŒ‡æ ‡
        metrics = {k: v for k, v in results.items() if k != 'returns'}

        with open(output_path / f"backtest_metrics_{model_name}.json", 'w') as f:
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            serializable_metrics = {}
            for k, v in metrics.items():
                if isinstance(v, (np.integer, np.floating)):
                    serializable_metrics[k] = float(v)
                else:
                    serializable_metrics[k] = v
            json.dump(serializable_metrics, f, indent=2)

        # ä¿å­˜èµ„é‡‘æ›²çº¿
        if 'returns' in results and len(results['returns']) > 0:
            returns = results['returns']
            equity_curve = (1 + returns).cumprod()

            df = pd.DataFrame({
                'date': equity_curve.index,
                'equity': equity_curve.values,
                'returns': returns.values
            })

            equity_file = output_path / f"equity_curve_{model_name}.csv"
            df.to_csv(equity_file, index=False)
            logger.info(f"èµ„é‡‘æ›²çº¿å·²ä¿å­˜è‡³: {equity_file}")

        # æ‰“å°å›æµ‹ç»“æœ
        self._print_results(results)

    def _print_results(self, results: Dict):
        """æ‰“å°å›æµ‹ç»“æœ"""
        print("\n" + "="*50)
        print("å›æµ‹ç»“æœæ±‡æ€»")
        print("="*50)
        print(f"ICå‡å€¼:        {results.get('ic_mean', 0):.4f}")
        print(f"IC_IR:         {results.get('ic_ir', 0):.4f}")
        print(f"æ€»æ”¶ç›Š:        {results.get('total_return', 0):.2%}")
        print(f"å¹´åŒ–æ”¶ç›Šç‡:    {results.get('annual_return', 0):.2%}")
        print(f"å¹´åŒ–æ³¢åŠ¨ç‡:    {results.get('volatility', 0):.2%}")
        print(f"å¤æ™®æ¯”ç‡:      {results.get('sharpe_ratio', 0):.2f}")
        print(f"æœ€å¤§å›æ’¤:      {results.get('max_drawdown', 0):.2%}")
        print(f"èƒœç‡:          {results.get('win_rate', 0):.2%}")
        print(f"å¹³å‡æ¢æ‰‹ç‡:    {results.get('avg_turnover', 0):.2f}")
        print(f"äº¤æ˜“æ—¥æ•°:      {results.get('trading_days', 0)}")
        print(f"ä»·æ ¼åŒºé—´:      ({results.get('price_min', 0):.2f}, {results.get('price_max', 1e9):.2f})")
        print("="*50)

    def _create_visualization(self, backtest_results: Dict, model_name: str, predictions: Dict):
        """åˆ›å»ºå¯è§†åŒ–åˆ†ææŠ¥å‘Š"""
        try:
            # æ£€æŸ¥Plotlyæ˜¯å¦å¯ç”¨
            import plotly.graph_objects as go
            from visualizer import BacktestVisualizer

            logger.info("æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–åˆ†ææŠ¥å‘Š...")

            # å‡†å¤‡èµ„é‡‘æ›²çº¿æ•°æ®
            if 'returns' in backtest_results:
                returns_series = backtest_results['returns']
                if len(returns_series) > 0:
                    # åˆ›å»ºæ—¥æœŸç´¢å¼•ï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
                    if not hasattr(returns_series.index, 'date'):
                        start_date = pd.to_datetime(self.config['valid_end']) + pd.Timedelta(days=1)
                        date_range = pd.date_range(start=start_date, periods=len(returns_series), freq='D')
                        returns_series.index = date_range

                    equity_curve = pd.DataFrame({
                        'date': returns_series.index,
                        'returns': returns_series.values,
                        'equity': (1 + returns_series).cumprod().values
                    })
                else:
                    # åˆ›å»ºç©ºçš„æ•°æ®æ¡†
                    equity_curve = pd.DataFrame(columns=['date', 'returns', 'equity'])
            else:
                equity_curve = pd.DataFrame(columns=['date', 'returns', 'equity'])

            # è·å–æœ€æ–°é€‰è‚¡æ•°æ®
            latest_picks_file = Path(self.config['output_path']) / 'latest_stock_picks.csv'
            latest_picks = None
            if latest_picks_file.exists():
                try:
                    latest_picks = pd.read_csv(latest_picks_file)
                except Exception as e:
                    logger.warning(f"è¯»å–æœ€æ–°é€‰è‚¡æ–‡ä»¶å¤±è´¥: {e}")

            # åˆ›å»ºå¯è§†åŒ–å™¨
            visualizer = BacktestVisualizer()

            # åˆ›å»ºç»¼åˆä»ªè¡¨æ¿
            dashboard_fig = visualizer.create_comprehensive_dashboard(
                equity_curve=equity_curve,
                metrics=backtest_results,
                predictions=predictions,
                latest_picks=latest_picks,
                title=f"AIé€‰è‚¡å™¨å›æµ‹åˆ†æ - {model_name}æ¨¡å‹"
            )

            # ä¿å­˜ä¸ºHTMLæ–‡ä»¶
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            html_filename = f"backtest_dashboard_{model_name}_{timestamp}.html"
            html_path = visualizer.save_dashboard_as_html(dashboard_fig, html_filename)

            print(f"\nğŸ¨ å¯è§†åŒ–åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ!")
            print(f"ğŸ“Š ä»ªè¡¨æ¿æ–‡ä»¶: {html_path}")
            print(f"ğŸŒ è¯·ç”¨æµè§ˆå™¨æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹äº¤äº’å¼å›¾è¡¨")

            # å°è¯•åœ¨æ”¯æŒçš„ç¯å¢ƒä¸­æ˜¾ç¤ºå›¾è¡¨
            try:
                dashboard_fig.show()
            except Exception:
                logger.info("æ— æ³•åœ¨å½“å‰ç¯å¢ƒç›´æ¥æ˜¾ç¤ºå›¾è¡¨ï¼Œè¯·æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹")

            # åˆ›å»ºè¯¦ç»†åˆ†ææŠ¥å‘Š
            try:
                detailed_fig = visualizer.create_detailed_analysis(
                    equity_curve=equity_curve,
                    metrics=backtest_results,
                    predictions=predictions
                )

                detailed_html = f"detailed_analysis_{model_name}_{timestamp}.html"
                detailed_path = visualizer.save_dashboard_as_html(detailed_fig, detailed_html)
                print(f"ğŸ“ˆ è¯¦ç»†åˆ†ææŠ¥å‘Š: {detailed_path}")

            except Exception as e:
                logger.warning(f"åˆ›å»ºè¯¦ç»†åˆ†ææŠ¥å‘Šå¤±è´¥: {e}")

            logger.info("å¯è§†åŒ–åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")

        except ImportError:
            logger.warning("Plotlyæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–åŠŸèƒ½")
            print("\nğŸ’¡ æç¤º: å®‰è£…Plotlyè·å¾—å¯è§†åŒ–åˆ†ææŠ¥å‘Š")
            print("å‘½ä»¤: pip install plotly")

        except Exception as e:
            logger.error(f"åˆ›å»ºå¯è§†åŒ–æŠ¥å‘Šå¤±è´¥: {e}")
            print(f"âš ï¸  å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")

    def create_visualization_only(self, model_name: str = None):
        """ä»…åˆ›å»ºå¯è§†åŒ–æŠ¥å‘Šï¼ˆåŸºäºå·²æœ‰ç»“æœï¼‰"""
        try:
            from visualizer import BacktestVisualizer

            logger.info("åŸºäºå·²æœ‰æ•°æ®åˆ›å»ºå¯è§†åŒ–æŠ¥å‘Š...")

            output_path = Path(self.config['output_path'])

            # æŸ¥æ‰¾æœ€æ–°çš„å›æµ‹ç»“æœæ–‡ä»¶
            if model_name is None:
                metric_files = list(output_path.glob("backtest_metrics_*.json"))
                if not metric_files:
                    logger.error("æœªæ‰¾åˆ°å›æµ‹ç»“æœæ–‡ä»¶")
                    return
                metric_file = max(metric_files, key=lambda x: x.stat().st_mtime)
                model_name = metric_file.stem.replace('backtest_metrics_', '')
            else:
                metric_file = output_path / f"backtest_metrics_{model_name}.json"
                if not metric_file.exists():
                    logger.error(f"æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„å›æµ‹ç»“æœ")
                    return

            # è¯»å–å›æµ‹æŒ‡æ ‡
            with open(metric_file, 'r') as f:
                metrics = json.load(f)

            # è¯»å–èµ„é‡‘æ›²çº¿
            equity_file = output_path / f"equity_curve_{model_name}.csv"
            if equity_file.exists():
                equity_curve = pd.read_csv(equity_file)
                equity_curve['date'] = pd.to_datetime(equity_curve['date'])
            else:
                equity_curve = pd.DataFrame(columns=['date', 'returns', 'equity'])

            # è¯»å–é¢„æµ‹ç»“æœ
            predictions = {}
            for pred_file in output_path.glob("signal_*.csv"):
                pred_name = pred_file.stem.replace('signal_', '')
                pred_data = pd.read_csv(pred_file)
                predictions[pred_name] = pred_data

            # è¯»å–æœ€æ–°é€‰è‚¡
            latest_picks_file = output_path / 'latest_stock_picks.csv'
            latest_picks = None
            if latest_picks_file.exists():
                latest_picks = pd.read_csv(latest_picks_file)

            # åˆ›å»ºå¯è§†åŒ–
            visualizer = BacktestVisualizer()

            dashboard_fig = visualizer.create_comprehensive_dashboard(
                equity_curve=equity_curve,
                metrics=metrics,
                predictions=predictions,
                latest_picks=latest_picks,
                title=f"AIé€‰è‚¡å™¨å›æµ‹åˆ†æ - {model_name}æ¨¡å‹"
            )

            # ä¿å­˜å¹¶æ˜¾ç¤º
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            html_filename = f"backtest_dashboard_{model_name}_{timestamp}.html"
            html_path = visualizer.save_dashboard_as_html(dashboard_fig, html_filename)

            print(f"\nğŸ¨ å¯è§†åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {html_path}")

            try:
                dashboard_fig.show()
            except:
                pass

            return html_path

        except ImportError:
            print("è¯·å®‰è£…Plotly: pip install plotly")
        except Exception as e:
            logger.error(f"åˆ›å»ºå¯è§†åŒ–å¤±è´¥: {e}")
            return None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='AIè‚¡ç¥¨é€‰æ‹©å™¨')
    parser.add_argument('--prepare_data', action='store_true', help='å‡†å¤‡æ•°æ®')
    parser.add_argument('--train', action='store_true', help='è®­ç»ƒæ¨¡å‹')
    parser.add_argument('--predict', action='store_true', help='ç”Ÿæˆé¢„æµ‹')
    parser.add_argument('--select_stocks', action='store_true', help='é€‰è‚¡å¹¶ç”ŸæˆæŠ•èµ„ç»„åˆ')
    parser.add_argument('--backtest', action='store_true', help='è¿è¡Œå›æµ‹')
    parser.add_argument('--backtest_stocks', action='store_true', help='é€‰è‚¡+å›æµ‹+å¯è§†åŒ–å®Œæ•´æµç¨‹')
    parser.add_argument('--visualize', action='store_true', help='åˆ›å»ºå¯è§†åŒ–åˆ†ææŠ¥å‘Š')
    parser.add_argument('--live_trade', action='store_true', help='å¯åŠ¨å®æ—¶äº¤æ˜“æ¨¡æ‹Ÿ')
    parser.add_argument('--topk', type=int, default=10, help='é€‰è‚¡æ•°é‡ï¼ˆé»˜è®¤10ï¼‰')
    parser.add_argument('--rebalance_freq', type=str, default='M', choices=['D', 'W', 'M'],
                       help='è°ƒä»“é¢‘ç‡ï¼šDæ—¥åº¦, Wå‘¨åº¦, Mæœˆåº¦')
    parser.add_argument('--universe', type=str, choices=['all', 'csi300', 'csi500'],
                       help='è‚¡ç¥¨æ± ï¼šallå…¨å¸‚åœº, csi300æ²ªæ·±300, csi500ä¸­è¯500')
    parser.add_argument('--price_min', type=float, default=0, help='æœ€ä½ä»·æ ¼é™åˆ¶ï¼ˆé»˜è®¤0ï¼‰')
    parser.add_argument('--price_max', type=float, default=1e9, help='æœ€é«˜ä»·æ ¼é™åˆ¶ï¼ˆé»˜è®¤1e9ï¼‰')
    parser.add_argument('--weight_method', type=str, default='equal', choices=['equal', 'score', 'risk_opt'],
                       help='æƒé‡åˆ†é…æ–¹æ³•ï¼šequalç­‰æƒé‡, scoreåŸºäºè¯„åˆ†, risk_opté£é™©ä¼˜åŒ–')
    parser.add_argument('--interval', type=int, default=60, help='å®æ—¶äº¤æ˜“è½®è¯¢é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤60ï¼‰')
    parser.add_argument('--trade_hours', type=str, default='09:30-11:30,13:00-15:00',
                       help='äº¤æ˜“æ—¶æ®µï¼ˆé»˜è®¤09:30-11:30,13:00-15:00ï¼‰')
    parser.add_argument('--capital', type=float, default=100000, help='åˆå§‹èµ„é‡‘ï¼ˆé»˜è®¤100000ï¼‰')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = CONFIG.copy()
    if args.config and Path(args.config).exists():
        with open(args.config, 'r') as f:
            custom_config = json.load(f)
            config.update(custom_config)

    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°åˆ°é…ç½®
    if args.universe:
        config['universe'] = args.universe

    # åˆ›å»ºé€‰è‚¡å™¨å®ä¾‹
    selector = AIStockSelector(config)

    # ä¼ é€’å‘½ä»¤è¡Œå‚æ•°
    selector.topk = args.topk
    selector.rebalance_freq = args.rebalance_freq
    selector.price_min = args.price_min
    selector.price_max = args.price_max
    selector.weight_method = args.weight_method

    try:
        if args.prepare_data:
            selector.prepare_data()
        elif args.train:
            selector.prepare_data()  # ç¡®ä¿æ•°æ®å¯ç”¨
            selector.train()
        elif args.predict:
            selector.predict()
        elif args.select_stocks:
            selector.predict()  # é€‰è‚¡åŒ…å«é¢„æµ‹æ­¥éª¤
        elif args.backtest:
            selector.backtest()
        elif args.backtest_stocks:
            # é€‰è‚¡+å›æµ‹+å¯è§†åŒ–å®Œæ•´æµç¨‹
            print(f"ğŸš€ å¼€å§‹é€‰è‚¡å›æµ‹æµç¨‹...")
            print(f"ğŸ“‹ å‚æ•°: é€‰è‚¡æ•°é‡={args.topk}, è°ƒä»“é¢‘ç‡={args.rebalance_freq}, ä»·æ ¼åŒºé—´=({args.price_min}, {args.price_max})")

            # ç¡®ä¿æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
            if not any(Path(selector.config['model_path']).glob("*_model.pkl")):
                print("âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¼€å§‹è®­ç»ƒ...")
                selector.prepare_data()
                selector.train()

            # æ‰§è¡Œé€‰è‚¡
            print("ğŸ“Š ç”Ÿæˆé¢„æµ‹ä¿¡å·...")
            predictions = selector.predict()

            # æ‰§è¡Œå›æµ‹
            print("ğŸ”„ è¿è¡Œé€‰è‚¡å›æµ‹...")
            backtest_results = selector.backtest()

            print("âœ… é€‰è‚¡å›æµ‹æµç¨‹å®Œæˆ!")

        elif args.visualize:
            selector.create_visualization_only()
        else:
            # é»˜è®¤è¿è¡Œå®Œæ•´æµç¨‹
            print("è¿è¡Œå®Œæ•´AIé€‰è‚¡æµç¨‹...")
            selector.prepare_data()
            selector.train()
            selector.predict()
            selector.backtest()

    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
