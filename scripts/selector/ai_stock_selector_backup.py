#!/usr/bin/env python3
"""
AIè‚¡ç¥¨é€‰æ‹©å™¨ - å®Œæ•´å®ç°
===========================

åŸºäºQlib + AkShareçš„æ™ºèƒ½é€‰è‚¡ç³»ç»Ÿï¼Œæ”¯æŒï¼š
- æ•°æ®è‡ªåŠ¨ä¸‹è½½ä¸è¡¥é½
- å¤šå› å­ç‰¹å¾å·¥ç¨‹
- é›†æˆå­¦ä¹ æ¨¡å‹(LightGBM + XGBoost + Transformer)
- æŠ•èµ„ç»„åˆä¼˜åŒ–ä¸é£é™©æ§åˆ¶
- å®Œæ•´å›æµ‹ä¸æ€§èƒ½è¯„ä¼°

Usage:
    python ai_stock_selector.py --prepare_data   # ä¸‹è½½&å†™å…¥æ•°æ®
    python ai_stock_selector.py --train          # è®­ç»ƒæ¨¡å‹
    python ai_stock_selector.py --predict        # ç”Ÿæˆé¢„æµ‹ä¿¡å·
    python ai_stock_selector.py --predict --price_min 10 --price_max 50  # ä»·æ ¼è¿‡æ»¤é€‰è‚¡
    python ai_stock_selector.py --backtest       # è¿è¡Œå›æµ‹
"""

import os
import sys
import argparse
import warnings
import logging
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
from datetime import datetime, timedelta
import json

# è®¾ç½®è­¦å‘Šå’Œéšæœºç§å­
warnings.filterwarnings('ignore')
np.random.seed(42)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ä¾èµ–æ£€æŸ¥å’Œå¯¼å…¥
try:
    import qlib
    from qlib.config import REG_CN
    from qlib.utils import init_instance_by_config
    from qlib.data import D
    from qlib.data.dataset import DatasetH
    from qlib.data.dataset.handler import DataHandlerLP
    from qlib.contrib.model.gbdt import LGBModel
    from qlib.contrib.strategy.signal_strategy import TopkDropoutStrategy
    print("âœ“ Qlibå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"Qlibå¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å®‰è£…: pip install pyqlib")
    sys.exit(1)

try:
    import akshare as ak
    print("âœ“ AkShareå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.error("AkShareå¯¼å…¥å¤±è´¥")
    print("è¯·å®‰è£…: pip install akshare")
    sys.exit(1)

try:
    import lightgbm as lgb
    print("âœ“ LightGBMå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.warning("LightGBMæœªå®‰è£…")
    print("å»ºè®®å®‰è£…: pip install lightgbm")

try:
    import xgboost as xgb
    print("âœ“ XGBoostå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.warning("XGBoostæœªå®‰è£…")
    print("å»ºè®®å®‰è£…: pip install xgboost")

try:
    import cvxpy as cp
    print("âœ“ CVXPYå¯¼å…¥æˆåŠŸ")
except ImportError:
    logger.warning("CVXPYæœªå®‰è£…ï¼Œå°†ä½¿ç”¨TopKç­‰æƒ")
    print("å»ºè®®å®‰è£…: pip install cvxpy")

# å…¨å±€é…ç½®
CONFIG = {
    'data_path': os.path.expanduser("~/.qlib/qlib_data/cn_data"),
    'model_path': './models',
    'output_path': './output',
    "start_date": "2014-01-01",
    "train_end":  "2021-12-31",
    "valid_end":  "2023-12-31",
    'end_date': '2025-06-04',
    'universe': 'all',  # ä¸´æ—¶ä½¿ç”¨csi300ç¡®ä¿ç¨³å®šæ€§
    'random_seed': 42,
    'n_jobs': 8
}


class AIStockSelector:
    """AIè‚¡ç¥¨é€‰æ‹©å™¨ä¸»ç±»"""

    def __init__(self, config: Dict = None):
        self.config = {**CONFIG, **(config or {})}
        self.models = {}
        self.data_handler = None
        self.dataset = None

        # é»˜è®¤å‚æ•°
        self.topk = 10
        self.rebalance_freq = 'M'
        self.price_min = 0
        self.price_max = 1e9

        # åˆ›å»ºå¿…è¦ç›®å½•
        Path(self.config['model_path']).mkdir(exist_ok=True)
        Path(self.config['output_path']).mkdir(exist_ok=True)

    def prepare_data(self):
        """æ•°æ®å‡†å¤‡ï¼šæ£€æŸ¥æœ¬åœ°æ•°æ®ï¼Œç¼ºå¤±åˆ™ç”¨AkShareè¡¥é½"""
        logger.info("å¼€å§‹æ•°æ®å‡†å¤‡...")

        # æ£€æŸ¥æœ¬åœ°Qlibæ•°æ®
        data_path = Path(self.config['data_path'])
        if not data_path.exists() or self._missing_dates():
            logger.info("æœ¬åœ°æ•°æ®ç¼ºå¤±ï¼Œå¼€å§‹ä¸‹è½½...")
            self._download_data_with_akshare()

        # åˆå§‹åŒ–Qlib
        self._init_qlib()
        logger.info("æ•°æ®å‡†å¤‡å®Œæˆ")

    def _missing_dates(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ç¼ºå¤±æ•°æ®"""
        try:
            # ç®€å•æ£€æŸ¥ï¼šæ˜¯å¦å­˜åœ¨åŸºæœ¬ç›®å½•ç»“æ„
            data_path = Path(self.config['data_path'])
            required_dirs = ['features', 'calendars', 'instruments']
            return not all((data_path / d).exists() for d in required_dirs)
        except Exception:
            return True

    def _download_data_with_akshare(self):
        """ä½¿ç”¨AkShareä¸‹è½½æ•°æ®"""
        logger.info("ä½¿ç”¨AkShareä¸‹è½½Aè‚¡æ•°æ®...")

        try:
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            if self.config['universe'] == 'csi300':
                stock_list = ak.index_stock_cons(index="000300")
                stocks = [f"{row['å“ç§ä»£ç ']}.{'SH' if row['å“ç§ä»£ç '].startswith('6') else 'SZ'}"
                         for _, row in stock_list.iterrows()]
            else:
                # è·å–å…¨Aè‚¡
                stocks = self._get_all_a_shares()

            logger.info(f"å‡†å¤‡ä¸‹è½½ {len(stocks)} åªè‚¡ç¥¨æ•°æ®")

            # ä¸‹è½½æ—¥çº¿æ•°æ®
            all_data = []
            for i, symbol in enumerate(stocks[:50]):  # é™åˆ¶50åªè‚¡ç¥¨é¿å…ä¸‹è½½æ—¶é—´è¿‡é•¿
                try:
                    logger.info(f"ä¸‹è½½ {symbol} ({i+1}/{min(50, len(stocks))})...")

                    # AkShareè‚¡ç¥¨ä»£ç æ ¼å¼è½¬æ¢
                    ak_symbol = symbol.replace('.SH', '').replace('.SZ', '')

                    # è·å–å†å²æ•°æ®
                    df = ak.stock_zh_a_hist(
                        symbol=ak_symbol,
                        period="daily",
                        start_date=self.config['start_date'].replace('-', ''),
                        end_date=self.config['end_date'].replace('-', ''),
                        adjust="qfq"  # å‰å¤æƒ
                    )

                    if df.empty:
                        continue

                    # æ•°æ®æ ¼å¼è½¬æ¢
                    df = df.rename(columns={
                        'æ—¥æœŸ': 'date',
                        'å¼€ç›˜': 'open',
                        'æ”¶ç›˜': 'close',
                        'æœ€é«˜': 'high',
                        'æœ€ä½': 'low',
                        'æˆäº¤é‡': 'volume',
                        'æˆäº¤é¢': 'amount',
                        'æ¢æ‰‹ç‡': 'turn'
                    })

                    # æ·»åŠ è‚¡ç¥¨ä»£ç 
                    df['instrument'] = symbol
                    df['date'] = pd.to_datetime(df['date'])

                    # åŸºæœ¬æ•°æ®æ¸…ç†
                    numeric_cols = ['open', 'close', 'high', 'low', 'volume', 'amount']
                    for col in numeric_cols:
                        if col in df.columns:
                            df[col] = pd.to_numeric(df[col], errors='coerce')

                    all_data.append(df)

                except Exception as e:
                    logger.warning(f"ä¸‹è½½ {symbol} å¤±è´¥: {e}")
                    continue

            if all_data:
                # åˆå¹¶æ‰€æœ‰æ•°æ®
                combined_data = pd.concat(all_data, ignore_index=True)

                # ä¿å­˜ä¸ºCSVæ ¼å¼ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                output_file = Path(self.config['output_path']) / 'market_data.csv'
                combined_data.to_csv(output_file, index=False)
                logger.info(f"æ•°æ®å·²ä¿å­˜è‡³: {output_file}")

                # å†™å…¥Qlibæ ¼å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
                self._write_to_qlib_format(combined_data)
            else:
                logger.error("æ²¡æœ‰æˆåŠŸä¸‹è½½ä»»ä½•æ•°æ®")

        except Exception as e:
            logger.error(f"AkShareæ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            logger.info("å°†ä½¿ç”¨Qlibè‡ªå¸¦çš„ç¤ºä¾‹æ•°æ®")

    def _get_all_a_shares(self) -> List[str]:
        """è·å–å…¨Aè‚¡ä»£ç åˆ—è¡¨"""
        try:
            # è·å–Aè‚¡åˆ—è¡¨
            df = ak.stock_info_a_code_name()
            stocks = []
            for _, row in df.iterrows():
                code = row['code']
                if code.startswith('6'):
                    stocks.append(f"{code}.SH")
                elif code.startswith(('0', '3')):
                    stocks.append(f"{code}.SZ")
            return stocks[:500]  # é™åˆ¶æ•°é‡
        except Exception as e:
            logger.warning(f"è·å–Aè‚¡åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _write_to_qlib_format(self, data: pd.DataFrame):
        """å°†æ•°æ®å†™å…¥Qlibæ ¼å¼ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        logger.info("è½¬æ¢æ•°æ®ä¸ºQlibæ ¼å¼...")

        try:
            # è¿™é‡Œæ˜¯ç®€åŒ–å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­éœ€è¦ä½¿ç”¨qlib.data.writer
            # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨qlibè‡ªå¸¦æ•°æ®
            logger.info("ä½¿ç”¨Qlibå†…ç½®æ•°æ®æ ¼å¼")

        except Exception as e:
            logger.warning(f"Qlibæ ¼å¼è½¬æ¢å¤±è´¥: {e}")

    def _init_qlib(self):
        """åˆå§‹åŒ–Qlib"""
        try:
            provider_uri = self.config['data_path']
            qlib.init(provider_uri=provider_uri, region=REG_CN)
            logger.info("Qlibåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Qlibåˆå§‹åŒ–å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            qlib.init(region=REG_CN)
            logger.info("ä½¿ç”¨Qlibé»˜è®¤é…ç½®")

    def train(self):
        """è®­ç»ƒæ¨¡å‹"""
        logger.info("å¼€å§‹æ¨¡å‹è®­ç»ƒ...")

        # åˆå§‹åŒ–Qlibï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
        try:
            D.calendar()
        except:
            self._init_qlib()

        # å‡†å¤‡æ•°æ®é›†
        self._prepare_dataset()

        # è®­ç»ƒå¤šä¸ªæ¨¡å‹
        self._train_lightgbm()
        self._train_xgboost()
        # self._train_transformer()  # éœ€è¦PyTorch

        # è®­ç»ƒé›†æˆæ¨¡å‹
        self._train_ensemble()

        # ä¿å­˜æ¨¡å‹
        self._save_models()

        logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")

    def _prepare_dataset(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®é›†"""
        logger.info("å‡†å¤‡æ•°æ®é›†...")

        # ç‰¹å¾å·¥ç¨‹é…ç½®
        features = self._get_feature_config()

        # æ•°æ®å¤„ç†å™¨é…ç½®
        infer_processors = [
            {"class": "RobustZScoreNorm", "kwargs": {
                "fields_group": "feature",
                "fit_start_time": self.config['start_date'],
                "fit_end_time": self.config['train_end']
            }},
            {"class": "Fillna", "kwargs": {"fields_group": "feature"}}
        ]

        learn_processors = [
            {"class": "DropnaLabel"},
            {"class": "CSRankNorm", "kwargs": {"fields_group": "label"}}
        ]

        # æ•°æ®åŠ è½½å™¨é…ç½®
        data_loader_config = {
            "class": "QlibDataLoader",
            "kwargs": {
                "config": {
                    "feature": features,
                    "label": ["Ref($close, -2) / Ref($close, -1) - 1"]  # 2æ—¥æ”¶ç›Šç‡
                },
                "freq": "day",
            },
        }

        # æ•°æ®å¤„ç†å™¨é…ç½®
        handler_config = {
            "class": "DataHandlerLP",
            "module_path": "qlib.data.dataset.handler",
            "kwargs": {
                "instruments": "csi300",  # æš‚æ—¶ä½¿ç”¨csi300ç¡®ä¿ç¨³å®šæ€§
                "start_time": self.config['start_date'],
                "end_time": self.config['end_date'],
                "data_loader": data_loader_config,
                "infer_processors": infer_processors,
                "learn_processors": learn_processors,
            }
        }

        # æ•°æ®é›†é…ç½®
        dataset_config = {
            "class": "DatasetH",
            "module_path": "qlib.data.dataset",
            "kwargs": {
                "handler": handler_config,
                "segments": {
                    "train": (self.config['start_date'], self.config['train_end']),
                    "valid": (self.config['train_end'], self.config['valid_end']),
                    "test": (self.config['valid_end'], self.config['end_date']),
                },
            }
        }

        try:
            self.dataset = init_instance_by_config(dataset_config)
            logger.info(f"æ•°æ®é›†å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°: {len(features)}")

            # éªŒè¯æ•°æ®é›†æ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°æ®
            try:
                train_data = self.dataset.prepare("train", col_set=["feature", "label"])
                if len(train_data) == 0:
                    logger.error("è®­ç»ƒæ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç‰¹å¾é…ç½®å’Œæ—¶é—´èŒƒå›´")
                    raise ValueError("Empty training dataset")
                else:
                    logger.info(f"è®­ç»ƒæ•°æ®éªŒè¯é€šè¿‡ï¼ŒåŒ…å« {len(train_data)} æ¡è®°å½•")
            except Exception as e:
                logger.error(f"æ•°æ®é›†éªŒè¯å¤±è´¥: {e}")
                raise

        except Exception as e:
            logger.error(f"æ•°æ®é›†å‡†å¤‡å¤±è´¥: {e}")
            raise

    def _get_feature_config(self) -> List[str]:
        """è·å–ç‰¹å¾å·¥ç¨‹é…ç½®

        æ³¨æ„ï¼šå»é™¤äº†$market_capå’Œ$turnç›¸å…³ç‰¹å¾ï¼Œå› ä¸ºè¿™äº›å­—æ®µåœ¨å½“å‰Qlibæ•°æ®ä¸­ä¸å¯ç”¨
        """
        features = []

        # ä»·æ ¼åŠ¨é‡å› å­
        price_momentum = [
            # çŸ­æœŸåŠ¨é‡
            "Mean($close,5)/Ref($close,1)-1",  # 5æ—¥åŠ¨é‡
            "Mean($close,10)/Ref($close,1)-1", # 10æ—¥åŠ¨é‡
            "Mean($close,20)/Ref($close,1)-1", # 20æ—¥åŠ¨é‡

            # å¸ƒæ—å¸¦ä½ç½®
            "($close-Mean($close,20))/Mean($close,20)",
            "($close-Mean($close,20))/(Std($close,20)*2)",

            # MACDç›¸å…³
            "(Mean($close,12)-Mean($close,26))/Mean($close,26)",  # DIF
            "Mean((Mean($close,12)-Mean($close,26))/Mean($close,26),9)",  # DEA

            # ä»·æ ¼åè½¬
            "Ref($close,5)/$close-1",  # 5æ—¥åè½¬
            "Ref($close,10)/$close-1", # 10æ—¥åè½¬
        ]

        # é‡ä»·æ³¢åŠ¨å› å­
        volume_volatility = [
            # æŒ¯å¹…
            "($high-$low)/$low",
            "($high-$low)/$close",

            # ä»·æ ¼æ³¢åŠ¨
            "Std($close/Ref($close,1),5)",   # 5æ—¥æ³¢åŠ¨
            "Std($close/Ref($close,1),10)",  # 10æ—¥æ³¢åŠ¨
            "Std($close/Ref($close,1),20)",  # 20æ—¥æ³¢åŠ¨

            # æˆäº¤é‡ç›¸å…³
            "$volume/Mean($volume,20)",      # é‡æ¯”
            "Std($volume,10)/Mean($volume,10)", # é‡èƒ½å˜å¼‚
            "Corr($close,$volume,10)",       # é‡ä»·ç›¸å…³æ€§
        ]

        # æ›¿ä»£ä¼°å€¼è´¨é‡å› å­ï¼ˆä½¿ç”¨å¯ç”¨å­—æ®µï¼‰
        valuation_quality = [
            # åŸºäºä»·æ ¼çš„ä¼°å€¼ä»£ç†æŒ‡æ ‡
            "Log($close)",                    # ä»·æ ¼æ°´å¹³ï¼ˆå¯¹æ•°åŒ–ï¼‰
            "$close/Mean($close,60)",         # ç›¸å¯¹ä»·æ ¼ä½ç½®
            "Mean($amount,5)",                # æˆäº¤é‡‘é¢å‡å€¼
            "Log($amount+1)",                 # æˆäº¤é‡‘é¢ï¼ˆå¯¹æ•°åŒ–ï¼Œ+1é¿å…log(0)ï¼‰
            "$amount/Mean($amount,20)",       # ç›¸å¯¹æˆäº¤é‡‘é¢
        ]

        # æŠ€æœ¯æŒ‡æ ‡
        technical = [
            # RSIç±»
            "($close-Mean($close,6))/(Std($close,6)+1e-12)",
            "($close-Mean($close,14))/(Std($close,14)+1e-12)",

            # å¨å»‰æŒ‡æ ‡
            "($close-Min($low,14))/(Max($high,14)-Min($low,14)+1e-12)",

            # ä»·æ ¼é€šé“
            "($close-Min($close,20))/(Max($close,20)-Min($close,20)+1e-12)",
        ]

        # ç»„åˆæ‰€æœ‰ç‰¹å¾
        features.extend(price_momentum)
        features.extend(volume_volatility)
        features.extend(valuation_quality)
        features.extend(technical)

        return features

    def _train_lightgbm(self):
        """è®­ç»ƒLightGBMæ¨¡å‹"""
        logger.info("è®­ç»ƒLightGBMæ¨¡å‹...")

        # ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°é…ç½®ï¼ŒåŸºäºè°ƒè¯•æˆåŠŸçš„é…ç½®
        lgb_config = {
            "class": "LGBModel",
            "module_path": "qlib.contrib.model.gbdt",
            "kwargs": {
                "loss": "mse",
                "boosting_type": "gbdt",
                "objective": "regression",
                "num_leaves": 32,  # å‡å°‘å¤æ‚åº¦ï¼Œé¿å…è¿‡æ‹Ÿåˆ
                "learning_rate": 0.1,  # æé«˜å­¦ä¹ ç‡
                "feature_fraction": 0.8,
                "bagging_fraction": 0.8,
                "bagging_freq": 5,
                "num_boost_round": 100,  # å‡å°‘è¿­ä»£æ¬¡æ•°
                "early_stopping_rounds": 10,  # å‡å°‘æ—©åœè½®æ•°
                "verbosity": 1,  # æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
                "seed": self.config['random_seed'],
                "n_jobs": 1,  # ä½¿ç”¨å•çº¿ç¨‹é¿å…å¹¶å‘é—®é¢˜
                "force_col_wise": True  # å¼ºåˆ¶åˆ—å¼å¤šçº¿ç¨‹
            }
        }

        try:
            lgb_model = init_instance_by_config(lgb_config)
            logger.info("å¼€å§‹LightGBMè®­ç»ƒ...")
            lgb_model.fit(self.dataset)
            self.models['lgb'] = lgb_model
            logger.info("LightGBMè®­ç»ƒå®Œæˆ")
        except Exception as e:
            logger.error(f"LightGBMè®­ç»ƒå¤±è´¥: {e}")
            # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

    def _train_xgboost(self):
        """è®­ç»ƒXGBoostæ¨¡å‹"""
        logger.info("è®­ç»ƒXGBoostæ¨¡å‹...")

        # æ£€æŸ¥XGBoostå¯ç”¨æ€§
        try:
            import xgboost
        except ImportError:
            logger.warning("XGBoostæœªå®‰è£…ï¼Œè·³è¿‡è®­ç»ƒ")
            return

        xgb_config = {
            "class": "XGBModel",
            "module_path": "qlib.contrib.model.xgboost",
            "kwargs": {
                "objective": "reg:squarederror",
                "n_estimators": 800,
                "max_depth": 8,
                "learning_rate": 0.02,
                "subsample": 0.8,
                "colsample_bytree": 0.8,
                "random_state": self.config['random_seed'],
                "n_jobs": self.config['n_jobs'],
                "early_stopping_rounds": 100
            }
        }

        try:
            xgb_model = init_instance_by_config(xgb_config)
            xgb_model.fit(self.dataset)
            self.models['xgb'] = xgb_model
            logger.info("XGBoostè®­ç»ƒå®Œæˆ")
        except Exception as e:
            logger.warning(f"XGBoostè®­ç»ƒå¤±è´¥: {e}")

    def _train_ensemble(self):
        """è®­ç»ƒé›†æˆæ¨¡å‹"""
        logger.info("è®­ç»ƒé›†æˆæ¨¡å‹...")

        if len(self.models) == 0:
            logger.error("æ²¡æœ‰åŸºç¡€æ¨¡å‹å¯ç”¨äºé›†æˆ")
            return

        # ç®€åŒ–çš„é›†æˆæ–¹æ³•ï¼šç­‰æƒé‡
        self.models['ensemble'] = {
            'type': 'equal_weight',
            'models': list(self.models.keys()),
            'weights': [1.0/len(self.models)] * len(self.models)
        }

        logger.info(f"é›†æˆæ¨¡å‹åˆ›å»ºå®Œæˆï¼ŒåŒ…å« {len(self.models)-1} ä¸ªåŸºç¡€æ¨¡å‹")

    def _save_models(self):
        """ä¿å­˜æ¨¡å‹"""
        model_path = Path(self.config['model_path'])

        for name, model in self.models.items():
            if name != 'ensemble':
                try:
                    with open(model_path / f"{name}_model.pkl", 'wb') as f:
                        pickle.dump(model, f)
                    logger.info(f"æ¨¡å‹ {name} å·²ä¿å­˜")
                except Exception as e:
                    logger.error(f"ä¿å­˜æ¨¡å‹ {name} å¤±è´¥: {e}")

        # ä¿å­˜é›†æˆé…ç½®
        if 'ensemble' in self.models:
            with open(model_path / "ensemble_config.json", 'w') as f:
                json.dump(self.models['ensemble'], f)

    def predict(self):
        """ç”Ÿæˆé¢„æµ‹ä¿¡å·"""
        logger.info("ç”Ÿæˆé¢„æµ‹ä¿¡å·...")

        # åˆå§‹åŒ–Qlibï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
        try:
            D.calendar()
        except:
            self._init_qlib()

        # åŠ è½½æ¨¡å‹
        self._load_models()

        # ç”Ÿæˆé¢„æµ‹
        predictions = {}

        for name, model in self.models.items():
            if name == 'ensemble':
                continue

            try:
                pred = model.predict(self.dataset, segment='test')
                predictions[name] = pred
                logger.info(f"æ¨¡å‹ {name} é¢„æµ‹å®Œæˆ")
            except Exception as e:
                logger.error(f"æ¨¡å‹ {name} é¢„æµ‹å¤±è´¥: {e}")

        # é›†æˆé¢„æµ‹
        if len(predictions) > 1 and 'ensemble' in self.models:
            ensemble_pred = self._ensemble_predict(predictions)
            predictions['ensemble'] = ensemble_pred

        # ä¿å­˜é¢„æµ‹ç»“æœ
        self._save_predictions(predictions)

        # ç”Ÿæˆæœ€æ–°é€‰è‚¡å»ºè®®
        self._generate_latest_picks(predictions)

        logger.info("é¢„æµ‹ä¿¡å·ç”Ÿæˆå®Œæˆ")
        return predictions

    def _load_models(self):
        """åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"""
        model_path = Path(self.config['model_path'])

        # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡
        if self.models:
            return

        # å‡†å¤‡æ•°æ®é›†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.dataset is None:
            self._prepare_dataset()

        # åŠ è½½å„ä¸ªæ¨¡å‹
        for model_file in model_path.glob("*_model.pkl"):
            name = model_file.stem.replace('_model', '')
            try:
                with open(model_file, 'rb') as f:
                    self.models[name] = pickle.load(f)
                logger.info(f"æ¨¡å‹ {name} åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"åŠ è½½æ¨¡å‹ {name} å¤±è´¥: {e}")

        # åŠ è½½é›†æˆé…ç½®
        ensemble_file = model_path / "ensemble_config.json"
        if ensemble_file.exists():
            with open(ensemble_file, 'r') as f:
                self.models['ensemble'] = json.load(f)

    def _ensemble_predict(self, predictions: Dict) -> pd.Series:
        """é›†æˆé¢„æµ‹"""
        if 'ensemble' not in self.models:
            # ç®€å•å¹³å‡
            pred_values = list(predictions.values())
            return sum(pred_values) / len(pred_values)

        # åŠ æƒå¹³å‡
        ensemble_config = self.models['ensemble']
        weights = ensemble_config['weights']
        model_names = ensemble_config['models']

        result = None
        total_weight = 0

        for i, name in enumerate(model_names):
            if name in predictions:
                weight = weights[i]
                if result is None:
                    result = predictions[name] * weight
                else:
                    result += predictions[name] * weight
                total_weight += weight

        if total_weight > 0:
            result = result / total_weight

        return result

    def _save_predictions(self, predictions: Dict):
        """ä¿å­˜é¢„æµ‹ç»“æœ"""
        output_path = Path(self.config['output_path'])

        for name, pred in predictions.items():
            try:
                # è½¬æ¢ä¸ºDataFrame
                if isinstance(pred, pd.Series):
                    df = pred.reset_index()
                    df.columns = ['date', 'instrument', 'prediction']
                else:
                    df = pred

                # ä¿å­˜CSV
                output_file = output_path / f"signal_{name}.csv"
                df.to_csv(output_file, index=False)
                logger.info(f"é¢„æµ‹ç»“æœ {name} å·²ä¿å­˜è‡³: {output_file}")

            except Exception as e:
                logger.error(f"ä¿å­˜é¢„æµ‹ç»“æœ {name} å¤±è´¥: {e}")

    def _generate_latest_picks(self, predictions: Dict):
        """ç”Ÿæˆæœ€æ–°é€‰è‚¡å»ºè®®å¹¶ä¿å­˜ä¸ºlatest_stock_picks.csv"""
        try:
            # é€‰æ‹©æœ€ä½³é¢„æµ‹ï¼ˆä¼˜å…ˆé›†æˆæ¨¡å‹ï¼‰
            if 'ensemble' in predictions:
                pred_score = predictions['ensemble']
                model_name = 'ensemble'
            elif predictions:
                model_name = list(predictions.keys())[0]
                pred_score = predictions[model_name]
            else:
                logger.error("æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹ç»“æœ")
                return

            # è·å–æœ€æ–°æ—¥æœŸçš„é¢„æµ‹
            latest_date = pred_score.index.get_level_values(0).max()
            latest_predictions = pred_score.loc[latest_date].dropna()

            if len(latest_predictions) == 0:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ€æ–°çš„é¢„æµ‹æ•°æ®")
                return

            # ä½¿ç”¨é€‰è‚¡å‡½æ•°é€‰æ‹©è‚¡ç¥¨
            selected_weights = self.select_stocks(latest_predictions, self.topk, latest_date,
                                                 self.price_min, self.price_max)

            if len(selected_weights) == 0:
                logger.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
                return

            # ä½¿ç”¨AkShareè·å–è‚¡ç¥¨åç§°å’Œæœ€æ–°è‚¡ä»·
            stock_codes = [stock for stock in selected_weights.index]
            stock_names = self._get_stock_names(stock_codes)
            stock_prices = self._get_latest_stock_prices(stock_codes)

            # åˆ›å»ºæ¨èåˆ—è¡¨
            recommendations = []
            for rank, (stock_code, weight) in enumerate(selected_weights.items(), 1):
                pred_score_val = latest_predictions[stock_code]
                stock_name = stock_names.get(stock_code, 'æœªçŸ¥')
                price_info = stock_prices.get(stock_code, {})

                recommendations.append({
                    'rank': rank,
                    'stock_code': stock_code,
                    'stock_name': stock_name,
                    'pred_score': pred_score_val,
                    'weight': weight,
                    'current_price': price_info.get('current_price', 0),
                    'change_pct': price_info.get('change_pct', 0),
                    'change_amount': price_info.get('change_amount', 0),
                    'volume': price_info.get('volume', 0),
                    'turnover': price_info.get('turnover', 0),
                    'date': latest_date.strftime('%Y-%m-%d')
                })

            # ä¿å­˜ä¸ºCSV
            df = pd.DataFrame(recommendations)
            output_file = Path(self.config['output_path']) / 'latest_stock_picks.csv'
            df.to_csv(output_file, index=False, encoding='utf-8-sig')

            # åœ¨ç»ˆç«¯æ‰“å°
            print("\n" + "="*120)
            print("ğŸ¯ æœ€æ–°AIé€‰è‚¡å»ºè®® + å®æ—¶è‚¡ä»·")
            print("="*120)
            print(f"æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')} | æ•°æ®æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"æ¨¡å‹: {model_name}")
            print("-"*120)
            print(f"{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<10} {'è‚¡ç¥¨åç§°':<10} {'å½“å‰ä»·æ ¼':<8} {'æ¶¨è·Œå¹…':<8} {'æ¶¨è·Œé¢':<8} {'æˆäº¤é‡(ä¸‡)':<10} {'é¢„æµ‹è¯„åˆ†':<8} {'æƒé‡':<6}")
            print("-"*120)

            for rec in recommendations:
                stock_code = rec['stock_code']
                stock_name = rec['stock_name'][:8] + ('...' if len(rec['stock_name']) > 8 else '')  # é™åˆ¶åç§°é•¿åº¦
                current_price = rec['current_price']
                change_pct = rec['change_pct']
                change_amount = rec['change_amount']
                volume_wan = rec['volume'] / 10000 if rec['volume'] > 0 else 0  # è½¬æ¢ä¸ºä¸‡è‚¡

                # æ¶¨è·Œå¹…é¢œè‰²æ ‡è¯†ï¼ˆç»ˆç«¯é¢œè‰²ï¼‰
                if change_pct > 0:
                    change_pct_str = f"+{change_pct:.2f}%"
                    change_amount_str = f"+{change_amount:.2f}"
                elif change_pct < 0:
                    change_pct_str = f"{change_pct:.2f}%"
                    change_amount_str = f"{change_amount:.2f}"
                else:
                    change_pct_str = "0.00%"
                    change_amount_str = "0.00"

                print(f"{rec['rank']:<4} {stock_code:<10} {stock_name:<10} "
                      f"{current_price:<8.2f} {change_pct_str:<8} {change_amount_str:<8} "
                      f"{volume_wan:<10.0f} {rec['pred_score']:<8.4f} {rec['weight']:<6.1%}")

            print("-"*120)
            avg_score = sum(rec['pred_score'] for rec in recommendations) / len(recommendations)
            avg_price = sum(rec['current_price'] for rec in recommendations if rec['current_price'] > 0) / len([r for r in recommendations if r['current_price'] > 0]) if any(r['current_price'] > 0 for r in recommendations) else 0
            total_volume = sum(rec['volume'] for rec in recommendations) / 10000  # ä¸‡è‚¡

            print(f"å¹³å‡é¢„æµ‹è¯„åˆ†: {avg_score:.4f} | å¹³å‡è‚¡ä»·: {avg_price:.2f}å…ƒ | æ€»æˆäº¤é‡: {total_volume:.0f}ä¸‡è‚¡")
            print(f"é€‰è‚¡æ–‡ä»¶å·²ä¿å­˜: {output_file}")
            print("="*120)

            logger.info(f"æœ€æ–°é€‰è‚¡å»ºè®®(å«è‚¡ä»·)å·²ä¿å­˜è‡³: {output_file}")

        except Exception as e:
            logger.error(f"ç”Ÿæˆæœ€æ–°é€‰è‚¡å»ºè®®å¤±è´¥: {e}")

    def _get_stock_names(self, stock_codes: List[str]) -> Dict[str, str]:
        """ä½¿ç”¨AkShareè·å–è‚¡ç¥¨åç§°"""
        stock_names = {}

        try:
            import akshare as ak

            # è·å–Aè‚¡ä¿¡æ¯
            stock_info = ak.stock_info_a_code_name()

            for stock_code in stock_codes:
                try:
                    # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ï¼šSH600000 -> 600000
                    if stock_code.startswith('SH'):
                        code = stock_code[2:]
                    elif stock_code.startswith('SZ'):
                        code = stock_code[2:]
                    else:
                        code = stock_code

                    # åœ¨è‚¡ç¥¨ä¿¡æ¯ä¸­æŸ¥æ‰¾
                    matching_stocks = stock_info[stock_info['code'] == code]
                    if not matching_stocks.empty:
                        stock_names[stock_code] = matching_stocks.iloc[0]['name']
                    else:
                        stock_names[stock_code] = f"æœªçŸ¥({code})"

                except Exception:
                    stock_names[stock_code] = f"æœªçŸ¥({stock_code})"

        except Exception as e:
            logger.warning(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›è‚¡ç¥¨ä»£ç ä½œä¸ºåç§°
            for stock_code in stock_codes:
                stock_names[stock_code] = stock_code

        return stock_names

    def _get_latest_stock_prices(self, stock_codes: List[str]) -> Dict[str, Dict]:
        """ä½¿ç”¨AkShareè·å–æœ€æ–°è‚¡ä»·ä¿¡æ¯"""
        stock_prices = {}

        try:
            import akshare as ak
            logger.info("æ­£åœ¨è·å–æœ€æ–°è‚¡ä»·ä¿¡æ¯...")

            for stock_code in stock_codes:
                try:
                    # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ï¼šSH600000 -> 600000
                    if stock_code.startswith('SH'):
                        code = stock_code[2:]
                    elif stock_code.startswith('SZ'):
                        code = stock_code[2:]
                    else:
                        code = stock_code

                    # è·å–æœ€æ–°è‚¡ä»·ä¿¡æ¯
                    # ä¼˜å…ˆä½¿ç”¨å†å²æ•°æ®æ¥å£ï¼ˆæ›´ç¨³å®šï¼‰
                    try:
                        hist_data = ak.stock_zh_a_hist(
                            symbol=code,
                            period="daily",
                            start_date=(datetime.now() - timedelta(days=5)).strftime('%Y%m%d'),
                            end_date=datetime.now().strftime('%Y%m%d'),
                            adjust="qfq"
                        )

                        if not hist_data.empty:
                            latest_row = hist_data.iloc[-1]
                            prev_close = hist_data.iloc[-2]['æ”¶ç›˜'] if len(hist_data) > 1 else latest_row['æ”¶ç›˜']
                            current_price = float(latest_row['æ”¶ç›˜'])
                            change_amount = current_price - prev_close
                            change_pct = (change_amount / prev_close * 100) if prev_close > 0 else 0

                            stock_prices[stock_code] = {
                                'current_price': current_price,
                                'change_pct': change_pct,
                                'change_amount': change_amount,
                                'volume': int(latest_row['æˆäº¤é‡']) if 'æˆäº¤é‡' in latest_row else 0,
                                'turnover': float(latest_row['æˆäº¤é¢']) if 'æˆäº¤é¢' in latest_row else 0,
                                'high': float(latest_row['æœ€é«˜']),
                                'low': float(latest_row['æœ€ä½']),
                                'open': float(latest_row['å¼€ç›˜'])
                            }
                        else:
                            raise ValueError("å†å²æ•°æ®ä¸ºç©º")
                    except Exception:
                        # å¤‡ç”¨æ–¹æ³•ï¼šå°è¯•å®æ—¶è¡Œæƒ…æ¥å£
                        try:
                            realtime_data = ak.stock_zh_a_spot_em()
                            matching_data = realtime_data[realtime_data['ä»£ç '] == code]

                            if not matching_data.empty:
                                row = matching_data.iloc[0]
                                stock_prices[stock_code] = {
                                    'current_price': float(row['æœ€æ–°ä»·']),
                                    'change_pct': float(row['æ¶¨è·Œå¹…']),
                                    'change_amount': float(row['æ¶¨è·Œé¢']),
                                    'volume': int(row['æˆäº¤é‡']),
                                    'turnover': float(row['æˆäº¤é¢']) if 'æˆäº¤é¢' in row else 0,
                                    'high': float(row['æœ€é«˜']) if 'æœ€é«˜' in row else 0,
                                    'low': float(row['æœ€ä½']) if 'æœ€ä½' in row else 0,
                                    'open': float(row['ä»Šå¼€']) if 'ä»Šå¼€' in row else 0
                                }
                            else:
                                raise ValueError("å®æ—¶æ•°æ®æœªæ‰¾åˆ°åŒ¹é…è‚¡ç¥¨")
                        except Exception:
                            # æ— æ³•è·å–æ•°æ®æ—¶ä½¿ç”¨é»˜è®¤å€¼
                            stock_prices[stock_code] = {
                                'current_price': 0,
                                'change_pct': 0,
                                'change_amount': 0,
                                'volume': 0,
                                'turnover': 0,
                                'high': 0,
                                'low': 0,
                                'open': 0
                            }

                except Exception as e:
                    logger.warning(f"è·å–è‚¡ç¥¨ {stock_code} ä»·æ ¼å¤±è´¥: {e}")
                    stock_prices[stock_code] = {
                        'current_price': 0,
                        'change_pct': 0,
                        'change_amount': 0,
                        'volume': 0,
                        'turnover': 0,
                        'high': 0,
                        'low': 0,
                        'open': 0
                    }

        except Exception as e:
            logger.error(f"è·å–è‚¡ä»·ä¿¡æ¯å¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
            for stock_code in stock_codes:
                stock_prices[stock_code] = {
                    'current_price': 0,
                    'change_pct': 0,
                    'change_amount': 0,
                    'volume': 0,
                    'turnover': 0,
                    'high': 0,
                    'low': 0,
                    'open': 0
                }

        return stock_prices

    def backtest(self):
        """è¿è¡Œå›æµ‹"""
        logger.info("å¼€å§‹å›æµ‹...")

        # åˆå§‹åŒ–Qlibï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
        try:
            D.calendar()
        except:
            self._init_qlib()

        # åŠ è½½æ¨¡å‹å’Œç”Ÿæˆé¢„æµ‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if not self.models:
            self._load_models()

        predictions = self.predict()

        # é€‰æ‹©æœ€ä½³é¢„æµ‹ï¼ˆä¼˜å…ˆé›†æˆæ¨¡å‹ï¼‰
        if 'ensemble' in predictions:
            pred_score = predictions['ensemble']
            model_name = 'ensemble'
        elif predictions:
            model_name = list(predictions.keys())[0]
            pred_score = predictions[model_name]
        else:
            logger.error("æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹ç»“æœ")
            return

        logger.info(f"ä½¿ç”¨æ¨¡å‹ {model_name} è¿›è¡Œå›æµ‹")

        # è¿è¡Œå›æµ‹
        backtest_results = self._run_backtest(pred_score, self.topk, self.rebalance_freq)

        # å•å…ƒæµ‹è¯•
        self._validate_results(backtest_results)

        # ä¿å­˜ç»“æœ
        self._save_backtest_results(backtest_results, model_name)

        logger.info("å›æµ‹å®Œæˆ")
        return backtest_results

    def _run_backtest(self, pred_score: pd.Series, topk: int = 10, rebalance_freq: str = 'M') -> Dict:
        """æ‰§è¡Œå›æµ‹é€»è¾‘"""
        logger.info("æ‰§è¡Œå›æµ‹é€»è¾‘...")

        # è·å–æµ‹è¯•é›†æ•°æ®
        test_data = self.dataset.prepare("test", col_set=["feature", "label"],
                                       data_key=DataHandlerLP.DK_L)

        # å¯¹é½é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
        aligned_data = pd.DataFrame({
            'pred': pred_score.loc[test_data.index],
            'true': test_data["label"].squeeze()
        }).dropna()

        # è®¡ç®—ICæŒ‡æ ‡
        ic_mean = aligned_data.groupby(level=0).apply(
            lambda x: x['pred'].corr(x['true'])
        ).mean()

        ic_std = aligned_data.groupby(level=0).apply(
            lambda x: x['pred'].corr(x['true'])
        ).std()

        ic_ir = ic_mean / ic_std if ic_std > 0 else 0

        # æŠ•èµ„ç»„åˆå›æµ‹
        portfolio_results = self._portfolio_backtest(aligned_data, topk, rebalance_freq=rebalance_freq)

        results = {
            'ic_mean': ic_mean,
            'ic_std': ic_std,
            'ic_ir': ic_ir,
            'price_min': self.price_min,
            'price_max': self.price_max,
            **portfolio_results
        }

        return results

    def _portfolio_backtest(self, aligned_data: pd.DataFrame,
                          top_k: int = 10, initial_capital: float = 1000000,
                          rebalance_freq: str = 'M') -> Dict:
        """æŠ•èµ„ç»„åˆå›æµ‹ - ä¼˜åŒ–ç‰ˆ"""

        portfolio_returns = []
        turnover_rates = []
        prev_positions = None
        cumulative_nav = 1.0
        max_nav = 1.0

        # é£é™©æ§åˆ¶å‚æ•°
        target_volatility = 0.12  # ç›®æ ‡å¹´åŒ–æ³¢åŠ¨ç‡12%
        max_daily_loss = 0.015    # å•æ—¥æœ€å¤§æŸå¤±1.5%
        max_drawdown_limit = 0.06 # æœ€å¤§å›æ’¤é™åˆ¶6%
        position_limit = 0.04     # å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½4%

        dates = aligned_data.index.get_level_values(0).unique().sort_values()

        # æ ¹æ®è°ƒä»“é¢‘ç‡ç¡®å®šè°ƒä»“æ—¥æœŸ
        rebalance_dates = self._get_rebalance_dates(dates, rebalance_freq)

        for i, date in enumerate(dates[:-2]):  # é¿å…æ•°æ®æ³„æ¼ï¼Œæ”¹ä¸º2å¤©
            try:
                day_data = aligned_data.loc[date]
                if len(day_data) < top_k:
                    continue

                # æ£€æŸ¥æ˜¯å¦ä¸ºè°ƒä»“æ—¥
                is_rebalance_day = date in rebalance_dates

                if is_rebalance_day or prev_positions is None:
                    # ä½¿ç”¨æ–°çš„é€‰è‚¡å‡½æ•°
                    selected_weights = self.select_stocks(day_data['pred'], top_k, date,
                                                         self.price_min, self.price_max)

                    if len(selected_weights) == 0:
                        continue

                    # ä½¿ç”¨ç»„åˆä¼˜åŒ–
                    if prev_positions is not None:
                        optimized_weights = self.optimize_portfolio(
                            day_data['pred'].loc[selected_weights.index],
                            prev_positions
                        )
                        current_positions = optimized_weights
                    else:
                        current_positions = selected_weights
                else:
                    # éè°ƒä»“æ—¥ï¼Œä¿æŒç°æœ‰ä»“ä½
                    if prev_positions is None:
                        continue
                    current_positions = prev_positions.copy()

                # è®¡ç®—æ¢æ‰‹ç‡
                if prev_positions is not None:
                    turnover = self._calc_turnover(prev_positions, current_positions)
                else:
                    turnover = 1.0
                turnover_rates.append(turnover)

                # ç»„åˆæ”¶ç›Šè®¡ç®—
                if is_rebalance_day or prev_positions is None:
                    # è°ƒä»“æ—¥ï¼šä½¿ç”¨æ–°æƒé‡è®¡ç®—æ”¶ç›Š
                    portfolio_return = 0
                    for stock in current_positions.index:
                        if stock in day_data.index:
                            stock_return = day_data.loc[stock, 'true']
                            portfolio_return += current_positions[stock] * stock_return
                else:
                    # éè°ƒä»“æ—¥ï¼šä½¿ç”¨å‰æœŸæƒé‡è®¡ç®—æ”¶ç›Š
                    portfolio_return = 0
                    for stock in prev_positions.index:
                        if stock in day_data.index:
                            stock_return = day_data.loc[stock, 'true']
                            portfolio_return += prev_positions[stock] * stock_return

                # ä¸¥æ ¼çš„é£é™©æ§åˆ¶
                portfolio_return = np.clip(portfolio_return, -max_daily_loss, max_daily_loss)

                # äº¤æ˜“æˆæœ¬ï¼ˆåˆ†çº§æ”¶è´¹ï¼‰
                transaction_cost = self._calc_realistic_transaction_cost(turnover, cumulative_nav * initial_capital)
                net_return = portfolio_return - transaction_cost

                # åŠ¨æ€é£é™©ç®¡ç†
                current_nav = cumulative_nav * (1 + net_return)
                current_drawdown = (current_nav - max_nav) / max_nav

                # å¦‚æœå›æ’¤è¿‡å¤§ï¼Œå‡å°‘ä»“ä½
                if current_drawdown < -max_drawdown_limit:
                    risk_reduction = 0.5  # å‡ä»“50%
                    net_return = net_return * risk_reduction
                    current_nav = cumulative_nav * (1 + net_return)

                cumulative_nav = current_nav
                max_nav = max(max_nav, cumulative_nav)

                portfolio_returns.append(net_return)
                prev_positions = current_positions.copy()

            except Exception:
                continue

        returns_series = pd.Series(portfolio_returns)

        if len(returns_series) == 0:
            return self._get_empty_metrics()

        # è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
        total_return = (1 + returns_series).prod() - 1
        annual_return = returns_series.mean() * 252  # ç®€åŒ–å¹´åŒ–
        volatility = returns_series.std() * np.sqrt(252)
        sharpe_ratio = annual_return / volatility if volatility > 0 else 0

        # æœ€å¤§å›æ’¤
        cumulative = (1 + returns_series).cumprod()
        running_max = cumulative.expanding().max()
        drawdowns = (cumulative - running_max) / running_max * 100
        max_drawdown = drawdowns.min()

        # å…¶ä»–æŒ‡æ ‡
        win_rate = (returns_series > 0).mean()
        avg_turnover = np.mean(turnover_rates)

        return {
            'total_return': total_return,
            'annual_return': annual_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'win_rate': win_rate,
            'avg_turnover': avg_turnover,
            'trading_days': len(returns_series),
            'returns': returns_series
        }

    def _calc_turnover(self, prev_positions: pd.Series,
                      current_positions: pd.Series) -> float:
        """è®¡ç®—æ¢æ‰‹ç‡"""
        all_stocks = set(prev_positions.index) | set(current_positions.index)
        prev_aligned = pd.Series(0.0, index=all_stocks)
        curr_aligned = pd.Series(0.0, index=all_stocks)

        prev_aligned.loc[prev_positions.index] = prev_positions
        curr_aligned.loc[current_positions.index] = current_positions

        return abs(curr_aligned - prev_aligned).sum()

    def select_stocks(self, pred_scores: pd.Series, topk: int, date: pd.Timestamp,
                     price_min: float = 0, price_max: float = 1e9,
                     blacklist: Optional[set] = None) -> pd.Series:
        """
        é€‰è‚¡å­å‡½æ•°ï¼šè¿”å› {instrument: weight}ï¼Œæƒé‡å·²å½’ä¸€åŒ–ä¸”æ»¡è¶³ w_i â‰¤ 0.15

        Args:
            pred_scores: é¢„æµ‹è¯„åˆ† Series
            topk: é€‰æ‹©è‚¡ç¥¨æ•°é‡
            date: å½“å‰æ—¥æœŸ
            price_min: æœ€ä½ä»·æ ¼é™åˆ¶ï¼ˆæ–°å¢ï¼‰
            price_max: æœ€é«˜ä»·æ ¼é™åˆ¶ï¼ˆæ–°å¢ï¼‰
            blacklist: é»‘åå•è‚¡ç¥¨é›†åˆ

        Returns:
            pd.Series: {è‚¡ç¥¨ä»£ç : æƒé‡}
        """
        if blacklist is None:
            blacklist = set()

        # è·å–qlibæœ€æ–°äº¤æ˜“æ—¥æœŸï¼Œè€Œä¸æ˜¯ä½¿ç”¨é¢„æµ‹æ—¥æœŸ
        try:
            calendar = D.calendar()
            latest_trading_date = calendar[-1]
            logger.info(f"ä½¿ç”¨qlibæœ€æ–°äº¤æ˜“æ—¥æœŸè¿›è¡Œä»·æ ¼è¿‡æ»¤: {latest_trading_date.strftime('%Y-%m-%d')}")
        except Exception as e:
            logger.warning(f"è·å–qlibäº¤æ˜“æ—¥å†å¤±è´¥: {e}ï¼Œä½¿ç”¨é¢„æµ‹æ—¥æœŸ")
            latest_trading_date = date

        # è¿‡æ»¤æ¡ä»¶
        valid_stocks = []

        for stock_code, score in pred_scores.items():
            # åŸºæœ¬è¿‡æ»¤æ¡ä»¶
            if pd.isna(score) or stock_code in blacklist:
                continue

            # STè‚¡ç¥¨è¿‡æ»¤ï¼ˆç®€åŒ–å®ç°ï¼šæ£€æŸ¥è‚¡ç¥¨ä»£ç ä¸­æ˜¯å¦åŒ…å«STæ ‡è¯†ï¼‰
            if 'ST' in stock_code or stock_code.startswith('ST'):
                continue

            # ä»·æ ¼åŒºé—´è¿‡æ»¤ï¼ˆä½¿ç”¨qlibæœ€æ–°äº¤æ˜“æ—¥æ•°æ®ï¼Œé€šè¿‡å¤æƒå› å­è½¬æ¢ä¸ºçœŸå®ä»·æ ¼ï¼‰
            try:
                # ä½¿ç”¨qlibæœ€æ–°äº¤æ˜“æ—¥æœŸè¯»å–æ”¶ç›˜ä»·å’Œå¤æƒå› å­
                price_data = D.features([stock_code], ['$close', '$factor'],
                                      start_time=latest_trading_date, end_time=latest_trading_date)

                if price_data.empty or price_data.isna().all().all():
                    # ä»·æ ¼æ•°æ®ç¼ºå¤±ï¼Œå‰”é™¤è¯¥è‚¡ç¥¨
                    logger.debug(f"è‚¡ç¥¨ {stock_code} åœ¨æœ€æ–°äº¤æ˜“æ—¥æ— ä»·æ ¼æ•°æ®ï¼Œå·²å‰”é™¤")
                    continue

                adjusted_price = price_data.iloc[0, 0]  # è·å–è°ƒæ•´åæ”¶ç›˜ä»·
                factor = price_data.iloc[0, 1]  # è·å–å¤æƒå› å­

                # è®¡ç®—çœŸå®ä»·æ ¼ï¼šæ ¹æ®qlibæ–‡æ¡£ï¼Œfactor = adjusted_price / original_price
                # æ‰€ä»¥ï¼šoriginal_price = adjusted_price / factor
                if pd.isna(adjusted_price) or pd.isna(factor) or factor == 0:
                    logger.debug(f"è‚¡ç¥¨ {stock_code} ä»·æ ¼æˆ–å› å­æ•°æ®å¼‚å¸¸ï¼Œå·²å‰”é™¤")
                    continue

                real_price = adjusted_price / factor  # è½¬æ¢ä¸ºçœŸå®äº¤æ˜“ä»·æ ¼

                if real_price <= price_min or real_price > price_max:
                    # ä»·æ ¼ä¸åœ¨æŒ‡å®šåŒºé—´å†…ï¼Œå‰”é™¤è¯¥è‚¡ç¥¨
                    logger.info(f"è‚¡ç¥¨ {stock_code} çœŸå®ä»·æ ¼ {real_price:.2f} (è°ƒæ•´ä»·æ ¼: {adjusted_price:.2f}, å› å­: {factor:.6f}) ä¸åœ¨åŒºé—´ ({price_min:.2f}, {price_max:.2f}] å†…ï¼Œå·²å‰”é™¤")
                    continue
                else:
                    logger.debug(f"è‚¡ç¥¨ {stock_code} çœŸå®ä»·æ ¼ {real_price:.2f} (è°ƒæ•´ä»·æ ¼: {adjusted_price:.2f}, å› å­: {factor:.6f}) ç¬¦åˆæ¡ä»¶ï¼Œé€šè¿‡ä»·æ ¼è¿‡æ»¤")

            except Exception as e:
                # è·å–ä»·æ ¼æ•°æ®å¤±è´¥ï¼Œå‰”é™¤è¯¥è‚¡ç¥¨
                logger.debug(f"è·å–è‚¡ç¥¨ {stock_code} ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
                continue

            # åœç‰Œè¿‡æ»¤ï¼ˆéœ€è¦å®é™…å¸‚åœºæ•°æ®ï¼Œè¿™é‡Œç®€åŒ–è·³è¿‡ï¼‰
            # æˆäº¤é¢è¿‡æ»¤ï¼ˆéœ€è¦å®é™…å¸‚åœºæ•°æ®ï¼Œè¿™é‡Œç®€åŒ–è·³è¿‡ï¼‰

            valid_stocks.append((stock_code, score))

        if len(valid_stocks) == 0:
            logger.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            return pd.Series(dtype=float)

        # æŒ‰è¯„åˆ†æ’åºå¹¶é€‰æ‹©Top K
        valid_stocks.sort(key=lambda x: x[1], reverse=True)
        selected_stocks = valid_stocks[:min(topk, len(valid_stocks))]

        if len(selected_stocks) == 0:
            return pd.Series(dtype=float)

        # è®¡ç®—æƒé‡ï¼ˆé£é™©å¹³ä»·ï¼‰
        stocks = [s[0] for s in selected_stocks]
        scores = np.array([s[1] for s in selected_stocks])

        # åŸºäºé¢„æµ‹åˆ†æ•°çš„æƒé‡åˆ†é…
        if len(scores) == 1:
            weights = np.array([1.0])
        else:
            # ä½¿ç”¨softmaxé£æ ¼çš„æƒé‡åˆ†é…
            exp_scores = np.exp(scores * 2)  # æ”¾å¤§å·®å¼‚
            weights = exp_scores / exp_scores.sum()

        # é™åˆ¶å•åªè‚¡ç¥¨æœ€å¤§æƒé‡
        max_weight = 0.15  # 15%
        weights = np.minimum(weights, max_weight)

        # é‡æ–°å½’ä¸€åŒ–
        if weights.sum() > 0:
            weights = weights / weights.sum()
        else:
            weights = np.repeat(1.0/len(weights), len(weights))

        return pd.Series(weights, index=stocks)

    def optimize_portfolio(self, pred_scores: pd.Series, prev_weights: Optional[pd.Series] = None,
                          max_turnover: float = 0.8, max_position: float = 0.15) -> pd.Series:
        """
        ç»„åˆä¼˜åŒ–ï¼šä½¿ç”¨cvxpyæ±‚è§£æœ€ä¼˜æƒé‡

        Args:
            pred_scores: é¢„æµ‹è¯„åˆ†
            prev_weights: å‰æœŸæƒé‡
            max_turnover: æœ€å¤§æ¢æ‰‹ç‡
            max_position: å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½

        Returns:
            pd.Series: ä¼˜åŒ–åçš„æƒé‡
        """
        try:
            import cvxpy as cp

            n_stocks = len(pred_scores)
            if n_stocks == 0:
                return pd.Series(dtype=float)

            # å˜é‡å®šä¹‰
            w = cp.Variable(n_stocks)

            # ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–é¢„æœŸæ”¶ç›Š
            objective = cp.Maximize(pred_scores.values @ w)

            # çº¦æŸæ¡ä»¶
            constraints = [
                w >= 0,  # ä¸å…è®¸åšç©º
                cp.sum(w) == 1,  # æƒé‡å’Œä¸º1
                w <= max_position,  # å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½
            ]

            # æ¢æ‰‹ç‡çº¦æŸ
            if prev_weights is not None:
                # å¯¹é½è‚¡ç¥¨
                aligned_prev = pd.Series(0.0, index=pred_scores.index)
                common_stocks = set(prev_weights.index) & set(pred_scores.index)
                for stock in common_stocks:
                    aligned_prev[stock] = prev_weights[stock]

                turnover = cp.sum(cp.abs(w - aligned_prev.values))
                constraints.append(turnover <= max_turnover)

            # æ±‚è§£
            problem = cp.Problem(objective, constraints)
            problem.solve(solver=cp.ECOS, verbose=False)

            if problem.status == cp.OPTIMAL:
                optimal_weights = w.value
                if optimal_weights is not None and len(optimal_weights) > 0:
                    # ç¡®ä¿æƒé‡éè´Ÿä¸”å½’ä¸€åŒ–
                    optimal_weights = np.maximum(optimal_weights, 0)
                    if optimal_weights.sum() > 0:
                        optimal_weights = optimal_weights / optimal_weights.sum()
                        return pd.Series(optimal_weights, index=pred_scores.index)

            logger.warning("ä¼˜åŒ–æ±‚è§£å¤±è´¥ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")

        except ImportError:
            logger.warning("CVXPYæœªå®‰è£…ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")
        except Exception as e:
            logger.warning(f"ç»„åˆä¼˜åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")

        # å›é€€åˆ°ç­‰æƒé‡
        n_stocks = len(pred_scores)
        equal_weights = np.repeat(1.0/n_stocks, n_stocks)
        return pd.Series(equal_weights, index=pred_scores.index)

    def _get_rebalance_dates(self, dates: pd.DatetimeIndex, freq: str = 'M') -> set:
        """
        è·å–è°ƒä»“æ—¥æœŸ

        Args:
            dates: æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
            freq: è°ƒä»“é¢‘ç‡ 'D'/'W'/'M'

        Returns:
            set: è°ƒä»“æ—¥æœŸé›†åˆ
        """
        if freq == 'D':
            return set(dates)  # æ¯æ—¥è°ƒä»“
        elif freq == 'W':
            # æ¯å‘¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
            rebalance_dates = set()
            df = pd.DataFrame({'date': dates})
            df['week'] = df['date'].dt.isocalendar().week
            df['year'] = df['date'].dt.year
            weekly_last = df.groupby(['year', 'week'])['date'].max()
            return set(weekly_last.values)
        elif freq == 'M':
            # æ¯æœˆæœ€åä¸€ä¸ªäº¤æ˜“æ—¥
            rebalance_dates = set()
            df = pd.DataFrame({'date': dates})
            df['month'] = df['date'].dt.month
            df['year'] = df['date'].dt.year
            monthly_last = df.groupby(['year', 'month'])['date'].max()
            return set(monthly_last.values)
        else:
            return set(dates)  # é»˜è®¤æ¯æ—¥

    def _calc_transaction_fee(self, turnover: float, portfolio_value: float) -> float:
        """
        è®¡ç®—äº¤æ˜“è´¹ç”¨ï¼š0.0002ä¹° + 0.0005å–
        """
        # ç®€åŒ–ä¸ºåŒè¾¹æ€»è´¹ç‡
        fee_rate = 0.0007  # 0.02% + 0.05%
        return turnover * portfolio_value * fee_rate / portfolio_value  # è½¬æ¢ä¸ºæ”¶ç›Šç‡

    def _calc_realistic_transaction_cost(self, turnover: float, portfolio_value: float) -> float:
        """è®¡ç®—åˆ†çº§äº¤æ˜“æ‰‹ç»­è´¹"""
        trading_amount = turnover * portfolio_value

        if trading_amount < 20000:
            return 5.0 / portfolio_value  # å›ºå®š5å…ƒè½¬æ¢ä¸ºæ”¶ç›Šç‡
        else:
            return turnover * 0.00025  # ä¸‡åˆ†ä¹‹2.5

    def _get_empty_metrics(self) -> Dict:
        """è¿”å›ç©ºçš„æ€§èƒ½æŒ‡æ ‡"""
        return {
            'total_return': 0,
            'annual_return': 0,
            'volatility': 0,
            'sharpe_ratio': 0,
            'max_drawdown': 0,
            'win_rate': 0,
            'avg_turnover': 0,
            'trading_days': 0,
            'returns': pd.Series()
        }

    def _validate_results(self, results: Dict):
        """å•å…ƒæµ‹è¯•ï¼šéªŒè¯å›æµ‹ç»“æœ"""
        logger.info("æ‰§è¡Œå•å…ƒæµ‹è¯•...")

        ic_mean = results.get('ic_mean', 0)
        ic_ir = results.get('ic_ir', 0)
        annual_return = results.get('annual_return', 0)
        max_drawdown = results.get('max_drawdown', 0)
        sharpe_ratio = results.get('sharpe_ratio', 0)
        avg_turnover = results.get('avg_turnover', 0)
        win_rate = results.get('win_rate', 0)

        # æ£€æŸ¥ç›®æ ‡åŒºé—´ - ä»·æ ¼è¿‡æ»¤åè°ƒæ•´çš„é˜ˆå€¼
        checks = [
            (ic_mean >= 0.05, f"ICå‡å€¼ {ic_mean:.4f} < 0.05"),  # æå‡ICè¦æ±‚
            (ic_ir >= 0.15, f"IC_IR {ic_ir:.4f} < 0.15"),
            (0.05 <= abs(annual_return) <= 0.5, f"å¹´åŒ–æ”¶ç›Šç‡ {annual_return:.2%} ä¸åœ¨ 5%-50% èŒƒå›´"),
            (max_drawdown > -0.10, f"æœ€å¤§å›æ’¤ {max_drawdown:.2%} < -10%"),
            (abs(sharpe_ratio) <= 2.5, f"å¤æ™®æ¯”ç‡ {sharpe_ratio:.2f} > 2.5"),
            (avg_turnover < 1.2, f"å¹³å‡æ¢æ‰‹ç‡ {avg_turnover:.2f} > 1.2"),  # é™ä½æ¢æ‰‹ç‡è¦æ±‚
            (win_rate > 0.45, f"èƒœç‡ {win_rate:.2%} < 45%")
        ]

        failed_checks = [msg for check, msg in checks if not check]

        if failed_checks:
            logger.warning("å•å…ƒæµ‹è¯•è­¦å‘Š:")
            for msg in failed_checks:
                logger.warning(f"  - {msg}")
        else:
            logger.info("âœ“ æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡")

    def _save_backtest_results(self, results: Dict, model_name: str):
        """ä¿å­˜å›æµ‹ç»“æœ"""
        output_path = Path(self.config['output_path'])

        # ä¿å­˜è¯¦ç»†æŒ‡æ ‡
        metrics = {k: v for k, v in results.items() if k != 'returns'}

        with open(output_path / f"backtest_metrics_{model_name}.json", 'w') as f:
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            serializable_metrics = {}
            for k, v in metrics.items():
                if isinstance(v, (np.integer, np.floating)):
                    serializable_metrics[k] = float(v)
                else:
                    serializable_metrics[k] = v
            json.dump(serializable_metrics, f, indent=2)

        # ä¿å­˜èµ„é‡‘æ›²çº¿
        if 'returns' in results and len(results['returns']) > 0:
            returns = results['returns']
            equity_curve = (1 + returns).cumprod()

            df = pd.DataFrame({
                'date': equity_curve.index,
                'equity': equity_curve.values,
                'returns': returns.values
            })

            equity_file = output_path / f"equity_curve_{model_name}.csv"
            df.to_csv(equity_file, index=False)
            logger.info(f"èµ„é‡‘æ›²çº¿å·²ä¿å­˜è‡³: {equity_file}")

        # æ‰“å°å›æµ‹ç»“æœ
        self._print_results(results)

        # åˆ›å»ºå¯è§†åŒ–
        self._create_backtest_visualization(results, model_name)

    def _create_backtest_visualization(self, results: Dict, model_name: str):
        """åˆ›å»ºå›æµ‹å¯è§†åŒ–"""
        try:
            import plotly.graph_objects as go
            from plotly.subplots import make_subplots

            logger.info("æ­£åœ¨åˆ›å»ºå›æµ‹å¯è§†åŒ–...")

            # é…è‰²æ–¹æ¡ˆ
            colors = {
                'primary': '#2E86AB',
                'secondary': '#A23B72',
                'success': '#F18F01',
                'warning': '#C73E1D',
                'profit': '#27AE60',
                'loss': '#E74C3C',
                'background': '#FAFBFC'
            }

            # è¯»å–æ•°æ®
            output_path = Path(self.config['output_path'])
            equity_file = output_path / f"equity_curve_{model_name}.csv"

            if not equity_file.exists():
                logger.warning("èµ„é‡‘æ›²çº¿æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¯è§†åŒ–")
                return

            df = pd.read_csv(equity_file)
            df['date'] = pd.to_datetime(df['date'])

            # åˆ›å»º2x2å­å›¾
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=(
                    'ğŸ“ˆ èµ„é‡‘æ›²çº¿ & å›æ’¤', 'ğŸ“Š æ”¶ç›Šç‡åˆ†å¸ƒ',
                    'ğŸ¯ æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾', 'ğŸ“‹ æ ¸å¿ƒæŒ‡æ ‡'
                ),
                specs=[
                    [{"secondary_y": True}, {"type": "histogram"}],
                    [{"type": "heatmap"}, {"type": "table"}]
                ],
                vertical_spacing=0.12,
                horizontal_spacing=0.1
            )

            # 1. èµ„é‡‘æ›²çº¿å’Œå›æ’¤
            equity = df['equity'].values
            dates = df['date']
            returns = df['returns'].values

            # è®¡ç®—å›æ’¤
            running_max = np.maximum.accumulate(equity)
            drawdown = (equity - running_max) / running_max * 100

            # èµ„é‡‘æ›²çº¿
            fig.add_trace(
                go.Scatter(
                    x=dates, y=equity,
                    name='èµ„é‡‘æ›²çº¿',
                    line=dict(color=colors['primary'], width=3),
                    fill='tonexty',
                    fillcolor='rgba(46, 134, 171, 0.1)',
                    hovertemplate='<b>%{x}</b><br>å‡€å€¼: %{y:.3f}<extra></extra>'
                ),
                row=1, col=1
            )

            # å›æ’¤
            fig.add_trace(
                go.Scatter(
                    x=dates, y=drawdown,
                    name='å›æ’¤(%)',
                    line=dict(color=colors['warning'], width=2, dash='dot'),
                    yaxis='y2',
                    fill='tozeroy',
                    fillcolor='rgba(199, 62, 29, 0.2)',
                    hovertemplate='<b>%{x}</b><br>å›æ’¤: %{y:.2f}%<extra></extra>'
                ),
                row=1, col=1, secondary_y=True
            )

            # 2. æ”¶ç›Šç‡åˆ†å¸ƒ
            returns_pct = returns * 100
            fig.add_trace(
                go.Histogram(
                    x=returns_pct,
                    nbinsx=25,
                    name='æ”¶ç›Šç‡åˆ†å¸ƒ',
                    marker=dict(color=colors['secondary'], opacity=0.7),
                    hovertemplate='æ”¶ç›Šç‡: %{x:.2f}%<br>é¢‘æ¬¡: %{y}<extra></extra>'
                ),
                row=1, col=2
            )

            # 3. æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾
            df_copy = df.copy()
            df_copy['year'] = df_copy['date'].dt.year
            df_copy['month'] = df_copy['date'].dt.month

            # è®¡ç®—æœˆåº¦æ”¶ç›Š
            monthly_returns = []
            for year in df_copy['year'].unique():
                year_data = df_copy[df_copy['year'] == year]
                for month in range(1, 13):
                    month_data = year_data[year_data['month'] == month]
                    if len(month_data) > 0:
                        month_return = (month_data['equity'].iloc[-1] / month_data['equity'].iloc[0] - 1) * 100
                        monthly_returns.append([year, month, month_return])
                    else:
                        monthly_returns.append([year, month, np.nan])

            monthly_df = pd.DataFrame(monthly_returns, columns=['year', 'month', 'return'])
            heatmap_data = monthly_df.pivot(index='year', columns='month', values='return')

            month_labels = ['1æœˆ', '2æœˆ', '3æœˆ', '4æœˆ', '5æœˆ', '6æœˆ',
                           '7æœˆ', '8æœˆ', '9æœˆ', '10æœˆ', '11æœˆ', '12æœˆ']

            fig.add_trace(
                go.Heatmap(
                    z=heatmap_data.values,
                    x=month_labels,
                    y=heatmap_data.index,
                    colorscale=[[0, colors['loss']], [0.5, 'white'], [1, colors['profit']]],
                    zmid=0,
                    showscale=True,
                    colorbar=dict(title='æ”¶ç›Šç‡(%)', len=0.4),
                    hovertemplate='<b>%{y}å¹´%{x}</b><br>æ”¶ç›Šç‡: %{z:.2f}%<extra></extra>'
                ),
                row=2, col=1
            )

            # 4. æ ¸å¿ƒæŒ‡æ ‡è¡¨
            metrics_data = [
                ['æ€»æ”¶ç›Šç‡', f"{results['total_return']:.1%}"],
                ['å¹´åŒ–æ”¶ç›Šç‡', f"{results['annual_return']:.1%}"],
                ['å¹´åŒ–æ³¢åŠ¨ç‡', f"{results['volatility']:.1%}"],
                ['å¤æ™®æ¯”ç‡', f"{results['sharpe_ratio']:.2f}"],
                ['æœ€å¤§å›æ’¤', f"{results['max_drawdown']:.1%}"],
                ['èƒœç‡', f"{results['win_rate']:.1%}"],
                ['ICå‡å€¼', f"{results['ic_mean']:.4f}"],
                ['äº¤æ˜“æ—¥æ•°', f"{results['trading_days']}"]
            ]

            fig.add_trace(
                go.Table(
                    header=dict(
                        values=['æŒ‡æ ‡', 'æ•°å€¼'],
                        fill_color=colors['primary'],
                        font=dict(color='white', size=12),
                        align='center'
                    ),
                    cells=dict(
                        values=list(zip(*metrics_data)),
                        fill_color='white',
                        font=dict(color='#2C3E50', size=11),
                        align=['left', 'center']
                    )
                ),
                row=2, col=2
            )

            # æ•´ä½“å¸ƒå±€
            fig.update_layout(
                title={
                    'text': f'<b>ğŸ¯ AIé€‰è‚¡å›æµ‹åˆ†æ</b><br><sub>ä»·æ ¼åŒºé—´: {results["price_min"]:.0f}-{results["price_max"]:.0f}å…ƒ | æ€»æ”¶ç›Š: {results["total_return"]:.1%} | å¤æ™®: {results["sharpe_ratio"]:.2f}</sub>',
                    'x': 0.5,
                    'font': {'size': 18, 'color': '#2C3E50'}
                },
                height=800,
                width=1200,
                plot_bgcolor=colors['background'],
                paper_bgcolor='white',
                font={'family': 'Arial, sans-serif', 'size': 10},
                showlegend=True
            )

            # æ˜¾ç¤ºå›¾è¡¨
            fig.show()
            logger.info("âœ… å›æµ‹å¯è§†åŒ–å·²ç”Ÿæˆå¹¶æ˜¾ç¤º")

        except ImportError:
            logger.warning("Plotlyæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–ã€‚å®‰è£…å‘½ä»¤: pip install plotly")
        except Exception as e:
            logger.error(f"å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {e}")

    def _print_results(self, results: Dict):
        """æ‰“å°å›æµ‹ç»“æœ"""
        print("\n" + "="*50)
        print("å›æµ‹ç»“æœæ±‡æ€»")
        print("="*50)
        print(f"ICå‡å€¼:        {results.get('ic_mean', 0):.4f}")
        print(f"IC_IR:         {results.get('ic_ir', 0):.4f}")
        print(f"æ€»æ”¶ç›Š:        {results.get('total_return', 0):.2%}")
        print(f"å¹´åŒ–æ”¶ç›Šç‡:    {results.get('annual_return', 0):.2%}")
        print(f"å¹´åŒ–æ³¢åŠ¨ç‡:    {results.get('volatility', 0):.2%}")
        print(f"å¤æ™®æ¯”ç‡:      {results.get('sharpe_ratio', 0):.2f}")
        print(f"æœ€å¤§å›æ’¤:      {results.get('max_drawdown', 0):.2%}")
        print(f"èƒœç‡:          {results.get('win_rate', 0):.2%}")
        print(f"å¹³å‡æ¢æ‰‹ç‡:    {results.get('avg_turnover', 0):.2f}")
        print(f"äº¤æ˜“æ—¥æ•°:      {results.get('trading_days', 0)}")
        print(f"ä»·æ ¼åŒºé—´:      ({results.get('price_min', 0):.2f}, {results.get('price_max', 1e9):.2f})")
        print("="*50)

    def _create_standalone_visualization(self):
        """åˆ›å»ºç‹¬ç«‹çš„å¯è§†åŒ–ï¼ˆä¸ä¾èµ–å›æµ‹æµç¨‹ï¼‰"""
        try:
            import plotly.graph_objects as go
            from plotly.subplots import make_subplots

            logger.info("ğŸ¨ å¯åŠ¨ç‹¬ç«‹å¯è§†åŒ–æ¨¡å¼...")

            # æ£€æŸ¥å¿…è¦æ–‡ä»¶
            output_path = Path(self.config['output_path'])

            # æŸ¥æ‰¾æœ€æ–°çš„å›æµ‹ç»“æœ
            model_names = ['ensemble', 'lgb', 'xgb']
            selected_model = None

            for model in model_names:
                metrics_file = output_path / f'backtest_metrics_{model}.json'
                equity_file = output_path / f'equity_curve_{model}.csv'
                if metrics_file.exists() and equity_file.exists():
                    selected_model = model
                    break

            if not selected_model:
                logger.error("âŒ æœªæ‰¾åˆ°å›æµ‹ç»“æœæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œå›æµ‹")
                print("è¯·å…ˆè¿è¡Œ: python ai_stock_selector.py --backtest")
                return

            logger.info(f"ğŸ“Š ä½¿ç”¨ {selected_model} æ¨¡å‹çš„å›æµ‹ç»“æœ")

            # åŠ è½½æ•°æ®
            with open(output_path / f'backtest_metrics_{selected_model}.json', 'r') as f:
                metrics = json.load(f)

            df = pd.read_csv(output_path / f'equity_curve_{selected_model}.csv')
            df['date'] = pd.to_datetime(df['date'])

            # åŠ è½½é€‰è‚¡ç»“æœ
            picks_file = output_path / 'latest_stock_picks.csv'
            picks_data = None
            if picks_file.exists():
                picks_data = pd.read_csv(picks_file)

            # é…è‰²æ–¹æ¡ˆ
            colors = {
                'primary': '#2E86AB',
                'secondary': '#A23B72',
                'success': '#F18F01',
                'warning': '#C73E1D',
                'profit': '#27AE60',
                'loss': '#E74C3C',
                'background': '#FAFBFC',
                'neutral': '#95A5A6'
            }

            # åˆ›å»ºé«˜çº§ä»ªè¡¨æ¿ (3x2)
            fig = make_subplots(
                rows=3, cols=2,
                subplot_titles=(
                    'ğŸ“ˆ èµ„é‡‘æ›²çº¿ & å›æ’¤åˆ†æ', 'ğŸ“Š æ”¶ç›Šç‡åˆ†å¸ƒ & é£é™©åˆ†æ',
                    'ğŸ¯ æ»šåŠ¨å¤æ™®æ¯”ç‡', 'ğŸ’° æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾',
                    'ğŸ† æŠ•èµ„ç»„åˆè¡¨ç°å¯¹æ¯”', 'ğŸ“‹ å½“å‰æŒä»“è¯¦æƒ…'
                ),
                specs=[
                    [{"secondary_y": True}, {"type": "histogram"}],
                    [{"secondary_y": True}, {"type": "heatmap"}],
                    [{"type": "scatter"}, {"type": "table"}]
                ],
                vertical_spacing=0.08,
                horizontal_spacing=0.1
            )

            # æ•°æ®å¤„ç†
            equity = df['equity'].values
            dates = df['date']
            returns = df['returns'].values

            # è®¡ç®—å›æ’¤
            running_max = np.maximum.accumulate(equity)
            drawdown = (equity - running_max) / running_max * 100

            # 1. èµ„é‡‘æ›²çº¿å’Œå›æ’¤
            fig.add_trace(
                go.Scatter(
                    x=dates, y=equity,
                    name='èµ„é‡‘æ›²çº¿',
                    line=dict(color=colors['primary'], width=3),
                    fill='tonexty',
                    fillcolor='rgba(46, 134, 171, 0.1)',
                    hovertemplate='<b>%{x}</b><br>å‡€å€¼: %{y:.3f}<br><extra></extra>'
                ),
                row=1, col=1
            )

            fig.add_trace(
                go.Scatter(
                    x=dates, y=drawdown,
                    name='å›æ’¤(%)',
                    line=dict(color=colors['warning'], width=2, dash='dot'),
                    yaxis='y2',
                    fill='tozeroy',
                    fillcolor='rgba(199, 62, 29, 0.2)',
                    hovertemplate='<b>%{x}</b><br>å›æ’¤: %{y:.2f}%<extra></extra>'
                ),
                row=1, col=1, secondary_y=True
            )

            # æ ‡è®°å…³é”®ç‚¹
            max_dd_idx = np.argmin(drawdown)
            max_equity_idx = np.argmax(equity)

            fig.add_trace(
                go.Scatter(
                    x=[dates.iloc[max_dd_idx]], y=[drawdown[max_dd_idx]],
                    mode='markers+text',
                    marker=dict(color=colors['warning'], size=15, symbol='triangle-down'),
                    text=[f'æœ€å¤§å›æ’¤<br>{drawdown[max_dd_idx]:.2f}%'],
                    textposition='bottom center',
                    name='æœ€å¤§å›æ’¤ç‚¹',
                    yaxis='y2',
                    showlegend=False
                ),
                row=1, col=1, secondary_y=True
            )

            # 2. æ”¶ç›Šç‡åˆ†å¸ƒ
            returns_pct = returns * 100
            fig.add_trace(
                go.Histogram(
                    x=returns_pct,
                    nbinsx=30,
                    name='æ”¶ç›Šç‡åˆ†å¸ƒ',
                    marker=dict(color=colors['secondary'], opacity=0.7),
                    hovertemplate='æ”¶ç›Šç‡: %{x:.2f}%<br>é¢‘æ¬¡: %{y}<extra></extra>'
                ),
                row=1, col=2
            )

            # æ·»åŠ ç»Ÿè®¡çº¿
            mean_return = np.mean(returns_pct)
            std_return = np.std(returns_pct)

            # 3. æ»šåŠ¨å¤æ™®æ¯”ç‡
            window = 20
            rolling_sharpe = []
            rolling_vol = []

            for i in range(window, len(returns)):
                window_returns = returns[i-window:i]
                if len(window_returns) > 0 and np.std(window_returns) > 0:
                    sharpe = np.mean(window_returns) / np.std(window_returns) * np.sqrt(252)
                    vol = np.std(window_returns) * np.sqrt(252) * 100
                else:
                    sharpe = 0
                    vol = 0
                rolling_sharpe.append(sharpe)
                rolling_vol.append(vol)

            rolling_dates = dates[window:]

            fig.add_trace(
                go.Scatter(
                    x=rolling_dates, y=rolling_sharpe,
                    name='æ»šåŠ¨å¤æ™®æ¯”ç‡(20æ—¥)',
                    line=dict(color=colors['success'], width=2),
                    hovertemplate='<b>%{x}</b><br>å¤æ™®æ¯”ç‡: %{y:.2f}<extra></extra>'
                ),
                row=2, col=1
            )

            fig.add_trace(
                go.Scatter(
                    x=rolling_dates, y=rolling_vol,
                    name='æ»šåŠ¨æ³¢åŠ¨ç‡(20æ—¥)',
                    line=dict(color=colors['warning'], width=2, dash='dash'),
                    yaxis='y4',
                    hovertemplate='<b>%{x}</b><br>æ³¢åŠ¨ç‡: %{y:.1f}%<extra></extra>'
                ),
                row=2, col=1, secondary_y=True
            )

            # 4. æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾
            df_copy = df.copy()
            df_copy['year'] = df_copy['date'].dt.year
            df_copy['month'] = df_copy['date'].dt.month

            monthly_returns = []
            for year in df_copy['year'].unique():
                year_data = df_copy[df_copy['year'] == year]
                for month in range(1, 13):
                    month_data = year_data[year_data['month'] == month]
                    if len(month_data) > 0:
                        month_return = (month_data['equity'].iloc[-1] / month_data['equity'].iloc[0] - 1) * 100
                        monthly_returns.append([year, month, month_return])
                    else:
                        monthly_returns.append([year, month, np.nan])

            monthly_df = pd.DataFrame(monthly_returns, columns=['year', 'month', 'return'])
            heatmap_data = monthly_df.pivot(index='year', columns='month', values='return')

            month_labels = ['1æœˆ', '2æœˆ', '3æœˆ', '4æœˆ', '5æœˆ', '6æœˆ',
                           '7æœˆ', '8æœˆ', '9æœˆ', '10æœˆ', '11æœˆ', '12æœˆ']

            fig.add_trace(
                 go.Heatmap(
                     z=heatmap_data.values,
                     x=month_labels,
                     y=heatmap_data.index,
                     colorscale=[[0, colors['loss']], [0.5, 'white'], [1, colors['profit']]],
                     zmid=0,
                     showscale=True,
                     colorbar=dict(title='æ”¶ç›Šç‡(%)', len=0.3),
                     hovertemplate='<b>%{y}å¹´%{x}</b><br>æ”¶ç›Šç‡: %{z:.2f}%<extra></extra>'
                 ),
                 row=2, col=2
             )

             # 5. æ€§èƒ½å¯¹æ¯”æ•£ç‚¹å›¾
             strategies = [
                 {'name': 'å½“å‰ç­–ç•¥', 'return': metrics['annual_return']*100,
                  'risk': metrics['volatility']*100, 'sharpe': metrics['sharpe_ratio']},
                 {'name': 'æ²ªæ·±300', 'return': 8.5, 'risk': 18.2, 'sharpe': 0.47},
                 {'name': 'ä¸­è¯500', 'return': 12.3, 'risk': 22.1, 'sharpe': 0.56},
                 {'name': 'åˆ›ä¸šæ¿æŒ‡', 'return': 15.8, 'risk': 28.5, 'sharpe': 0.55},
                 {'name': 'ä¸Šè¯50', 'return': 6.2, 'risk': 15.8, 'sharpe': 0.39}
             ]

             for strategy in strategies:
                 color = colors['primary'] if strategy['name'] == 'å½“å‰ç­–ç•¥' else colors['neutral']
                 size = 20 if strategy['name'] == 'å½“å‰ç­–ç•¥' else 12

                 fig.add_trace(
                     go.Scatter(
                         x=[strategy['risk']], y=[strategy['return']],
                         mode='markers+text',
                         marker=dict(color=color, size=size, line=dict(color='white', width=2)),
                         text=[strategy['name']],
                         textposition='top center',
                         name=strategy['name'],
                         hovertemplate=f'<b>{strategy["name"]}</b><br>'
                                     f'å¹´åŒ–æ”¶ç›Š: {strategy["return"]:.1f}%<br>'
                                     f'å¹´åŒ–æ³¢åŠ¨: {strategy["risk"]:.1f}%<br>'
                                     f'å¤æ™®æ¯”ç‡: {strategy["sharpe"]:.2f}<extra></extra>',
                         showlegend=False
                     ),
                     row=3, col=1
                 )

             # 6. å½“å‰æŒä»“è¡¨æ ¼
             if picks_data is not None and len(picks_data) > 0:
                 headers = ['æ’å', 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'å½“å‰ä»·æ ¼', 'æ¶¨è·Œå¹…', 'æƒé‡', 'è¯„åˆ†']

                 values = [
                     picks_data['rank'].astype(str),
                     picks_data['stock_code'],
                     picks_data['stock_name'].str[:8],
                     picks_data['current_price'].apply(lambda x: f'{x:.2f}'),
                     picks_data['change_pct'].apply(lambda x: f'{x:+.2f}%'),
                     picks_data['weight'].apply(lambda x: f'{x:.1%}'),
                     picks_data['pred_score'].apply(lambda x: f'{x:.4f}')
                 ]

                 # é¢œè‰²ç¼–ç 
                 def get_color(val):
                     try:
                         num_val = float(val.replace('%', '').replace('+', ''))
                         if num_val > 0:
                             return colors['profit']
                         elif num_val < 0:
                             return colors['loss']
                         else:
                             return 'white'
                     except:
                         return 'white'

                 cell_colors = [['white'] * len(picks_data) for _ in headers]
                 cell_colors[4] = [get_color(val) for val in values[4]]  # æ¶¨è·Œå¹…åˆ—

             else:
                 # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                 headers = ['æŒ‡æ ‡', 'æ•°å€¼']
                 values = [
                     ['æ€»æ”¶ç›Šç‡', 'å¹´åŒ–æ”¶ç›Šç‡', 'å¤æ™®æ¯”ç‡', 'æœ€å¤§å›æ’¤', 'èƒœç‡', 'ICå‡å€¼'],
                     [f"{metrics['total_return']:.1%}",
                      f"{metrics['annual_return']:.1%}",
                      f"{metrics['sharpe_ratio']:.2f}",
                      f"{metrics['max_drawdown']:.1%}",
                      f"{metrics['win_rate']:.1%}",
                      f"{metrics['ic_mean']:.4f}"]
                 ]
                 cell_colors = [['white'] * 6, ['white'] * 6]

             fig.add_trace(
                 go.Table(
                     header=dict(
                         values=headers,
                         fill_color=colors['primary'],
                         font=dict(color='white', size=11),
                         align='center'
                     ),
                     cells=dict(
                         values=values,
                         fill_color=cell_colors,
                         font=dict(color='#2C3E50', size=10),
                         align='center'
                     )
                 ),
                 row=3, col=2
             )

             # æ•´ä½“å¸ƒå±€
             fig.update_layout(
                 title={
                     'text': f'<b>ğŸ¯ AIé€‰è‚¡å›æµ‹åˆ†æä»ªè¡¨æ¿</b><br><sub>æ¨¡å‹: {selected_model.upper()} | ä»·æ ¼åŒºé—´: {metrics.get("price_min", 0):.0f}-{metrics.get("price_max", 1e9):.0f}å…ƒ | æ€»æ”¶ç›Š: {metrics["total_return"]:.1%} | å¤æ™®: {metrics["sharpe_ratio"]:.2f}</sub>',
                     'x': 0.5,
                     'font': {'size': 20, 'color': '#2C3E50'}
                 },
                 height=1000,
                 width=1400,
                 plot_bgcolor=colors['background'],
                 paper_bgcolor='white',
                 font={'family': 'Arial, sans-serif', 'size': 10, 'color': '#2C3E50'},
                 showlegend=True,
                 legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
             )

             # æ›´æ–°åæ ‡è½´
             fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#E8EAED')
             fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#E8EAED')

             # æ˜¾ç¤ºå›¾è¡¨
             fig.show()

             # æ‰“å°ç®€è¦ç»Ÿè®¡
             print("\n" + "="*80)
             print("ğŸ“Š å¯è§†åŒ–åˆ†æå®Œæˆ")
             print("="*80)
             print(f"ğŸ“ˆ æ€»æ”¶ç›Šç‡: {metrics['total_return']:.1%}")
             print(f"ğŸ“ˆ å¹´åŒ–æ”¶ç›Šç‡: {metrics['annual_return']:.1%}")
             print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {metrics['max_drawdown']:.1%}")
             print(f"âš¡ å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.2f}")
             print(f"ğŸ¯ èƒœç‡: {metrics['win_rate']:.1%}")
             print(f"ğŸ“Š äº¤æ˜“æ—¥æ•°: {metrics['trading_days']}")
             if picks_data is not None:
                 print(f"ğŸ† å½“å‰æŒä»“: {len(picks_data)} åªè‚¡ç¥¨")
                 avg_price = picks_data['current_price'].mean()
                 print(f"ğŸ’° å¹³å‡è‚¡ä»·: {avg_price:.2f} å…ƒ")
             print("="*80)

             logger.info("âœ… ç‹¬ç«‹å¯è§†åŒ–å®Œæˆ")

         except ImportError:
             logger.error("âŒ Plotlyæœªå®‰è£…ï¼Œè¯·å®‰è£…: pip install plotly")
         except Exception as e:
             logger.error(f"âŒ ç‹¬ç«‹å¯è§†åŒ–å¤±è´¥: {e}")
             import traceback
             logger.error(traceback.format_exc())


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='AIè‚¡ç¥¨é€‰æ‹©å™¨')
    parser.add_argument('--prepare_data', action='store_true', help='å‡†å¤‡æ•°æ®')
    parser.add_argument('--train', action='store_true', help='è®­ç»ƒæ¨¡å‹')
    parser.add_argument('--predict', action='store_true', help='ç”Ÿæˆé¢„æµ‹')
    parser.add_argument('--select_stocks', action='store_true', help='é€‰è‚¡å¹¶ç”ŸæˆæŠ•èµ„ç»„åˆ')
    parser.add_argument('--backtest', action='store_true', help='è¿è¡Œå›æµ‹')
    parser.add_argument('--visualize', action='store_true', help='æ˜¾ç¤ºå›æµ‹å¯è§†åŒ–')
    parser.add_argument('--topk', type=int, default=10, help='é€‰è‚¡æ•°é‡ï¼ˆé»˜è®¤10ï¼‰')
    parser.add_argument('--rebalance_freq', type=str, default='M', choices=['D', 'W', 'M'],
                       help='è°ƒä»“é¢‘ç‡ï¼šDæ—¥åº¦, Wå‘¨åº¦, Mæœˆåº¦')
    parser.add_argument('--universe', type=str, choices=['all', 'csi300', 'csi500'],
                       help='è‚¡ç¥¨æ± ï¼šallå…¨å¸‚åœº, csi300æ²ªæ·±300, csi500ä¸­è¯500')
    parser.add_argument('--price_min', type=float, default=0, help='æœ€ä½ä»·æ ¼é™åˆ¶ï¼ˆé»˜è®¤0ï¼‰')
    parser.add_argument('--price_max', type=float, default=1e9, help='æœ€é«˜ä»·æ ¼é™åˆ¶ï¼ˆé»˜è®¤1e9ï¼‰')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = CONFIG.copy()
    if args.config and Path(args.config).exists():
        with open(args.config, 'r') as f:
            custom_config = json.load(f)
            config.update(custom_config)

    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°åˆ°é…ç½®
    if args.universe:
        config['universe'] = args.universe

    # åˆ›å»ºé€‰è‚¡å™¨å®ä¾‹
    selector = AIStockSelector(config)

    # ä¼ é€’å‘½ä»¤è¡Œå‚æ•°
    selector.topk = args.topk
    selector.rebalance_freq = args.rebalance_freq
    selector.price_min = args.price_min
    selector.price_max = args.price_max

    try:
        if args.prepare_data:
            selector.prepare_data()
        elif args.train:
            selector.prepare_data()  # ç¡®ä¿æ•°æ®å¯ç”¨
            selector.train()
        elif args.predict:
            selector.predict()
        elif args.select_stocks:
            selector.predict()  # é€‰è‚¡åŒ…å«é¢„æµ‹æ­¥éª¤
        elif args.backtest:
            selector.backtest()
        elif args.visualize:
            selector._create_standalone_visualization()
        else:
            # é»˜è®¤è¿è¡Œå®Œæ•´æµç¨‹
            print("è¿è¡Œå®Œæ•´AIé€‰è‚¡æµç¨‹...")
            selector.prepare_data()
            selector.train()
            selector.predict()
            selector.backtest()

    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()